{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFzxIH1wmRemPFyx5MJCot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DISHA2608129/DISHAAAA/blob/main/Disha_Halder_Decission_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a Decision Tree, and how does it work?"
      ],
      "metadata": {
        "id": "2Lv3BM1yAeF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a popular machine learning algorithm used for both classification and regression tasks. It works by recursively splitting the data into subsets based on feature values, ultimately making predictions based on these splits. The structure of a decision tree is similar to a flowchart, where each node represents a decision (based on a feature), and each branch represents the outcome of that decision.\n",
        "\n",
        "How a Decision Tree Works:\n",
        "Root Node:\n",
        "\n",
        "The tree starts with a root node which represents the entire dataset. The algorithm selects the best feature (based on a criterion) to split the data into subsets.\n",
        "\n",
        "Splitting:\n",
        "\n",
        "The root node is split into branches based on the values of a feature. Each branch corresponds to a possible value or range of values for that feature.\n",
        "\n",
        "This process is recursively applied at each subsequent node (i.e., split) until one of the stopping criteria is met (e.g., maximum depth, minimum samples per leaf, or purity of the node).\n",
        "\n",
        "Leaf Nodes:\n",
        "\n",
        "Once the data cannot be split further (based on the stopping criteria), the final nodes are called leaf nodes. These nodes provide the final decision or prediction.\n",
        "\n",
        "For classification, the leaf node will assign the most frequent class in that subset of data.\n",
        "\n",
        "For regression, the leaf node will provide the mean or median of the target variable in that subset of data.\n",
        "\n",
        "Decision Making:\n",
        "\n",
        "To make a prediction for new, unseen data, the decision tree uses the values of the input features to follow the path from the root to the appropriate leaf node. The output is the prediction in the leaf node."
      ],
      "metadata": {
        "id": "ZCnplj6MAjfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are impurity measures in Decision Trees?"
      ],
      "metadata": {
        "id": "na7ECCwbAkDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Decision Trees, impurity measures are metrics used to evaluate how well a dataset is split at each node. The goal is to minimize the impurity of the data at each node, ensuring that the splits lead to more homogenous groups, ultimately resulting in more accurate predictions. Two commonly used impurity measures are Gini Impurity and Entropy (used for classification tasks), and Variance Reduction (used for regression tasks).\n",
        "\n",
        "Gini Impurity: This is a measure of how often a randomly selected element would be incorrectly classified if it were randomly labeled according to the distribution of labels in the node. A Gini Impurity of 0 means that all elements in the node belong to a single class, while a Gini Impurity of 0.5 indicates an equal distribution of elements across different classes. The Decision Tree algorithm aims to minimize Gini Impurity by selecting splits that result in the lowest possible impurity.\n",
        "\n",
        "Entropy (Information Gain): Entropy is a measure of disorder or uncertainty in the data. A node with low entropy means the data is more homogenous, and a node with high entropy indicates more mixed classes. Information Gain is the reduction in entropy achieved by a split. The Decision Tree algorithm uses Information Gain to choose splits that result in the greatest reduction in entropy, leading to more predictable nodes.\n",
        "\n",
        "Variance Reduction (for Regression Trees): In regression trees, the impurity is typically measured by the variance of the target variable within the node. A node with low variance means that the target variable values are close to each other, and a node with high variance indicates that the target variable values are spread out. The algorithm aims to minimize the variance within each split, which improves the model's predictive accuracy."
      ],
      "metadata": {
        "id": "0t9XQcR7Aoum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the mathematical formula for Gini Impurity?"
      ],
      "metadata": {
        "id": "l786pscxArIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical formula for Gini Impurity is given by:\n",
        "\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini(D)=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝐷\n",
        "D is the dataset or node.\n",
        "\n",
        "𝐶\n",
        "C is the number of unique classes in the target variable.\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of instances in class\n",
        "𝑖\n",
        "i in the node.\n",
        "\n",
        "Explanation:\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability (or relative frequency) of a sample being classified into class\n",
        "𝑖\n",
        "i.\n",
        "\n",
        "The Gini Impurity score ranges from 0 to 1:\n",
        "\n",
        "A Gini Impurity of 0 means that all elements in the node belong to a single class (i.e., perfect purity).\n",
        "\n",
        "A Gini Impurity of 1 would indicate that the classes are evenly distributed across the node (i.e., maximum impurity)."
      ],
      "metadata": {
        "id": "FwlSAzg4Aw-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the mathematical formula for Entropy?"
      ],
      "metadata": {
        "id": "JOyG-zA0Axe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical formula for Entropy is given by:\n",
        "\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy(D)=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝐷\n",
        "D is the dataset or node.\n",
        "\n",
        "𝐶\n",
        "C is the number of unique classes in the target variable.\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of instances in class\n",
        "𝑖\n",
        "i in the node.\n",
        "\n",
        "Explanation:\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability (or relative frequency) of a sample being classified into class\n",
        "𝑖\n",
        "i.\n",
        "\n",
        "The logarithm is base 2 because entropy is often measured in bits (as it is related to information theory).\n",
        "\n",
        "Entropy measures the uncertainty or impurity in a dataset. Higher entropy indicates greater uncertainty or disorder, while lower entropy indicates more certainty or purity."
      ],
      "metadata": {
        "id": "EcEs5xVFA4iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Information Gain, and how is it used in Decision Trees\t?"
      ],
      "metadata": {
        "id": "yD31M7xmA7J_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Gain (IG) is a metric used to measure the effectiveness of a feature in classifying a dataset. It quantifies the reduction in uncertainty or entropy after a dataset is split based on a particular feature. In the context of Decision Trees, Information Gain is used to determine the best feature to split the data at each node in the tree-building process.\n",
        "\n",
        "Formula for Information Gain:\n",
        "Information Gain is calculated as the difference between the entropy of the original dataset and the weighted average entropy of the dataset after it is split into subsets based on a specific feature.\n",
        "\n",
        "Information Gain\n",
        "(\n",
        "𝐷\n",
        ",\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "−\n",
        "∑\n",
        "𝑣\n",
        "∈\n",
        "𝑉\n",
        "𝑎\n",
        "𝑙\n",
        "𝑢\n",
        "𝑒\n",
        "𝑠\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "×\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        "𝑣\n",
        ")\n",
        "Information Gain(D,A)=Entropy(D)−\n",
        "v∈Values(A)\n",
        "∑\n",
        "​\n",
        "  \n",
        "∣D∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        " ×Entropy(D\n",
        "v\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝐷\n",
        "D is the dataset.\n",
        "\n",
        "𝐴\n",
        "A is the feature used for splitting the data.\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "Entropy(D) is the entropy of the entire dataset before splitting.\n",
        "\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        "𝑣\n",
        ")\n",
        "Entropy(D\n",
        "v\n",
        "​\n",
        " ) is the entropy of the subset\n",
        "𝐷\n",
        "𝑣\n",
        "D\n",
        "v\n",
        "​\n",
        "  that corresponds to the values\n",
        "𝑣\n",
        "v of feature\n",
        "𝐴\n",
        "A.\n",
        "\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "∣D∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        "  is the weight of subset\n",
        "𝐷\n",
        "𝑣\n",
        "D\n",
        "v\n",
        "​\n",
        " , which is the fraction of samples in subset\n",
        "𝐷\n",
        "𝑣\n",
        "D\n",
        "v\n",
        "​\n",
        "  relative to the total number of samples in\n",
        "𝐷\n",
        "D."
      ],
      "metadata": {
        "id": "Ub-Em0GyBA4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the difference between Gini Impurity and Entropy\t?"
      ],
      "metadata": {
        "id": "_crUdb7RBBhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gini Impurity and Entropy are both impurity measures used in Decision Trees for classification tasks, helping to evaluate the quality of a split. While they serve the same purpose (measuring how mixed the classes are in a dataset), they are calculated differently and may lead to slightly different splits in some cases. Here's a comparison between the two:\n",
        "\n",
        "1. Mathematical Formula:\n",
        "Gini Impurity:\n",
        "\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini(D)=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes in the target variable.\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples belonging to class\n",
        "𝑖\n",
        "i in the node.\n",
        "\n",
        "Entropy:\n",
        "\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝑝\n",
        "𝑖\n",
        ")\n",
        "Entropy(D)=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " (p\n",
        "i\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes in the target variable.\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of samples belonging to class\n",
        "𝑖\n",
        "i in the node.\n",
        "\n",
        "2. Range of Values:\n",
        "Gini Impurity:\n",
        "\n",
        "Ranges from 0 to 1.\n",
        "\n",
        "0 indicates perfect purity (all samples in the node belong to one class).\n",
        "\n",
        "1 is the maximum impurity (classes are evenly distributed).\n",
        "\n",
        "Entropy:\n",
        "\n",
        "Ranges from 0 to\n",
        "log\n",
        "⁡\n",
        "2\n",
        "(\n",
        "𝐶\n",
        ")\n",
        "log\n",
        "2\n",
        "​\n",
        " (C), where\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "\n",
        "0 indicates perfect purity (all samples in the node belong to one class).\n",
        "\n",
        "The maximum entropy occurs when the classes are perfectly mixed. For binary classification, it would be 1 (when the classes are evenly distributed).\n",
        "\n",
        "3. Interpretation:\n",
        "Gini Impurity:\n",
        "\n",
        "Focuses on the probability of misclassification. If you randomly pick two samples from the dataset, the Gini Impurity represents the likelihood that they belong to different classes.\n",
        "\n",
        "Lower Gini values indicate a node is more pure (better for classification).\n",
        "\n",
        "Entropy:\n",
        "\n",
        "Measures the amount of uncertainty or disorder in the dataset. A higher entropy means more uncertainty about class membership.\n",
        "\n",
        "Lower entropy means the node has more homogeneous samples (more certain about classification).\n",
        "\n",
        "4. Computation and Behavior:\n",
        "Gini Impurity:\n",
        "\n",
        "Is computationally faster than entropy since it does not involve logarithms.\n",
        "\n",
        "It has a more biased tendency towards splitting the dataset into larger homogenous groups.\n",
        "\n",
        "Entropy:\n",
        "\n",
        "More sensitive to the distribution of class probabilities than Gini, especially when classes are unevenly distributed. This makes entropy more sensitive to small changes in the dataset.\n",
        "\n",
        "Tends to give more balanced splits than Gini when classes are mixed.\n",
        "\n",
        "5. Preference in Practice:\n",
        "Gini Impurity:\n",
        "\n",
        "More commonly used in practical implementations of Decision Trees, especially in libraries like scikit-learn.\n",
        "\n",
        "It is often chosen due to its simplicity and slightly faster computation.\n",
        "\n",
        "Entropy:\n",
        "\n",
        "Less commonly used in practice compared to Gini Impurity but is sometimes preferred when the exact reduction in disorder (uncertainty) is more critical.\n",
        "\n",
        "6. Impact on Splits:\n",
        "While both Gini and Entropy often lead to similar results in practice, Entropy may sometimes result in splits that are more balanced (more evenly distributed), whereas Gini tends to make splits that are more strongly focused on purer subgroups."
      ],
      "metadata": {
        "id": "4ZmHoC96BFR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What is the mathematical explanation behind Decision Trees\t?"
      ],
      "metadata": {
        "id": "FlYg9GWCBKDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mathematical Explanation of Decision Trees\n",
        "A Decision Tree is a supervised machine learning model used for both classification and regression tasks. It recursively partitions the feature space into regions that are as homogeneous as possible with respect to the target variable. Here’s a mathematical breakdown of how Decision Trees work, focusing on the splitting criterion, tree structure, and decision-making process:\n",
        "\n",
        "1. Tree Structure\n",
        "A Decision Tree consists of:\n",
        "\n",
        "Nodes: Represent decisions or tests based on features.\n",
        "\n",
        "Root node: The topmost node that represents the entire dataset.\n",
        "\n",
        "Internal nodes: Nodes that represent decisions based on features, splitting the data.\n",
        "\n",
        "Leaf nodes: The final nodes that represent the predicted class (in classification) or value (in regression).\n",
        "\n",
        "Edges/Branches: Represent the outcome of a feature test that leads to further nodes or leaf nodes.\n",
        "\n",
        "2. Goal of a Decision Tree\n",
        "The main goal is to minimize the impurity or uncertainty of the dataset at each split and to predict the output at the leaf node (class label or value).\n",
        "\n",
        "3. Splitting Criterion\n",
        "At each node, the Decision Tree uses a splitting criterion to decide how to divide the data into subsets. Common criteria include Gini Impurity and Entropy for classification, and Variance Reduction for regression. These criteria help in deciding the best feature and threshold to split the data.\n",
        "\n",
        "3.1 Classification (Gini Impurity / Entropy)\n",
        "For binary classification, the splitting criterion is designed to maximize the information gain (in the case of entropy) or minimize the impurity (in the case of Gini).\n",
        "\n",
        "Gini Impurity: The Gini impurity for a dataset\n",
        "𝐷\n",
        "D is calculated as:\n",
        "\n",
        "𝐺\n",
        "𝑖\n",
        "𝑛\n",
        "𝑖\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "1\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "2\n",
        "Gini(D)=1−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "2\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the probability of class\n",
        "𝑖\n",
        "i in the dataset\n",
        "𝐷\n",
        "D.\n",
        "\n",
        "Entropy: The entropy of dataset\n",
        "𝐷\n",
        "D is calculated as:\n",
        "\n",
        "𝐸\n",
        "𝑛\n",
        "𝑡\n",
        "𝑟\n",
        "𝑜\n",
        "𝑝\n",
        "𝑦\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "−\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝐶\n",
        "𝑝\n",
        "𝑖\n",
        "log\n",
        "⁡\n",
        "2\n",
        "𝑝\n",
        "𝑖\n",
        "Entropy(D)=−\n",
        "i=1\n",
        "∑\n",
        "C\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        " log\n",
        "2\n",
        "​\n",
        " p\n",
        "i\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "𝐶\n",
        "C is the number of classes.\n",
        "\n",
        "𝑝\n",
        "𝑖\n",
        "p\n",
        "i\n",
        "​\n",
        "  is the proportion of class\n",
        "𝑖\n",
        "i in the dataset\n",
        "𝐷\n",
        "D.\n",
        "\n",
        "Information Gain (for entropy) is used to evaluate how much the uncertainty is reduced after a split:\n",
        "\n",
        "Information Gain\n",
        "(\n",
        "𝐷\n",
        ",\n",
        "𝐴\n",
        ")\n",
        "=\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "−\n",
        "∑\n",
        "𝑣\n",
        "∈\n",
        "𝑉\n",
        "𝑎\n",
        "𝑙\n",
        "𝑢\n",
        "𝑒\n",
        "𝑠\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "×\n",
        "Entropy\n",
        "(\n",
        "𝐷\n",
        "𝑣\n",
        ")\n",
        "Information Gain(D,A)=Entropy(D)−\n",
        "v∈Values(A)\n",
        "∑\n",
        "​\n",
        "  \n",
        "∣D∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        " ×Entropy(D\n",
        "v\n",
        "​\n",
        " )\n",
        "Where:\n",
        "\n",
        "𝐴\n",
        "A is the attribute used for the split.\n",
        "\n",
        "𝐷\n",
        "𝑣\n",
        "D\n",
        "v\n",
        "​\n",
        "  is the subset of data where the value of attribute\n",
        "𝐴\n",
        "A is\n",
        "𝑣\n",
        "v.\n",
        "\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "∣D∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        "  is the weight of the subset relative to the entire dataset.\n",
        "\n",
        "For Gini Impurity, the split is chosen that minimizes the Gini score, aiming for the purest possible child nodes.\n",
        "\n",
        "3.2 Regression (Variance Reduction)\n",
        "In regression, the goal is to split the data in a way that minimizes the variance within each subset. The variance of a dataset\n",
        "𝐷\n",
        "D is calculated as:\n",
        "\n",
        "𝑉\n",
        "𝑎\n",
        "𝑟\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "‾\n",
        ")\n",
        "2\n",
        "Var(D)=\n",
        "∣D∣\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "∣D∣\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "Where:\n",
        "\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "i\n",
        "​\n",
        "  is the target value for each data point.\n",
        "\n",
        "𝑦\n",
        "‾\n",
        "y\n",
        "​\n",
        "  is the mean of the target values in the dataset.\n",
        "\n",
        "Splitting Criterion: To select the best split, we aim to reduce the variance of the target values in the child nodes after the split.\n",
        "\n",
        "Variance Reduction\n",
        "=\n",
        "Var\n",
        "(\n",
        "𝐷\n",
        ")\n",
        "−\n",
        "∑\n",
        "𝑣\n",
        "∈\n",
        "𝑉\n",
        "𝑎\n",
        "𝑙\n",
        "𝑢\n",
        "𝑒\n",
        "𝑠\n",
        "(\n",
        "𝐴\n",
        ")\n",
        "∣\n",
        "𝐷\n",
        "𝑣\n",
        "∣\n",
        "∣\n",
        "𝐷\n",
        "∣\n",
        "×\n",
        "Var\n",
        "(\n",
        "𝐷\n",
        "𝑣\n",
        ")\n",
        "Variance Reduction=Var(D)−\n",
        "v∈Values(A)\n",
        "∑\n",
        "​\n",
        "  \n",
        "∣D∣\n",
        "∣D\n",
        "v\n",
        "​\n",
        " ∣\n",
        "​\n",
        " ×Var(D\n",
        "v\n",
        "​\n",
        " )\n",
        "4. Recursive Process (Top-Down Approach)\n",
        "Step 1: Start at the root node.\n",
        "\n",
        "The dataset is used to calculate the chosen impurity measure (e.g., Gini or Entropy) for the whole dataset.\n",
        "\n",
        "Step 2: Evaluate possible splits.\n",
        "\n",
        "For each feature, calculate the impurity or variance for each possible split (threshold). The split with the best (lowest) impurity or highest information gain is selected.\n",
        "\n",
        "Step 3: Apply the split.\n",
        "\n",
        "Divide the dataset into two subsets based on the chosen split. These subsets become the child nodes.\n",
        "\n",
        "Step 4: Repeat the process recursively for each child node until a stopping criterion is met, such as:\n",
        "\n",
        "Maximum depth of the tree.\n",
        "\n",
        "Minimum number of samples required to split.\n",
        "\n",
        "Impurity reduction becomes very small (or zero)"
      ],
      "metadata": {
        "id": "5XYkAUewBN1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Pre-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "fKOUfoS2BTXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Pruning in Decision Trees\n",
        "Pre-pruning, also known as early stopping or cost-complexity pruning, refers to the process of stopping the growth of the Decision Tree before it fully develops. This is done by setting certain conditions or criteria that prevent the tree from growing beyond a certain point. The goal of pre-pruning is to avoid overfitting by limiting the complexity of the model early on, thus improving its generalization ability.\n",
        "\n",
        "How Pre-Pruning Works\n",
        "During the tree-building process, pre-pruning can be applied by imposing constraints on the tree’s growth. These constraints typically involve:\n",
        "\n",
        "Maximum Depth:\n",
        "\n",
        "Pre-pruning stops further splitting when the tree reaches a specified maximum depth. This ensures that the tree doesn’t become too deep and complex, potentially capturing noise in the data.\n",
        "\n",
        "Minimum Samples per Split:\n",
        "\n",
        "A node will only be split if there are at least a minimum number of samples in the node. If a node has fewer than the specified number of samples, it is not split further and becomes a leaf node.\n",
        "\n",
        "Minimum Samples per Leaf:\n",
        "\n",
        "After a split, each leaf node must contain at least a minimum number of samples. If a split results in a leaf with fewer samples than the specified threshold, the split is not performed.\n",
        "\n",
        "Maximum Number of Leaf Nodes:\n",
        "\n",
        "A constraint on the number of leaf nodes that the tree can have. Once the specified number of leaf nodes is reached, no further splits are allowed."
      ],
      "metadata": {
        "id": "bL1io65BBaz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is Post-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "RbgJ2lXIBe4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post-Pruning in Decision Trees\n",
        "Post-pruning (also known as cost-complexity pruning or pruning after tree creation) is a technique used to simplify a fully grown decision tree by removing branches (subtrees) that have little predictive power, thereby reducing overfitting. Unlike pre-pruning, which stops the tree from growing too deep during its construction, post-pruning involves growing the tree to its full extent and then pruning it by removing nodes or subtrees that don't contribute much to the model’s performance.\n",
        "\n",
        "How Post-Pruning Works\n",
        "In post-pruning, the process generally follows these steps:\n",
        "\n",
        "Fully Grow the Tree:\n",
        "\n",
        "First, the decision tree is allowed to grow without any restrictions. This can result in a very deep tree with many nodes, which may fit the training data perfectly but overfit the data by capturing noise.\n",
        "\n",
        "Evaluate Subtrees:\n",
        "\n",
        "The tree is then evaluated, and each node or subtree is assessed to determine its importance. This is typically done by evaluating the cost-complexity of a subtree, which is a measure of the trade-off between the tree's complexity (its size) and its performance (its ability to fit the data).\n",
        "\n",
        "Prune Unnecessary Branches:\n",
        "\n",
        "Nodes or subtrees that do not significantly improve the predictive performance (often measured by a validation set or cross-validation) are removed. The idea is to simplify the tree without sacrificing too much accuracy.\n",
        "\n",
        "Re-evaluate the Tree:\n",
        "\n",
        "After pruning, the tree is re-evaluated to check its accuracy. If further pruning can improve performance, it is applied again until an optimal level of complexity is reached.\n",
        "\n",
        "How Post-Pruning Works Mathematically\n",
        "Post-pruning is often based on the cost-complexity pruning framework, which considers two factors:\n",
        "\n",
        "Error Rate (Empirical Error): This measures how well the tree fits the training data.\n",
        "\n",
        "Tree Size: The complexity of the tree, which increases as the tree grows deeper.\n",
        "\n",
        "The cost-complexity measure for a subtree\n",
        "𝑇\n",
        "T is typically defined as:\n",
        "\n",
        "𝐶\n",
        "𝛼\n",
        "(\n",
        "𝑇\n",
        ")\n",
        "=\n",
        "𝑅\n",
        "(\n",
        "𝑇\n",
        ")\n",
        "+\n",
        "𝛼\n",
        "⋅\n",
        "∣\n",
        "𝑇\n",
        "∣\n",
        "C\n",
        "α\n",
        "​\n",
        " (T)=R(T)+α⋅∣T∣\n",
        "Where:\n",
        "\n",
        "𝑅\n",
        "(\n",
        "𝑇\n",
        ")\n",
        "R(T) is the empirical error (often measured as the misclassification rate or the sum of squared errors for regression).\n",
        "\n",
        "∣\n",
        "𝑇\n",
        "∣\n",
        "∣T∣ is the size of the tree, which could be the number of terminal nodes (leaf nodes) or the total number of nodes.\n",
        "\n",
        "𝛼\n",
        "α is a penalty parameter that controls the trade-off between complexity and error. As\n",
        "𝛼\n",
        "α increases, the model is penalized more for complexity, leading to more aggressive pruning."
      ],
      "metadata": {
        "id": "diV_JVjXBwDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the difference between Pre-Pruning and Post-Pruning\t?"
      ],
      "metadata": {
        "id": "MIpXUiZ7Bwkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Difference Between Pre-Pruning and Post-Pruning in Decision Trees\n",
        "Pre-pruning and post-pruning are two techniques used to control the complexity of decision trees and prevent overfitting. While they both aim to improve the generalization of the model, they differ in when and how pruning is applied during the tree-building process.\n",
        "\n",
        "Here’s a detailed comparison:\n",
        "\n",
        "1. Timing of Pruning\n",
        "Pre-Pruning:\n",
        "\n",
        "Pruning occurs during the tree-building process.\n",
        "\n",
        "The tree is stopped from growing further based on certain constraints (e.g., maximum depth, minimum samples per leaf, minimum samples per split).\n",
        "\n",
        "If the conditions are met, no further splits are made, and the tree is \"pruned\" or limited before it grows too complex.\n",
        "\n",
        "Post-Pruning:\n",
        "\n",
        "Pruning occurs after the tree has been fully grown.\n",
        "\n",
        "The tree is allowed to grow to its maximum size (deep and complex), and then nodes or subtrees that are not useful are pruned.\n",
        "\n",
        "The goal is to remove branches that do not contribute significantly to predictive power, improving the model's generalization.\n",
        "\n",
        "2. Tree Growth\n",
        "Pre-Pruning:\n",
        "\n",
        "The tree's growth is restricted from the beginning by setting hyperparameters that limit complexity.\n",
        "\n",
        "It can stop the tree from splitting too early, resulting in a smaller, potentially simpler tree.\n",
        "\n",
        "Post-Pruning:\n",
        "\n",
        "The tree grows fully without constraints, allowing it to explore all potential splits.\n",
        "\n",
        "The model then evaluates the tree's performance and prunes unimportant branches afterward.\n",
        "\n",
        "3. Control Over Tree Complexity\n",
        "Pre-Pruning:\n",
        "\n",
        "Provides more control over the initial size and complexity of the tree because limits are set upfront (e.g., depth, minimum samples per split).\n",
        "\n",
        "It may stop the tree from capturing important patterns in the data if the constraints are too strict (underfitting).\n",
        "\n",
        "Post-Pruning:\n",
        "\n",
        "Allows the tree to capture as many patterns as possible during its growth phase.\n",
        "\n",
        "The complexity is then reduced by removing unimportant branches, resulting in a model that may capture the important features of the data without overfitting."
      ],
      "metadata": {
        "id": "35nYc_WSB5iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is a Decision Tree Regressor?"
      ],
      "metadata": {
        "id": "D36SuJmQB9Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree Regressor is a type of machine learning algorithm used for regression tasks, where the goal is to predict a continuous numeric value. It is a non-linear model that works by splitting the data into subsets based on feature values, in a hierarchical manner, to make predictions for the target variable.\n",
        "\n",
        "How It Works:\n",
        "Splitting: The decision tree regressor works by repeatedly splitting the dataset into smaller subsets based on feature values. Each node of the tree represents a decision based on a particular feature.\n",
        "\n",
        "Leaf Nodes: At the leaf nodes of the tree, the final prediction is made. In the case of regression, the prediction is typically the mean of the target values of the data points that fall into that particular leaf node.\n",
        "\n",
        "Recursive Process: The tree is built recursively, where at each node, the algorithm selects the best feature and value to split the data based on some impurity measure (like mean squared error (MSE) or variance reduction).\n",
        "\n",
        "Stopping Criterion: The tree continues to grow until a predefined stopping criterion is met. This could be a maximum tree depth, a minimum number of data points required at a node, or when the data within a node is sufficiently homogeneous.\n",
        "\n",
        "Key Characteristics:\n",
        "Non-Linear Model: Unlike linear regression, which assumes a linear relationship between input features and the target, decision trees do not make this assumption. They can handle complex, non-linear relationships.\n",
        "\n",
        "Interpretability: Decision trees are easy to visualize and interpret, as they provide a clear path from input features to the prediction. You can easily trace how a prediction was made by following the decisions made at each node.\n",
        "\n",
        "Handling of Different Data Types: Decision trees can handle both numerical and categorical data, making them versatile for a wide range of problems.\n",
        "\n",
        "Overfitting: One of the challenges with decision trees is that they can easily overfit the training data, especially if the tree grows too deep and becomes too specific to the data. This can be controlled using pruning techniques (e.g., pre-pruning and post-pruning), or by setting hyperparameters like max_depth."
      ],
      "metadata": {
        "id": "4z3a6Wt6B-e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What are the advantages and disadvantages of Decision Trees?"
      ],
      "metadata": {
        "id": "ip5cQmJ8CDGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages and Disadvantages of Decision Trees\n",
        "Advantages:\n",
        "\n",
        "Easy to Interpret and Visualize:\n",
        "\n",
        "Decision trees are highly interpretable. The model is easy to understand and can be visualized as a flowchart, where each internal node represents a decision based on a feature, and each leaf node gives the predicted value or class.\n",
        "\n",
        "This makes decision trees ideal for problems where interpretability is essential, such as in healthcare or finance.\n",
        "\n",
        "Non-linear Relationships:\n",
        "\n",
        "Unlike linear regression, decision trees do not assume a linear relationship between the features and the target variable. This makes them capable of modeling complex, non-linear relationships in the data.\n",
        "\n",
        "Works with Both Categorical and Numerical Data:\n",
        "\n",
        "Decision trees can handle both numerical and categorical data without needing additional transformation. This makes them versatile and applicable to a wide variety of problems.\n",
        "\n",
        "No Need for Feature Scaling:\n",
        "\n",
        "Decision trees do not require normalization or standardization of features, unlike many other algorithms (e.g., KNN, SVM). The tree construction process is not affected by the scale of the features.\n",
        "Disadvantages:\n",
        "\n",
        "Overfitting:\n",
        "\n",
        "Decision trees are prone to overfitting, especially when they are deep. They tend to fit the training data very closely, which can result in poor generalization to new, unseen data. Overfitting can be controlled with techniques like pruning, setting a maximum depth, or limiting the minimum samples required to split a node.\n",
        "\n",
        "Instability:\n",
        "\n",
        "Small changes in the data can lead to a large change in the structure of the tree. This makes decision trees highly sensitive to variations in the dataset and can result in unstable models, especially when the training set is small.\n",
        "\n",
        "Bias Toward Features with More Levels:\n",
        "\n",
        "Decision trees can be biased toward features that have more categories (in the case of categorical data). For example, if one feature has many possible values, it may dominate the tree-building process, even if other features are more informative.\n",
        "\n",
        "Poor Performance on Unstructured Data:\n",
        "\n",
        "Decision trees are not the best choice for unstructured data like text, images, or audio. Models like neural networks or support vector machines (SVMs) are better suited for such data types."
      ],
      "metadata": {
        "id": "ufDf7L4XCMqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. How does a Decision Tree handle missing values?"
      ],
      "metadata": {
        "id": "UdKpPWcjCQhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree can handle missing values in several ways, depending on the specific algorithm or framework being used. Here's a breakdown of the common techniques used to handle missing values in Decision Trees:\n",
        "\n",
        "1. Surrogate Splits:\n",
        "What it is: Surrogate splits are alternative splits that a decision tree can use when a feature has a missing value for a particular observation. In the case of missing data for a primary feature used for a split, the algorithm looks for another feature that could serve as a substitute to make the decision.\n",
        "\n",
        "How it works: If a data point has a missing value for a feature used for splitting, the tree uses another feature that behaves similarly to the missing feature in terms of predicting the target variable.\n",
        "\n",
        "Example: If a tree splits based on \"age\" and a record has a missing \"age\" value, the tree could use a surrogate split based on \"income\" or another correlated feature to make a decision.\n",
        "\n",
        "2. Imputation Before Building the Tree:\n",
        "What it is: Missing values can be imputed (filled in) before the tree-building process. Common techniques for imputation include filling missing values with the mean, median, or mode of the respective feature, or using more sophisticated imputation techniques such as k-nearest neighbors (KNN) imputation.\n",
        "\n",
        "How it works: The missing values are replaced with estimated values before the tree construction begins, so the tree doesn't need to handle them during the learning process.\n",
        "\n",
        "Example: If the \"age\" feature has missing values, the algorithm might replace them with the mean or median age of the available records.\n",
        "\n",
        "3. Assigning Missing Values to a Separate Category:\n",
        "What it is: In some cases, missing values are treated as a separate category or class in categorical features. This can be done for both categorical and numerical features.\n",
        "\n",
        "How it works: The missing values are not imputed or ignored but instead are explicitly labeled as a separate category and treated as a valid value during the tree-building process. This way, the decision tree can learn to make a decision based on whether the value is missing or not.\n",
        "\n",
        "Example: If the \"education level\" feature has missing values, the tree might create an additional category called \"missing\" to split the data based on the presence or absence of an education level."
      ],
      "metadata": {
        "id": "CtE3gZ1cCVW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How does a Decision Tree handle categorical features?"
      ],
      "metadata": {
        "id": "n_09sJARCX3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees can handle categorical features (features with discrete values, such as \"yes/no\", \"low/high\", \"red/blue/green\", etc.) by using specific methods to split the data at each decision node. Here's how they work with categorical data:\n",
        "\n",
        "1. Splitting on Categorical Features:\n",
        "Binary Categorical Features:\n",
        "\n",
        "If a categorical feature has two possible values (binary), such as \"Yes\" or \"No\", the Decision Tree can split the dataset based on those two categories.\n",
        "\n",
        "Example: For a \"Has_Credit_Card\" feature, the tree might split the data into two branches: one for \"Yes\" and one for \"No\".\n",
        "\n",
        "Multiclass Categorical Features:\n",
        "\n",
        "If the categorical feature has more than two possible values (e.g., \"Red\", \"Blue\", \"Green\"), the Decision Tree can either:\n",
        "\n",
        "Create multiple branches: Each possible value of the categorical feature gets its own branch.\n",
        "\n",
        "Use one-hot encoding (in some implementations): One-hot encoding transforms the categorical variable into several binary features (e.g., for \"Color\" with categories \"Red\", \"Blue\", \"Green\", it will create three binary features \"Is_Red\", \"Is_Blue\", and \"Is_Green\")."
      ],
      "metadata": {
        "id": "oG_8wm8eCdv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What are some real-world applications of Decision Trees?\n"
      ],
      "metadata": {
        "id": "r1Seoux_CifL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees are widely used in various industries due to their simplicity, interpretability, and effectiveness in handling both classification and regression tasks. Here are some real-world applications:\n",
        "\n",
        "1. Healthcare\n",
        "Disease Diagnosis: Decision trees are used to predict the likelihood of diseases based on patient symptoms and medical histories. For example, they can help in diagnosing conditions like diabetes, heart disease, or cancer by analyzing patient data and identifying key risk factors.\n",
        "\n",
        "Example: A decision tree could predict whether a patient has diabetes based on features like age, BMI, blood sugar levels, and family history.\n",
        "\n",
        "Medical Decision Support: They assist healthcare professionals in decision-making by suggesting treatment options based on patient characteristics.\n",
        "\n",
        "Example: A decision tree could recommend treatment options (e.g., chemotherapy, radiation) for cancer patients based on tumor size, age, and other clinical factors.\n",
        "\n",
        "2. Finance\n",
        "Credit Scoring: Financial institutions use decision trees to evaluate the creditworthiness of borrowers. By analyzing past loan repayment histories, income levels, and other factors, decision trees can classify applicants into high-risk or low-risk categories.\n",
        "\n",
        "Example: A decision tree model might predict whether a loan applicant will default on their loan based on credit score, income, and previous debts.\n",
        "\n",
        "Fraud Detection: Decision trees are used to detect fraudulent transactions by analyzing patterns in transaction data, such as unusual spending behavior or account access from unfamiliar locations.\n",
        "\n",
        "Example: A decision tree might flag a credit card transaction as fraudulent based on factors like transaction size, location, and time.\n",
        "\n",
        "3. Marketing and Retail\n",
        "Customer Segmentation: Decision trees help businesses segment their customers based on various features, such as purchasing behavior, demographics, and online activity. This segmentation helps in targeting customers with personalized marketing campaigns.\n",
        "\n",
        "Example: A decision tree might classify customers into different segments (e.g., loyal customers, occasional buyers, and one-time visitors) based on their spending habits.\n",
        "\n",
        "Churn Prediction: In subscription-based businesses (e.g., telecom, SaaS), decision trees are used to predict customer churn. By analyzing historical data on customer behavior, decision trees can identify factors that increase the likelihood of customers canceling their service.\n",
        "\n",
        "Example: A decision tree might predict whether a customer is likely to cancel their subscription based on features like usage frequency, customer support calls, and account age.\n",
        "\n",
        "4. E-commerce\n",
        "Recommendation Systems: Decision trees are often used in recommendation engines to suggest products based on past purchasing behavior and customer preferences.\n",
        "\n",
        "Example: A decision tree might recommend products to customers based on their browsing history, similar users' purchasing patterns, or seasonal trends.\n",
        "\n",
        "Price Optimization: E-commerce platforms use decision trees to optimize pricing strategies by analyzing the impact of various factors (e.g., competition, demand, inventory) on sales.\n",
        "\n",
        "Example: A decision tree might recommend the optimal price for a product based on historical sales data, competitor prices, and customer demand.\n",
        "\n",
        "5. Manufacturing and Supply Chain\n",
        "Predictive Maintenance: In industrial settings, decision trees are used to predict equipment failures by analyzing sensor data and maintenance records. This helps businesses perform maintenance before a breakdown occurs, reducing downtime and costs.\n",
        "\n",
        "Example: A decision tree could predict when a machine is likely to fail based on factors like temperature, vibration, and usage hours.\n",
        "\n",
        "Supply Chain Optimization: Decision trees are used to optimize inventory levels, predict demand, and identify the best suppliers based on historical data and business requirements.\n",
        "\n",
        "Example: A decision tree might help a retailer predict product demand during holidays and recommend optimal stock levels.\n",
        "\n",
        "6. Sports Analytics\n",
        "Player Performance Prediction: Decision trees are used to predict player performance or outcomes of sports events by analyzing factors such as player stats, team composition, and historical performance.\n",
        "\n",
        "Example: A decision tree could predict the likelihood of a football player scoring a goal based on past performance, team strength, and match conditions.\n",
        "\n",
        "Match Outcome Prediction: Decision trees can predict the outcome of sports games by analyzing team performance data, player stats, and other variables like home/away games, weather, and injuries.\n",
        "\n",
        "Example: A decision tree might predict the outcome of a football match by analyzing factors like team rankings, average goals scored, and recent form."
      ],
      "metadata": {
        "id": "nA7G7PMeCnHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy*"
      ],
      "metadata": {
        "id": "gQBLcMu9Cqbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be_jMTkHCwDo",
        "outputId": "53cbc965-6a46-468a-da28-e1d6873c4e87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the\n",
        "feature importances."
      ],
      "metadata": {
        "id": "1Lqdk798C_Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Gini Impurity as the criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print the feature importances\n",
        "print('Feature Importances:')\n",
        "for feature, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f'{feature}: {importance:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlSXmFuQDEX-",
        "outputId": "675f0556-3a52-4826-ed58-8730397e1141"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.8933\n",
            "petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the\n",
        "model accuracy."
      ],
      "metadata": {
        "id": "kXp4x60rDGZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with Entropy as the criterion\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vci5JDfDK_k",
        "outputId": "b18044e6-6844-483b-daea-5305efd4a7e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean\n",
        "Squared Error (MSE)."
      ],
      "metadata": {
        "id": "n1ljZQRdDQRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable (house prices)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the MSE\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-vZD2OHDV_x",
        "outputId": "839b2152-8f88-4052-9296-17d04ac7c9ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.5280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz"
      ],
      "metadata": {
        "id": "jiEK8Z5QDXct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the tree using Graphviz\n",
        "dot_data = export_graphviz(clf, out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_decision_tree\")  # Saves the visualization as a file\n",
        "\n",
        "# Display the tree\n",
        "graph.view()  # This will open the tree visualization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UgmD3BETDbub",
        "outputId": "8b5c115d-2114-4fa1-bf77-e5c7d3693ac5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iris_decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its\n",
        "accuracy with a fully grown tree."
      ],
      "metadata": {
        "id": "f9KGVP2PDfmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train a Decision Tree Classifier with maximum depth of 3\n",
        "clf_max_depth_3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_max_depth_3.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the tree with max depth 3\n",
        "y_pred_max_depth_3 = clf_max_depth_3.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the tree with max depth 3\n",
        "accuracy_max_depth_3 = accuracy_score(y_test, y_pred_max_depth_3)\n",
        "print(f'Accuracy of Decision Tree with max depth 3: {accuracy_max_depth_3 * 100:.2f}%')\n",
        "\n",
        "# Initialize and train a fully grown Decision Tree Classifier (no max depth constraint)\n",
        "clf_full_tree = DecisionTreeClassifier(random_state=42)\n",
        "clf_full_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the fully grown tree\n",
        "y_pred_full_tree = clf_full_tree.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the fully grown tree\n",
        "accuracy_full_tree = accuracy_score(y_test, y_pred_full_tree)\n",
        "print(f'Accuracy of Fully Grown Decision Tree: {accuracy_full_tree * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y5IL6WEDkKQ",
        "outputId": "fd2c29d7-7cbb-4aba-cfe6-f696b9367efe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree with max depth 3: 100.00%\n",
            "Accuracy of Fully Grown Decision Tree: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its\n",
        "accuracy with a default tree."
      ],
      "metadata": {
        "id": "Cycr8j-9DnDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Default Decision Tree\n",
        "default_tree = DecisionTreeClassifier(random_state=42)\n",
        "default_tree.fit(X_train, y_train)\n",
        "default_preds = default_tree.predict(X_test)\n",
        "default_accuracy = accuracy_score(y_test, default_preds)\n",
        "\n",
        "# Decision Tree with min_samples_split=5\n",
        "custom_tree = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "custom_preds = custom_tree.predict(X_test)\n",
        "custom_accuracy = accuracy_score(y_test, custom_preds)\n",
        "\n",
        "# Output comparison\n",
        "print(\"Accuracy of Default Decision Tree:\", default_accuracy)\n",
        "print(\"Accuracy of Decision Tree with min_samples_split=5:\", custom_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqpZ9SRUDqwW",
        "outputId": "99d0efc7-e947-4fd5-cae8-b90246596063"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Default Decision Tree: 1.0\n",
            "Accuracy of Decision Tree with min_samples_split=5: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its\n",
        "accuracy with unscaled data."
      ],
      "metadata": {
        "id": "dVkhiqiWD2jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Train on unscaled data\n",
        "tree_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "tree_unscaled.fit(X_train, y_train)\n",
        "preds_unscaled = tree_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, preds_unscaled)\n",
        "\n",
        "# 2. Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train on scaled data\n",
        "tree_scaled = DecisionTreeClassifier(random_state=42)\n",
        "tree_scaled.fit(X_train_scaled, y_train)\n",
        "preds_scaled = tree_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, preds_scaled)\n",
        "\n",
        "# Output comparison\n",
        "print(\"Accuracy on Unscaled Data:\", accuracy_unscaled)\n",
        "print(\"Accuracy on Scaled Data:\", accuracy_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRo1SphDD9rl",
        "outputId": "a96e7ab4-9f4b-4d97-9142-59438a9afa63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Unscaled Data: 1.0\n",
            "Accuracy on Scaled Data: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass\n",
        "classification."
      ],
      "metadata": {
        "id": "vRWJfUTrEA0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset (multiclass: 3 classes)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# One-vs-Rest wrapper around a Decision Tree\n",
        "ovr_classifier = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = ovr_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy of Decision Tree with One-vs-Rest strategy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq_hqUx0EEUa",
        "outputId": "f2607408-9b7e-41c8-c609-2974ae3b64d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Decision Tree with One-vs-Rest strategy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores."
      ],
      "metadata": {
        "id": "urCvcLi9EJjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better display\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance Score': importances\n",
        "}).sort_values(by='Importance Score', ascending=False)\n",
        "\n",
        "# Display results\n",
        "print(\"Feature Importance Scores:\")\n",
        "print(importance_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro0nr_YEENHz",
        "outputId": "74883dae-d7ff-45dc-93db-ca20a261aefa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "             Feature  Importance Score\n",
            "2  petal length (cm)          0.564056\n",
            "3   petal width (cm)          0.422611\n",
            "0  sepal length (cm)          0.013333\n",
            "1   sepal width (cm)          0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance\n",
        "with an unrestricted tree."
      ],
      "metadata": {
        "id": "3YnaMAbCEXlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Decision Tree Regressor with max_depth=5\n",
        "reg_limited = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "reg_limited.fit(X_train, y_train)\n",
        "preds_limited = reg_limited.predict(X_test)\n",
        "mse_limited = mean_squared_error(y_test, preds_limited)\n",
        "\n",
        "# 2. Decision Tree Regressor with no depth limit\n",
        "reg_unlimited = DecisionTreeRegressor(random_state=42)\n",
        "reg_unlimited.fit(X_train, y_train)\n",
        "preds_unlimited = reg_unlimited.predict(X_test)\n",
        "mse_unlimited = mean_squared_error(y_test, preds_unlimited)\n",
        "\n",
        "# Output comparison\n",
        "print(\"MSE with max_depth=5:\", mse_limited)\n",
        "print(\"MSE with no depth limit:\", mse_unlimited)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPz2JFjgEb95",
        "outputId": "07589cea-60af-4ebc-a55b-91b1d475d111"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with max_depth=5: 0.5210801561811793\n",
            "MSE with no depth limit: 0.5280096503174904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and\n",
        "visualize its effect on accuracy."
      ],
      "metadata": {
        "id": "utyRzrnmEea7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a base Decision Tree to get effective alphas\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "# Train a tree for each alpha\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)\n",
        "\n",
        "# Remove the last tree which is usually just the root\n",
        "clfs = clfs[:-1]\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "# Evaluate accuracy\n",
        "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
        "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, train_scores, marker='o', label='Train Accuracy', drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alphas, test_scores, marker='o', label='Test Accuracy', drawstyle=\"steps-post\")\n",
        "plt.xlabel(\"ccp_alpha (pruning strength)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Effect of Cost Complexity Pruning on Decision Tree Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "oGxbqxJJEioY",
        "outputId": "82199674-cf67-40d7-dc45-f88924002b36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision,\n",
        "Recall, and F1-Score."
      ],
      "metadata": {
        "id": "wJuNpmFUEoMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate with precision, recall, and F1-score\n",
        "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPkMOgdDEtTe",
        "outputId": "3696a80a-e301-415c-98aa-562e40016645"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        19\n",
            "  versicolor       1.00      1.00      1.00        13\n",
            "   virginica       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn."
      ],
      "metadata": {
        "id": "cZtPOCleEwti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names,\n",
        "            yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix of Decision Tree Classifier')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "-ihm8taMEyqo",
        "outputId": "2072ff59-e21d-4a5b-e1ea-0890b68cfa21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGGCAYAAABolMvdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAX/JJREFUeJzt3XdYFFfbBvB7QViQrnQLICJFKfaCRo0kiIaoxBqN2BNLLFhJREGj2DVRozFGMZZEY03UYMHeK7ZYESRGUEEUQQWE8/3hx76uLMgCMrDev1xzXe6ZM2eeXSbLwykzMiGEABEREZEG0JI6ACIiIqKSwsSGiIiINAYTGyIiItIYTGyIiIhIYzCxISIiIo3BxIaIiIg0BhMbIiIi0hhMbIiIiEhjMLEhIiIijcHERoPdvHkTH3/8MUxMTCCTybB169YSbT8uLg4ymQwREREl2m551qpVK7Rq1arUz/vy5UuMGzcO1apVg5aWFjp27FjqMRRWaGgoZDKZWsfwWisZZeFztLe3R58+fZTKVH1XRUREQCaTIS4uTpI4qfxiYvOOxcTE4Msvv0SNGjWgp6cHY2NjeHt74/vvv8fz58/f6bkDAwNx6dIlTJs2DatXr0aDBg3e6flKU58+fSCTyWBsbKzyc7x58yZkMhlkMhnmzJmjdvv37t1DaGgooqOjSyDad2/FihWYPXs2OnfujFWrVmHUqFH51m3VqpXis9HS0oKxsTGcnZ3xxRdfYM+ePaUYddl24MABxef0tq0sOHDgAAICAmBtbQ1dXV1YWlrC398fmzdvljq0t9Lk7yoqfRWkDkCT7dixA126dIFcLkfv3r1Rp04dZGZm4siRIxg7diyuXLmCZcuWvZNzP3/+HMePH8e3336LYcOGvZNz2NnZ4fnz59DR0Xkn7b9NhQoV8OzZM/z111/o2rWr0r61a9dCT08PL168KFLb9+7dQ1hYGOzt7eHl5VXo43bv3l2k8xXXvn37UKVKFcyfP79Q9atWrYrw8HAAQHp6Om7duoXNmzdjzZo16Nq1K9asWfPOfq4TJ07EhAkT1DpGimvN1dUVq1evVioLDg6GoaEhvv3221KLozAmT56MKVOmwMnJCV9++SXs7OyQnJyMnTt34rPPPsPatWvx+eefSx0mAOD69evQ0vrf39T5fVd98cUX6N69O+RyuRRhUjnGxOYdiY2NRffu3WFnZ4d9+/bBxsZGsW/o0KG4desWduzY8c7O//DhQwCAqanpOzuHTCaDnp7eO2v/beRyOby9vfHbb7/lSWzWrVuH9u3bY9OmTaUSy7Nnz1CxYkXo6uqWyvne9ODBA7V+1iYmJujVq5dS2YwZMzB8+HD8+OOPsLe3x8yZM0s4ylcqVKiAChXU++qR4lqzsrJS+RmZm5vnKX9dTk4OMjMzSy3ejRs3YsqUKejcuTPWrVunlPyNHTsWu3btQlZWVqnEUhhvJir5fVdpa2tDW1u7xM6bnp4OAwODEmuPyjBB78RXX30lAIijR48Wqn5WVpaYMmWKqFGjhtDV1RV2dnYiODhYvHjxQqmenZ2daN++vTh8+LBo2LChkMvlwsHBQaxatUpRZ/LkyQKA0mZnZyeEECIwMFDx79flHvO63bt3C29vb2FiYiIMDAxErVq1RHBwsGJ/bGysACBWrlypdFxUVJRo3ry5qFixojAxMRGffvqp+Oeff1Se7+bNmyIwMFCYmJgIY2Nj0adPH5Genv7WzyswMFAYGBiIiIgIIZfLRUpKimLfqVOnBACxadMmAUDMnj1bsS85OVmMHj1a1KlTRxgYGAgjIyPRtm1bER0draizf//+PJ/f6++zZcuWonbt2uLMmTOiRYsWQl9fX4wYMUKxr2XLloq2evfuLeRyeZ73//HHHwtTU1Px33//Ffg+09LSRFBQkKhatarQ1dUVtWrVErNnzxY5OTlCiP/9DN7c9u/fn2+bufGr8vLlS+Hm5iYqVqwoHj9+rLRv9erVol69ekJPT0+YmZmJbt26ifj4+DxtnDhxQvj5+QlTU1NRsWJF4e7uLhYsWKDYX96utdfVrl1b6ecrhBAAxNChQ8WaNWuEm5ubqFChgtiyZYsQQoi7d++Kvn37CktLS6Grqyvc3NzEL7/8kqfdFy9eiEmTJglHR0ehq6srqlatKsaOHZvn/39VXFxcRKVKlURqaupb66r6HC9cuCACAwOFg4ODkMvlwsrKSvTt21ckJSUpHZuamipGjBgh7OzshK6urrCwsBA+Pj7i7Nmzijo3btwQAQEBwsrKSsjlclGlShXRrVs3pWvJzs5OBAYGCiEK/q5auXKlACBiY2OV4ti5c6fiZ25oaCjatWsnLl++rFQn9/vh1q1bws/PTxgaGooOHTq89fMhzcAem3fkr7/+Qo0aNdCsWbNC1R8wYABWrVqFzp07Y/To0Th58iTCw8Nx9epVbNmyRanurVu30LlzZ/Tv3x+BgYFYsWIF+vTpg/r166N27doICAiAqakpRo0ahR49eqBdu3YwNDRUK/4rV67gk08+gYeHB6ZMmQK5XI5bt27h6NGjBR63d+9e+Pn5oUaNGggNDcXz58+xcOFCeHt749y5c7C3t1eq37VrVzg4OCA8PBznzp3D8uXLYWlpWejegoCAAHz11VfYvHkz+vXrB+BVb42Liwvq1auXp/7t27exdetWdOnSBQ4ODrh//z5++ukntGzZEv/88w9sbW3h6uqKKVOmYNKkSRg0aBBatGgBAEo/y+TkZPj5+aF79+7o1asXrKysVMb3/fffY9++fQgMDMTx48ehra2Nn376Cbt378bq1atha2ub73sTQuDTTz/F/v370b9/f3h5eWHXrl0YO3Ys/vvvP8yfPx8WFhZYvXo1pk2bhrS0NMXwkqura6E+vzdpa2ujR48eCAkJwZEjR9C+fXsAwLRp0xASEoKuXbtiwIABePjwIRYuXIgPPvgA58+fV/y1vWfPHnzyySewsbHBiBEjYG1tjatXr2L79u0YMWKEynOWl2utIPv27cOGDRswbNgwmJubw97eHvfv30eTJk0gk8kwbNgwWFhY4O+//0b//v2RmpqKkSNHAnjVw/Ppp5/iyJEjGDRoEFxdXXHp0iXMnz8fN27cKHDS/82bN3Ht2jX069cPRkZGRYp9z549uH37Nvr27Qtra2vFEPmVK1dw4sQJxRyir776Chs3bsSwYcPg5uaG5ORkHDlyBFevXkW9evWQmZkJX19fZGRk4Ouvv4a1tTX+++8/bN++HY8fP4aJiUmec6v7XbV69WoEBgbC19cXM2fOxLNnz7BkyRI0b94c58+fV/qZv3z5Er6+vmjevDnmzJmDihUrFunzoXJI6sxKEz158kQAKPRfCNHR0QKAGDBggFL5mDFjBACxb98+RZmdnZ0AIA4dOqQoe/DggZDL5WL06NGKsty/zF7vrRCi8D028+fPFwDEw4cP841b1V9/Xl5ewtLSUiQnJyvKLly4ILS0tETv3r3znK9fv35KbXbq1ElUrlw533O+/j4MDAyEEEJ07txZtGnTRgghRHZ2trC2thZhYWEqP4MXL16I7OzsPO9DLpeLKVOmKMpOnz6tsodAiFc9HgDE0qVLVe578y/6Xbt2CQDiu+++E7dv3xaGhoaiY8eOb32PW7duVRz3us6dOwuZTCZu3bqldN78emFUxVhQ3S1btggA4vvvvxdCCBEXFye0tbXFtGnTlOpdunRJVKhQQVH+8uVL4eDgIOzs7JR60IQQih4mIcrftfa6/HpstLS0xJUrV5TK+/fvL2xsbPL0fHTv3l2YmJiIZ8+eCSFe9YRpaWmJw4cPK9VbunTpW3t9t23bJgCI+fPnFyp+VZ9jbhyv++233/J8z5iYmIihQ4fm2/b58+cFAPHHH38UGMPrPTavx/Tmd9WbPTZPnz4VpqamYuDAgUr1EhMThYmJiVJ5YGCgACAmTJhQYCykmbgq6h1ITU0FgEL/BbVz504AQFBQkFL56NGjASDPXBw3NzdFLwIAWFhYwNnZGbdv3y5yzG/K/Qt827ZtyMnJKdQxCQkJiI6ORp8+fVCpUiVFuYeHBz766CPF+3zdV199pfS6RYsWSE5OVnyGhfH555/jwIEDSExMxL59+5CYmJjvREm5XK6YuJidnY3k5GQYGhrC2dkZ586dK/Q55XI5+vbtW6i6H3/8Mb788ktMmTIFAQEB0NPTw08//fTW43bu3AltbW0MHz5cqXz06NEQQuDvv/8udLzqyP2L+enTpwCAzZs3IycnB127dkVSUpJis7a2hpOTE/bv3w8AOH/+PGJjYzFy5Mg88yUKWjlUnq61/LRs2RJubm6K10IIbNq0Cf7+/hBCKH1uvr6+ePLkieJ6++OPP+Dq6goXFxeleh9++CEAKD5fVdT9rlFFX19f8e8XL14gKSkJTZo0AQCl/ydMTU1x8uRJ3Lt3T2U7uT0yu3btwrNnz4ocT3727NmDx48fo0ePHkqfk7a2Nho3bqzycxo8eHCJx0FlHxObd8DY2BjA/34xvM2dO3egpaWFmjVrKpVbW1vD1NQUd+7cUSqvXr16njbMzMyQkpJSxIjz6tatG7y9vTFgwABYWVmhe/fu2LBhQ4G/eHLjdHZ2zrPP1dUVSUlJSE9PVyp/872YmZkBgFrvpV27djAyMsL69euxdu1aNGzYMM9nmSsnJwfz58+Hk5MT5HI5zM3NYWFhgYsXL+LJkyeFPmeVKlXUmig8Z84cVKpUCdHR0fjhhx9gaWn51mPu3LkDW1vbPL+0coeZ3rwuSkpaWhqA//2yvHnzJoQQcHJygoWFhdJ29epVPHjwAMCrWxsAQJ06ddQ6X3m61vLj4OCg9Prhw4d4/Pgxli1bluczy02Icz+3mzdv4sqVK3nq1apVS6meKup+16jy6NEjjBgxAlZWVtDX14eFhYXi/bz+/8SsWbNw+fJlVKtWDY0aNUJoaKjSH1MODg4ICgrC8uXLYW5uDl9fXyxevFit/68KcvPmTQDAhx9+mOez2r17d57PqUKFCqhatWqJnJvKF86xeQeMjY1ha2uLy5cvq3VcYe+Hkd9KASFEkc+RnZ2t9FpfXx+HDh3C/v37sWPHDkRGRmL9+vX48MMPsXv37hJbrVCc95JLLpcjICAAq1atwu3btxEaGppv3enTpyMkJAT9+vXD1KlTUalSJWhpaWHkyJGF7i0AlP/KLYzz588rvngvXbqEHj16qHV8acq9bnOTw5ycHMhkMvz9998qf17qzt96U3m61vLz5vWQey316tULgYGBKo/x8PBQ1HV3d8e8efNU1qtWrVq+53VxcQHw6poqqq5du+LYsWMYO3YsvLy8YGhoiJycHLRt21bp/4muXbuiRYsW2LJlC3bv3o3Zs2dj5syZ2Lx5M/z8/AAAc+fORZ8+fbBt2zbs3r0bw4cPR3h4OE6cOFHsJCM3ltWrV8Pa2jrP/jdX2r3eO0vvFyY278gnn3yCZcuW4fjx42jatGmBde3s7JCTk4ObN28qTfq8f/8+Hj9+DDs7uxKLy8zMDI8fP85Truqvfy0tLbRp0wZt2rTBvHnzMH36dHz77bfYv38/fHx8VL4P4NV9Kt507do1mJubv7Pllp9//jlWrFgBLS0tdO/ePd96GzduROvWrfHLL78olT9+/Bjm5uaK1yV507X09HT07dsXbm5uaNasGWbNmoVOnTqhYcOGBR5nZ2eHvXv34unTp0q9NteuXVPsL2nZ2dlYt24dKlasiObNmwMAHB0dIYSAg4ODohdBFUdHRwCvEiNV10dBytO1VhgWFhYwMjJCdnb2Wz8LR0dHXLhwAW3atFH7uqtVqxacnZ2xbds2fP/992onmSkpKYiKikJYWBgmTZqkKM/tHXmTjY0NhgwZgiFDhuDBgweoV68epk2bpkhsAMDd3R3u7u6YOHEijh07Bm9vbyxduhTfffedWrG9Kff6srS0VPv6ovcL09l3ZNy4cTAwMMCAAQNw//79PPtjYmLw/fffA3g1lAIACxYsUKqT+xdc7sqUkuDo6IgnT57g4sWLirKEhIQ8K68ePXqU59jcG9VlZGSobNvGxgZeXl5YtWqVUvJ0+fJl7N69W/E+34XWrVtj6tSpWLRokcq/5nJpa2vn+Qv9jz/+wH///adUlvtLUVUSqK7x48cjPj4eq1atwrx582Bvb4/AwMB8P8dc7dq1Q3Z2NhYtWqRUPn/+fMhkMqVfJiUhOzsbw4cPx9WrVzF8+HDFMEdAQAC0tbURFhaW57MTQiA5ORkAUK9ePTg4OGDBggV5PreCekXK27VWGNra2vjss8+wadMmlT23ufduAV71hPz333/4+eef89R7/vx5niG1N4WFhSE5ORkDBgzAy5cv8+zfvXs3tm/fnm+cQN6fz5vfRdnZ2XmGlCwtLWFra6v4GaWmpuY5v7u7O7S0tN56rReGr68vjI2NMX36dJX35Xn9M6X3G3ts3hFHR0esW7cO3bp1g6urq9Kdh48dO4Y//vhD8bwUT09PBAYGYtmyZXj8+DFatmyJU6dOYdWqVejYsSNat25dYnF1794d48ePR6dOnTB8+HDFcslatWopTRScMmUKDh06hPbt28POzg4PHjzAjz/+iKpVqyr+kldl9uzZ8PPzQ9OmTdG/f3/FElwTE5MCh4iKS0tLCxMnTnxrvU8++QRTpkxB37590axZM1y6dAlr165FjRo1lOo5OjrC1NQUS5cuhZGREQwMDNC4ceM8cyneZt++ffjxxx8xefJkxfLzlStXolWrVggJCcGsWbPyPdbf3x+tW7fGt99+i7i4OHh6emL37t3Ytm0bRo4cqfgLtiiePHmCNWvWAHh1c8HcOw/HxMSge/fumDp1qqKuo6MjvvvuOwQHByMuLg4dO3aEkZERYmNjsWXLFgwaNAhjxoyBlpYWlixZAn9/f3h5eaFv376wsbHBtWvXcOXKFezatUtlLOXtWiusGTNmYP/+/WjcuDEGDhwINzc3PHr0COfOncPevXsVCd0XX3yBDRs24KuvvsL+/fvh7e2N7OxsXLt2DRs2bMCuXbsKfMRAt27dFI8jOH/+PHr06KG483BkZCSioqKwbt06lccaGxvjgw8+wKxZs5CVlYUqVapg9+7diI2NVar39OlTVK1aFZ07d4anpycMDQ2xd+9enD59GnPnzgXw6lofNmwYunTpglq1auHly5dYvXq1IskrLmNjYyxZsgRffPEF6tWrh+7du8PCwgLx8fHYsWMHvL298/wRQO8pSdZivUdu3LghBg4cKOzt7YWurq4wMjIS3t7eYuHChUo338rKyhJhYWHCwcFB6OjoiGrVqhV4g743vbnMOL8llEK8uhlanTp1hK6urnB2dhZr1qzJswQ3KipKdOjQQdja2gpdXV1ha2srevToIW7cuJHnHG8uid67d6/w9vYW+vr6wtjYWPj7++d707Q3l/jmd1OuN72+3Ds/+S33Hj16tLCxsRH6+vrC29tbHD9+XOUy7W3btiluuPb6+yxoufTr7aSmpgo7OztRr149kZWVpVRv1KhRQktLSxw/frzA9/D06VMxatQoYWtrK3R0dISTk5PSDfpeP686y73x2g3RDA0NhZOTk+jVq5fYvXt3vsdt2rRJNG/eXBgYGAgDAwPh4uIihg4dKq5fv65U78iRI+Kjjz4SRkZGwsDAQHh4eIiFCxcq9pe3a+11Bd2gT5X79++LoUOHimrVqgkdHR1hbW0t2rRpI5YtW6ZULzMzU8ycOVPUrl1byOVyYWZmJurXry/CwsLEkydPChVb7udoaWkpKlSoICwsLIS/v7/Ytm2boo6qz/Hu3buiU6dOwtTUVJiYmIguXbqIe/fuCQBi8uTJQgghMjIyxNixY4Wnp6fi5+rp6Sl+/PFHRTu3b98W/fr1E46OjkJPT09UqlRJtG7dWuzdu1cpzqIu9861f/9+4evrK0xMTISenp5wdHQUffr0EWfOnFHUKcz3A2kumRAlMHOOiIiIqAzgHBsiIiLSGExsiIiISGMwsSEiIiKNwcSGiIiINAYTGyIiItIYTGyIiIhIYzCxISIiIo2hkXce1q87TOoQqJxJOc07lhLRu6NXSr9ti/P77/l5zfgeZI8NERERaQyN7LEhIiJ6L8nYX8HEhoiISFPIZFJHIDkmNkRERJqCPTZMbIiIiDQGe2yY2BAREWkM9tgwsSEiItIY7LHhcm8iIiLSHOyxISIi0hQcimJiQ0REpDE4FMXEhoiISGOwx4aJDRERkcZgjw0TGyIiIo3BHhuuiiIiIiLNwR4bIiIiTcGhKCY2REREGoNDUUxsiIiINAYTGyY2REREGkOLQ1FMbIiIiDQFe2y4KoqIiIjUc+jQIfj7+8PW1hYymQxbt25V2i+TyVRus2fPzrfN0NDQPPVdXFzUjo09NkRERJqilFZFpaenw9PTE/369UNAQECe/QkJCUqv//77b/Tv3x+fffZZge3Wrl0be/fuVbyuUEH9NIWJDRERkaYopaEoPz8/+Pn55bvf2tpa6fW2bdvQunVr1KhRo8B2K1SokOdYdXEoioiISFPIZEXeMjIykJqaqrRlZGQUO6T79+9jx44d6N+//1vr3rx5E7a2tqhRowZ69uyJ+Ph4tc/HxIaIiEhTyLSKvIWHh8PExERpCw8PL3ZIq1atgpGRkcohq9c1btwYERERiIyMxJIlSxAbG4sWLVrg6dOnap2PQ1FERESaohhzbIKDgxEUFKRUJpfLixsRVqxYgZ49e0JPT6/Aeq8PbXl4eKBx48aws7PDhg0bCtXbk4uJDRERkaYoxhwbuVxeIonM6w4fPozr169j/fr1ah9ramqKWrVq4datW2odx6EoIiIieid++eUX1K9fH56enmofm5aWhpiYGNjY2Kh1HBMbIiIiTVGMycPqSEtLQ3R0NKKjowEAsbGxiI6OVprsm5qaij/++AMDBgxQ2UabNm2waNEixesxY8bg4MGDiIuLw7Fjx9CpUydoa2ujR48easXGoSgiIiJNUUrLvc+cOYPWrVsrXufOzQkMDERERAQA4Pfff4cQIt/EJCYmBklJSYrXd+/eRY8ePZCcnAwLCws0b94cJ06cgIWFhVqxyYQQQs33U+bp1x0mdQhUzqScXvT2SkRERaRXSt0I+u1/KPKxz3cML8FIpFOmemxevHiBzMxMpTJjY2OJoiEiIipn+Kwo6efYPHv2DMOGDYOlpSUMDAxgZmamtBEREVEhFeM+NppC8ncyduxY7Nu3D0uWLIFcLsfy5csRFhYGW1tb/Prrr1KHR0REROWI5ENRf/31F3799Ve0atUKffv2RYsWLVCzZk3Y2dlh7dq16Nmzp9QhEhERlQ+l9BDMskzyHptHjx4pHoplbGyMR48eAQCaN2+OQ4cOSRkaERFR+cKhKOkTmxo1aiA2NhYA4OLigg0bNgB41ZNjamoqYWRERETlTCndx6Yskzyx6du3Ly5cuAAAmDBhAhYvXgw9PT2MGjUKY8eOlTg6IiKicoQ9NtLPsRk1apTi3z4+Prh27RrOnj2LmjVrwsPDQ8LIiIiIyhkN6nkpKskTmzfZ2dnBxMSEw1BERESkNsn7nmbOnKn01M+uXbuicuXKqFKlimKIioiIiN5OJpMVedMUkic2S5cuRbVq1QAAe/bswZ49e/D333/Dz8+Pc2yIiIjUwMSmDAxFJSYmKhKb7du3o2vXrvj4449hb2+Pxo0bSxwdERFROaI5+UmRSd5jY2Zmhn///RcAEBkZCR8fHwCAEALZ2dlShkZERFSusMemDPTYBAQE4PPPP4eTkxOSk5Ph5+cHADh//jxq1qwpcXRERETlhyYlKEUleY/N/PnzMWzYMLi5uWHPnj0wNDQEACQkJGDIkCESR1f+eNdzxMYFX+L27ml4fn4R/FspL5m3rGSEZWG9cHv3NCQfm4dti4bAsbqFRNFSWfX7urXw++hDNKzrjp7du+DSxYtSh0RlHK8ZKiskT2x0dHQwZswYfP/996hbt66ifNSoURgwYICEkZVPBvpyXLrxH0aGr1e5f8P8QXCoao4uI39Ckx4zEJ/wCDuXfo2KerqlHCmVVZF/78ScWeH4cshQ/P7HFjg7u2Dwl/2RnJwsdWhURvGaKTs4FFUGEhsAiImJwddffw0fHx/4+Phg+PDhuH37ttRhlUu7j/6DsB+348/9ef9aqlndEo09HDB82u84+088bt55gOHT10NProOufvUliJbKotWrViKgc1d07PQZHGvWxMTJYdDT08PWzZukDo3KKF4zZQcTmzKQ2OzatQtubm44deoUPDw84OHhgZMnTyqGpqjkyHVfTal6kflSUSaEQGbmSzTzcpQqLCpDsjIzcfWfK2jStJmiTEtLC02aNMPFC+cljIzKKl4zZYysGJuGkHzy8IQJEzBq1CjMmDEjT/n48ePx0UcfSRSZ5rkel4j4hEeY+vWnGPbdb0h/nonhvVqjqrUZrM1NpA6PyoCUxynIzs5G5cqVlcorV66M2Fj2olJevGbKFk3qeSkqyXtsrl69iv79++cp79evH/7555+3Hp+RkYHU1FSlTeRwmbgqL1/moPvon1HTzhIJh2bj0fF5+KBBLUQeuYIckSN1eEREVEwciioDiY2FhQWio6PzlEdHR8PS0vKtx4eHh8PExERpe3n/7DuIVDOcv/ovmnSfAasWY+Dw8bfoMOxHVDYxQOxdTvIjwMzUDNra2nkmfSYnJ8Pc3FyiqKgs4zVTtjCxKQOJzcCBAzFo0CDMnDkThw8fxuHDhzFjxgx8+eWXGDhw4FuPDw4OxpMnT5S2ClacCPs2qWkvkJSSBsfqFqjnVh3bD3BpJgE6urpwdauNkyeOK8pycnJw8uRxeHjWLeBIel/xmqGyRvI5NiEhITAyMsLcuXMRHBwMALC1tUVoaCiGDx/+1uPlcjnkcrlSmUxL+53EWh4Y6OvCsdr/7ktjX6UyPGpVQUrqM/ybmIIAn7p4mJKGfxMfoY6TLeaM7Yy/DlxE1IlrEkZNZckXgX0R8s141K5dB3XcPbBm9So8f/4cHTsFSB0alVG8ZsoOTep5KSrJExuZTIZRo0Zh1KhRePr0KQDAyMhI4qjKr3pudti9fITi9awxnwEAVv95AoMmr4G1hTFmjg6AZWUjJCalYu32kwhfFilVuFQGtfVrh5RHj/Djoh+QlPQQzi6u+PGn5ajMYQXKB6+ZMoR5DWRCCCFlAB9++CE2b94MU1NTpfLU1FR07NgR+/btU7tN/brDSig6el+knF4kdQhEpMH0SqkbwbzP70U+NimiewlGIh3Je2wOHDiAzMzMPOUvXrzA4cOHJYiIiIiofOJQlISJzcXXniPyzz//IDExUfE6OzsbkZGRqFKlihShERERlUtMbCRMbLy8vBRLzD788MM8+/X19bFw4UIJIiMiIqLySrLEJjY2FkII1KhRA6dOnYKFxf9W8ujq6sLS0hLa2u/v6iYiIiK1scNGuvvY2NnZwd7eHjk5OWjQoAHs7OwUm42NDZMaIiIiNZXWDfoOHToEf39/2NraQiaTYevWrUr7+/Tpk6f9tm3bvrXdxYsXw97eHnp6emjcuDFOnTqlVlxAGbhBHwCsXr0a3t7esLW1xZ07dwAA8+fPx7Zt2ySOjIiIqPworcQmPT0dnp6eWLx4cb512rZti4SEBMX222+/Fdjm+vXrERQUhMmTJ+PcuXPw9PSEr68vHjx4oFZskic2S5YsQVBQENq1a4fHjx8jO/vVc57MzMywYMECaYMjIiIqR0orsfHz88N3332HTp065VtHLpfD2tpasZmZmRXY5rx58zBw4ED07dsXbm5uWLp0KSpWrIgVK1aoFZvkic3ChQvx888/49tvv1UafmrQoAEuXbokYWRERETlS3ESG1UPlc7IyChyLAcOHIClpSWcnZ0xePDgPM8Te11mZibOnj0LHx8fRZmWlhZ8fHxw/PjxfI9TRfLEJjY2FnXr5n2eiFwuR3p6ugQRERERvX9UPVQ6PDy8SG21bdsWv/76K6KiojBz5kwcPHgQfn5+ilGZNyUlJSE7OxtWVlZK5VZWVkq3gykMyW/Q5+DggOjoaNjZ2SmVR0ZGwtXVVaKoiIiIyqFirIoKDg5GUFCQUtmbz2IsrO7d/3cXY3d3d3h4eMDR0REHDhxAmzZtih5kIUie2AQFBWHo0KF48eIFhBA4deoUfvvtN4SHh2P58uVSh0dERFRuFOcGfaoeKl1SatSoAXNzc9y6dUtlYmNubg5tbW3cv39fqfz+/fuwtrZW61ySJzYDBgyAvr4+Jk6ciGfPnuHzzz9HlSpV8P333ytlfERERFSwsnrn4bt37yI5ORk2NjYq9+vq6qJ+/fqIiopCx44dAQA5OTmIiorCsGHqPf9R8sTm+fPn6NSpE3r27Ilnz57h8uXLOHr0KKpWrSp1aEREROVKaSU2aWlpuHXrluJ1bGwsoqOjUalSJVSqVAlhYWH47LPPYG1tjZiYGIwbNw41a9aEr6+v4pg2bdqgU6dOisQlKCgIgYGBaNCgARo1aoQFCxYgPT0dffv2VSs2yRObDh06ICAgAF999RUyMzPx6aefQkdHB0lJSZg3bx4GDx4sdYhERETlQyl12Jw5cwatW7dWvM6dmxMYGIglS5bg4sWLWLVqFR4/fgxbW1t8/PHHmDp1qtJQV0xMDJKSkhSvu3XrhocPH2LSpElITEyEl5cXIiMj80wofhuZEEIU8/0Vi7m5OQ4ePIjatWtj+fLlWLhwIc6fP49NmzZh0qRJuHr1qtpt6tdVr9uKKOX0IqlDICINpldK3QjVv/6zyMfGL/y0BCORjuTLvZ89ewYjIyMAwO7duxEQEAAtLS00adJEcRdiIiIiosKQPLGpWbMmtm7din///Re7du3Cxx9/DAB48OABjI2NJY6OiIio/CitOw+XZZInNpMmTcKYMWNgb2+Pxo0bo2nTpgBe9d6ounEfERERqcbEpgxMHu7cuTOaN2+OhIQEeHp6KspzZ0sTERFR4WhSglJUkic2ABQPyHpdo0aNJIqGiIionGJeUzYSGyIiIio+9tiUgTk2RERERCWFPTZEREQagj02TGyIiIg0BvMaJjZEREQagz02TGyIiIg0BvMaJjZEREQagz02XBVFREREGoQ9NkRERBqCHTZMbIiIiDSGlhYzGyY2REREGoI9NkxsiIiINAYnDzOxISIi0hjMa7gqioiIiDQIe2yIiIg0BIeimNgQERFpDCY2TGyIiIg0BvMaJjZEREQagz02TGyIiIg0BvMaJjZEREQagz02XO5NREREGoQ9NkRERBqCHTZMbIiIiDQGh6KY2BAREWkM5jWcY0NERKQxZDJZkTd1HDp0CP7+/rC1tYVMJsPWrVsV+7KysjB+/Hi4u7vDwMAAtra26N27N+7du1dgm6GhoXlicnFxUfszYGJDRESkIWSyom/qSE9Ph6enJxYvXpxn37Nnz3Du3DmEhITg3Llz2Lx5M65fv45PP/30re3Wrl0bCQkJiu3IkSPqBQYNHYpKOb1I6hConPEO3y91CFSOHA1uLXUIRJLy8/ODn5+fyn0mJibYs2ePUtmiRYvQqFEjxMfHo3r16vm2W6FCBVhbWxcrNvbYEBERaYjiDEVlZGQgNTVVacvIyCiRuJ48eQKZTAZTU9MC6928eRO2traoUaMGevbsifj4eLXPxcSGiIhIQxRnKCo8PBwmJiZKW3h4eLFjevHiBcaPH48ePXrA2Ng433qNGzdGREQEIiMjsWTJEsTGxqJFixZ4+vSpWufTyKEoIiKi91FxlnsHBwcjKChIqUwulxcrnqysLHTt2hVCCCxZsqTAuq8PbXl4eKBx48aws7PDhg0b0L9//0Kfk4kNERGRhijOcm+5XF7sROZ1uUnNnTt3sG/fvgJ7a1QxNTVFrVq1cOvWLbWO41AUERGRhiit5d5vk5vU3Lx5E3v37kXlypXVbiMtLQ0xMTGwsbFR6zgmNkRERKSWtLQ0REdHIzo6GgAQGxuL6OhoxMfHIysrC507d8aZM2ewdu1aZGdnIzExEYmJicjMzFS00aZNGyxa9L9VzGPGjMHBgwcRFxeHY8eOoVOnTtDW1kaPHj3Uio1DUURERBqitB6pcObMGbRu/b/bHuTOzQkMDERoaCj+/PNPAICXl5fScfv370erVq0AADExMUhKSlLsu3v3Lnr06IHk5GRYWFigefPmOHHiBCwsLNSKjYkNERGRhiitRyq0atUKQoh89xe0L1dcXJzS699//724YQFgYkNERKQx+BBMJjZEREQag3kNExsiIiKNwR4bJjZEREQag3kNl3sTERGRBmGPDRERkYbQYpcNExsiIiJNwbyGiQ0REZHG4ORhJjZEREQaQ4t5jbSTh7OystCmTRvcvHlTyjCIiIg0Qll5CKaUJE1sdHR0cPHiRSlDICIiIg0i+XLvXr164ZdffpE6DCIionJPJiv6pikkn2Pz8uVLrFixAnv37kX9+vVhYGCgtH/evHkSRUZERFS+yKBBGUoRSZ7YXL58GfXq1QMA3LhxQ2mfJo35ERERvWucPFwGEpv9+/dLHQIREZFGYIdAGUhsXnf37l0AQNWqVSWOhIiIqPxhXlMGJg/n5ORgypQpMDExgZ2dHezs7GBqaoqpU6ciJydH6vCIiIioHJG8x+bbb7/FL7/8ghkzZsDb2xsAcOTIEYSGhuLFixeYNm2axBESERGVD3xWVBlIbFatWoXly5fj008/VZR5eHigSpUqGDJkCBMbIiKiQmJeUwYSm0ePHsHFxSVPuYuLCx49eiRBREREROUTJw+XgTk2np6eWLRoUZ7yRYsWwdPTU4KIiIiIyifeoK8M9NjMmjUL7du3x969e9G0aVMAwPHjx/Hvv/9i586dEkdHRERUfnCOTSETmz///LPQDb4+V6YwWrZsiRs3bmDx4sW4du0aACAgIABDhgyBra2tWm0RERHR+61QiU3Hjh0L1ZhMJkN2drbaQdja2nKSMBERUTGxv6aQiU1J309GnSd6e3h4lOi5iYiINBUnD0s0x8bLywsymQxCiALrFbUHiIiI6H3EZ0UVMbFJT0/HwYMHER8fj8zMTKV9w4cPf+vxsbGxRTktERERFYA9NkVIbM6fP4927drh2bNnSE9PR6VKlZCUlISKFSvC0tKyUImNnZ1dkYIlIiKi/DGvKcJ9bEaNGgV/f3+kpKRAX18fJ06cwJ07d1C/fn3MmTOnSEHExMTg66+/ho+PD3x8fDB8+HDExMQUqS0iIqL3lUwmK/KmKdRObKKjozF69GhoaWlBW1sbGRkZqFatGmbNmoVvvvlG7QB27doFNzc3nDp1Ch4eHvDw8MDJkydRu3Zt7NmzR+32iIiI6N06dOgQ/P39YWtrC5lMhq1btyrtF0Jg0qRJsLGxgb6+Pnx8fHDz5s23trt48WLY29tDT08PjRs3xqlTp9SOTe3ERkdHB1parw6ztLREfHw8AMDExAT//vuv2gFMmDABo0aNwsmTJzFv3jzMmzcPJ0+exMiRIzF+/Hi12yMiInpfacmKvqkjPT0dnp6eWLx4scr9s2bNwg8//IClS5fi5MmTMDAwgK+vL168eJFvm+vXr0dQUBAmT56Mc+fOwdPTE76+vnjw4IFasamd2NStWxenT58G8OrmepMmTcLatWsxcuRI1KlTR93mcPXqVfTv3z9Peb9+/fDPP/+o3R4REdH7qrSGovz8/PDdd9+hU6dOefYJIbBgwQJMnDgRHTp0gIeHB3799Vfcu3cvT8/O6+bNm4eBAweib9++cHNzw9KlS1GxYkWsWLFCrdjUTmymT58OGxsbAMC0adNgZmaGwYMH4+HDh1i2bJm6zcHCwgLR0dF5yqOjo2Fpaal2e0RERO8rWTG2khIbG4vExET4+PgoykxMTNC4cWMcP35c5TGZmZk4e/as0jFaWlrw8fHJ95j8qL0qqkGDBop/W1paIjIyUt0mlAwcOBCDBg3C7du30axZMwDA0aNHMXPmTAQFBRWrbSIiovdJcZ4VlZGRgYyMDKUyuVwOuVyuVjuJiYkAACsrK6VyKysrxb43JSUlITs7W+UxuY9bKizJH4IZEhICIyMjzJ07F8HBwQBePWIhNDS0UEvHiYiI6JXiLG4KDw9HWFiYUtnkyZMRGhpavKBKmdqJjYODQ4Fjcbdv31arPZlMhlGjRmHUqFF4+vQpAMDIyEjdsIiIiKgYgoOD84yUqNtbAwDW1tYAgPv37yumruS+9vLyUnmMubk5tLW1cf/+faXy+/fvK9orLLUTm5EjRyq9zsrKwvnz5xEZGYmxY8eq2xxiY2Px8uVLODk5KSU0N2/ehI6ODuzt7dVuk/L6fd1arFr5C5KSHqKWswsmfBMCdz6HiwDUrW6C3k2rw9XGCBZGcozecAkHricp9g/6wB6+tS1hZayHrOwcXE14ih/3x+LyvVQJo6ayht8xZUNx7kdTlGEnVRwcHGBtbY2oqChFIpOamoqTJ09i8ODBKo/R1dVF/fr1ERUVpXjwdk5ODqKiojBs2DC1zq92YjNixAiV5YsXL8aZM2fUbQ59+vRBv3794OTkpFR+8uRJLF++HAcOHFC7TVIW+fdOzJkVjomTw+Du7om1q1dh8Jf9sW17JCpXrix1eCQxfR1t3Lifhj+jEzCnq3ue/fGPnmFm5E38l/Icch0t9GxcDYt7eqLD4hN4/CxLgoiprOF3TNlRWvfZS0tLw61btxSvY2NjER0djUqVKqF69eoYOXIkvvvuOzg5OcHBwQEhISGwtbVVJC0A0KZNG3Tq1EmRuAQFBSEwMBANGjRAo0aNsGDBAqSnp6Nv375qxab2qqj8+Pn5YdOmTWofd/78eXh7e+cpb9KkicrVUqS+1atWIqBzV3Ts9Bkca9bExMlh0NPTw9bN6v+8SPMci3mEJQdisf+1XprXRV5+gFOxKfjv8QvcfvgM83bfgqFeBThZGpZypFRW8Tum7NCSyYq8qePMmTOoW7cu6tatC+BVUlK3bl1MmjQJADBu3Dh8/fXXGDRoEBo2bIi0tDRERkZCT09P0UZMTAySkv73vdOtWzfMmTMHkyZNgpeXF6KjoxEZGZlnQvHblNjk4Y0bN6JSpUpqHyeTyRRza1735MkTPtm7BGRlZuLqP1fQf+CXijItLS00adIMFy+clzAyKo8qaMkQUM8WT19k4eb9NKnDoTKA3zFlS2n12LRq1QpCiALikGHKlCmYMmVKvnXi4uLylA0bNkztoac3qZ3Y1K1bV2kMTwiBxMREPHz4ED/++KPaAXzwwQcIDw/Hb7/9Bm1tbQBAdnY2wsPD0bx5c7XbI2Upj1OQnZ2dpzu4cuXKiI1Vb6I3vb9aOFXG9AA36OloI+lpJoasuYDHzzkMRfyOKWs06ZlPRaV2YtOhQwelD05LSwsWFhZo1aoVXFxc1A5g5syZ+OCDD+Ds7IwWLVoAAA4fPozU1FTs27fvrcerWncvtEtmAhQRvXI6LgU9lp2BaUUddKprgxmf1UbgirNI4RwbIipj1E5sSno9u5ubGy5evIhFixbhwoUL0NfXR+/evTFs2LBCDW2pWnf/bchkTJxUsnGWV2amZtDW1kZycrJSeXJyMszNzSWKisqbF1k5uJvyHHdTnuPyf6nYMqQxOta1wcqj8VKHRhLjd0zZUmITZ8sxtRMbbW1tJCQk5HncQXJyMiwtLYs0L8bW1hbTp09X+zhA9bp7oc3emlw6urpwdauNkyeO48M2r25VnZOTg5Mnj6N7j14SR0fllZZMBh1tfoUSv2PKGg5FFSGxyW+yUEZGBnR1dQvVxsWLF1GnTh1oaWnh4sWLBdb1eMt9EFStu3/xslBhvDe+COyLkG/Go3btOqjj7oE1q1fh+fPn6NgpQOrQqAzQ19FGtUr6ite2pnqoZWWI1OdZePw8C/2b2+PgjSQkpWXAVF8HXRtWhYWxLvZeVe+Ju6S5+B1Tdqj7lG5NVOjE5ocffgDwKhtcvnw5DA3/t9QzOzsbhw4dKvQcGy8vLyQmJsLS0hJeXl6QyWQqEyaZTMaVUSWgrV87pDx6hB8X/YCkpIdwdnHFjz8tR2V2ExMAN1sjLOtdV/F69Mev7in114UETN9xA/bmFfGJRx2YVtTBk+dZuHIvFQMizuP2w2dShUxlDL9jyg4mNoBMFLRe6zUODg4AgDt37qBq1aqKFUzAqzsG2tvbY8qUKWjcuPFb27pz5w6qV68OmUyGO3fuFFjXzs6uMOEpYY8Nqcs7fL/UIVA5cjS4tdQhUDmjV0pPZhz91/UiHzvX37kEI5FOoT/q2NhYAEDr1q2xefNmmJmZFfmkrycrRUlciIiIKC/22BRhAvX+/fuLldS8adWqVdixY4fi9bhx42BqaopmzZq9tTeHiIiI6HVqJzafffYZZs6cmad81qxZ6NKli9oBTJ8+Hfr6ryYuHj9+HIsWLcKsWbNgbm6OUaNGqd0eERHR+0omK/qmKdRObA4dOoR27drlKffz88OhQ4fUDuDff/9FzZo1AQBbt25F586dMWjQIISHh+Pw4cNqt0dERPS+Kq1nRZVlaic2aWlpKpd16+joIDU1Ve0ADA0NFTd22r17Nz766CMAgJ6eHp4/f652e0RERO8rrWJsmkLt9+Lu7o7169fnKf/999/h5uamdgAfffQRBgwYgAEDBuDGjRuK3qArV67A3t5e7faIiIjeVxyKKsIN+kJCQhAQEICYmBh8+OGHAICoqCisW7cOGzduVDuAxYsXIyQkBPHx8di0aZPiQWpnz55Fjx491G6PiIjofaVJQ0pFpXZi4+/vj61bt2L69OnYuHEj9PX14enpiX379hXq2U6ve/nyJX744QeMHz8eVatWVdr35vOfiIiIiN6mSMNq7du3x9GjR5Geno7bt2+ja9euGDNmDDw9PdVqp0KFCpg1axZevuQd9YiIiIqLQ1HFmC906NAhBAYGwtbWFnPnzsWHH36IEydOqN1OmzZtcPDgwaKGQURERP9PS1b0TVOoNRSVmJiIiIgI/PLLL0hNTUXXrl2RkZGBrVu3FmniMPBqmfiECRNw6dIl1K9fHwYGBkr7P/300yK1S0RE9L7hHBs1Eht/f38cOnQI7du3x4IFC9C2bVtoa2tj6dKlxQpgyJAhAIB58+bl2ceHYBIRERUe8xo1Epu///4bw4cPx+DBg+Hk5FRiAeTk5JRYW0RERO8zTRpSKqpCz7E5cuQInj59ivr166Nx48ZYtGgRkpKSSjSYFy9elGh7RERE9H4pdGLTpEkT/Pzzz0hISMCXX36J33//Hba2tsjJycGePXvw9OnTIgWQnZ2NqVOnokqVKjA0NMTt27cBvLpfzi+//FKkNomIiN5HsmL8pynUXhVlYGCAfv364ciRI7h06RJGjx6NGTNmwNLSskgTfadNm4aIiAjMmjVL6VENderUwfLly9Vuj4iI6H3FVVHFfDyEs7MzZs2ahbt37+K3334rUhu//vorli1bhp49e0JbW1tR7unpiWvXrhUnPCIiovcKE5si3HlYFW1tbXTs2BEdO3ZU+9j//vtP8XTv1+Xk5CArK6sEoiMiIno/yLgsSvoHerq5ueHw4cN5yjdu3Ii6detKEBEREVH5xB6bEuqxKY5JkyYhMDAQ//33H3JycrB582Zcv34dv/76K7Zv3y51eEREROUGO2zKQI9Nhw4d8Ndff2Hv3r0wMDDApEmTcPXqVfz111/46KOPpA6PiIiIyhHJe2wGDBiAXr16Yc+ePVKHQkREVK7xkQploMfm4cOHaNu2LapVq4Zx48bhwoULUodERERULpXWHBt7e3vIZLI829ChQ1XWj4iIyFNXT0+vBN5xXpInNtu2bUNCQgJCQkJw6tQp1KtXD7Vr18b06dMRFxcndXhERETlhkxW9E0dp0+fRkJCgmLLHXXp0qVLvscYGxsrHXPnzp3ivNV8SZ7YAICZmRkGDRqEAwcO4M6dO+jTpw9Wr16tchk4ERERqaYFWZE3dVhYWMDa2lqxbd++HY6OjmjZsmW+x8hkMqVjrKysivt2VSoTiU2urKwsnDlzBidPnkRcXNw7e9NERESaqLR6bF6XmZmJNWvWoF+/fgXeRyctLQ12dnaoVq0aOnTogCtXrhT9pAUoE4nN/v37MXDgQFhZWaFPnz4wNjbG9u3bcffuXalDIyIiei9kZGQgNTVVacvIyHjrcVu3bsXjx4/Rp0+ffOs4OztjxYoV2LZtG9asWYOcnBw0a9bsnfyelwkhRIm3qoYqVarg0aNHaNu2LXr27Al/f3/I5fJitfniZQkFR+8N7/D9UodA5cjR4NZSh0DljF4prUFeejyuyMcm7opAWFiYUtnkyZMRGhpa4HG+vr7Q1dXFX3/9VehzZWVlwdXVFT169MDUqVOLEm6+JF/uHRoaii5dusDU1FTqUIiIiMq14iz3Dg4ORlBQkFLZ2zoa7ty5g71792Lz5s1qnUtHRwd169bFrVu31I7zbSRPbAYOHCh1CERERBqhOHNl5HK52iMmK1euhKWlJdq3b6/WcdnZ2bh06RLatWun1nGFIXliQ0RERCWjNG/Ql5OTg5UrVyIwMBAVKiinE71790aVKlUQHh4OAJgyZQqaNGmCmjVr4vHjx5g9ezbu3LmDAQMGlHhcTGyIiIg0RGneeHjv3r2Ij49Hv3798uyLj4+Hltb/1ielpKRg4MCBSExMhJmZGerXr49jx47Bzc2txOOSfPLwu8DJw6QuTh4mdXDyMKmrtCYPrzgdX+Rj+zWsXoKRSIc9NkRERBqiTNzDRWJMbIiIiDREQTfIe18wsSEiItIQTGuY2BAREWmM0lwVVVYxsSEiItIQTGs4z4iIiIg0CHtsiIiINARHopjYEBERaQyuimJiQ0REpDE4v4SJDRERkcZgjw0TGyIiIo3BtIaJDRERkcZgjw0TGyIAfKghqYcPTSV1nQ3hd0xpYWJDRESkITh5mIkNERGRxuBQFBMbIiIijcG0hokNERGRxmCHDRMbIiIijaHFPhvOMyIiIiLNwR4bIiIiDcGhKCY2REREGkPGoSgmNkRERJqCPTZMbIiIiDQGJw8zsSEiItIY7LHhqigiIiLSIOyxISIi0hDssWFiQ0REpDG4KoqJDRERkcbQYl7DxIaIiEhTsMeGk4eJiIg0hkxW9E0doaGhkMlkSpuLi0uBx/zxxx9wcXGBnp4e3N3dsXPnzmK80/wxsSEiItIQsmL8p67atWsjISFBsR05ciTfuseOHUOPHj3Qv39/nD9/Hh07dkTHjh1x+fLl4rxdlZjYEBERkdoqVKgAa2trxWZubp5v3e+//x5t27bF2LFj4erqiqlTp6JevXpYtGhRicfFxIaIiEhDaMmKvqnr5s2bsLW1RY0aNdCzZ0/Ex8fnW/f48ePw8fFRKvP19cXx48fVP/FbcPIwERGRhijO5OGMjAxkZGQolcnlcsjl8jx1GzdujIiICDg7OyMhIQFhYWFo0aIFLl++DCMjozz1ExMTYWVlpVRmZWWFxMTEIsebH/bYEBERaYjiTB4ODw+HiYmJ0hYeHq7yPH5+fujSpQs8PDzg6+uLnTt34vHjx9iwYUMpv+O82GNDRESkIYqz2Ds4OBhBQUFKZap6a1QxNTVFrVq1cOvWLZX7ra2tcf/+faWy+/fvw9raumjBFoA9NkRERBpCSyYr8iaXy2FsbKy0FTaxSUtLQ0xMDGxsbFTub9q0KaKiopTK9uzZg6ZNmxb7Pb9J8sQmOzsbc+bMQaNGjWBtbY1KlSopbURERFS2jBkzBgcPHkRcXByOHTuGTp06QVtbGz169AAA9O7dG8HBwYr6I0aMQGRkJObOnYtr164hNDQUZ86cwbBhw0o8NskTm7CwMMybNw/dunXDkydPEBQUhICAAGhpaSE0NFTq8IiIiMoNWTE2ddy9exc9evSAs7MzunbtisqVK+PEiROwsLAAAMTHxyMhIUFRv1mzZli3bh2WLVsGT09PbNy4EVu3bkWdOnWK9X5VkQkhRIm3qgZHR0f88MMPaN++PYyMjBAdHa0oO3HiBNatW6d2my9evoNAiYj+n3f4fqlDoHLmbEjrUjnPiZjHRT62iaNpicUhJcl7bBITE+Hu7g4AMDQ0xJMnTwAAn3zyCXbs2CFlaEREROVKad55uKySPLGpWrWqorvK0dERu3fvBgCcPn260JOWiIiIqPSeFVWWSZ7YdOrUSTFT+uuvv0ZISAicnJzQu3dv9OvXT+LoiIiIyo/SmmNTlkl+H5sZM2Yo/t2tWzfY2dnh2LFjcHJygr+/v4SRERERUXkjeWLzpiZNmqBJkyZSh0FERFT+aFLXSxFJPhQVHh6OFStW5ClfsWIFZs6cKUFERERE5RMnD5eBxOann36Ci4tLnvLatWtj6dKlEkRERERUPnHycBkYikpMTFR5C2YLCwulm/sQERFRwTQoPykyyXtsqlWrhqNHj+YpP3r0KGxtbSWIiIiIqJzisijpe2wGDhyIkSNHIisrCx9++CEAICoqCuPGjcPo0aMljo6IiIjKE8kTm7FjxyI5ORlDhgxBZmYmAEBPTw/jx49XeoAWERERFUyTJgEXleTPisqVlpaGq1evQl9fH05OTsW66zCfFUVE7xKfFUXqKq1nRUXHPy3ysV7VjUowEulI3mOTy9DQEA0bNpQ6DCIionKL/TUSJTYBAQGIiIiAsbExAgICCqy7efPmUoqKiIionGNmI01iY2JiAtn/L5o3MTGRIgQiIiKNwzk2EiU2K1euVPlvIiIiKjpNutFeUUl+HxsiIiKikiL55OH79+9jzJgxiIqKwoMHD/DmIq3s7GyJItMsv69bi1Urf0FS0kPUcnbBhG9C4O7hIXVYVEbxeqH81K1ugt5Nq8PVxggWRnKM3nAJB64nKfYP+sAevrUtYWWsh6zsHFxNeIof98fi8r1UCaN+f7DDpgwkNn369EF8fDxCQkJgY2OjmHtDJSfy752YMyscEyeHwd3dE2tXr8LgL/tj2/ZIVK5cWerwqIzh9UIF0dfRxo37afgzOgFzurrn2R//6BlmRt7EfynPIdfRQs/G1bC4pyc6LD6Bx8+yJIj4PcNfodInNkeOHMHhw4fh5eUldSgaa/WqlQjo3BUdO30GAJg4OQyHDh3A1s2b0H/gIImjo7KG1wsV5FjMIxyLeZTv/sjLD5Rez9t9Cx3r2sLJ0hCn41LedXjvPU4eLgNzbKpVq5Zn+IlKTlZmJq7+cwVNmjZTlGlpaaFJk2a4eOG8hJFRWcTrhUpSBS0ZAurZ4umLLNy8nyZ1OO8FPt27DCQ2CxYswIQJExAXFyd1KBop5XEKsrOz8wwhVK5cGUlJSfkcRe8rXi9UElo4Vcbh8S1w/JuW+LxxNQxZcwGPn3MYqjTwGZhlYCiqW7duePbsGRwdHVGxYkXo6Ogo7X/0KP8uTwDIyMhARkaGUpnQlhfrkQxERFR0p+NS0GPZGZhW1EGnujaY8VltBK44ixTOsaFSIHlis2DBgmIdHx4ejrCwMKWyb0MmY+Kk0GK1qynMTM2gra2N5ORkpfLk5GSYm5tLFBWVVbxeqCS8yMrB3ZTnuJvyHJf/S8WWIY3Rsa4NVh6Nlzo0zadJXS9FJHliExgYWKzjg4ODERQUpFQmtNlbk0tHVxeubrVx8sRxfNjGBwCQk5ODkyePo3uPXhJHR2UNrxd6F7RkMuhoSz7z4b3AycMSJTapqakwNjZW/LsgufXyI5fnHXbi072VfRHYFyHfjEft2nVQx90Da1avwvPnz9GxU8HP6aL3E68XKoi+jjaqVdJXvLY11UMtK0OkPs/C4+dZ6N/cHgdvJCEpLQOm+jro2rAqLIx1sffqgwJapZKiSZOAi0qSxMbMzAwJCQmwtLSEqampynvXCCEgk8l4g74S0NavHVIePcKPi35AUtJDOLu44seflqMyhxZIBV4vVBA3WyMs611X8Xr0x04AgL8uJGD6jhuwN6+ITzzqwLSiDp48z8KVe6kYEHEetx8+kyrk9wrzGkAmJFhrffDgQXh7e6NChQo4ePBggXVbtmypdvvssSGid8k7fL/UIVA5czakdamc58b9oieQtawqlmAk0pGkx+b1ZKUoiQsRERGRKpJPHr548aLKcplMBj09PVSvXp1Lt4mIiAqhtCYPh4eHY/Pmzbh27Rr09fXRrFkzzJw5E87OzvkeExERgb59+yqVyeVyvHjxokRjkzyx8fLyKvD5UDo6OujWrRt++ukn6OnplWJkRERE5UtpTR4+ePAghg4dioYNG+Lly5f45ptv8PHHH+Off/6BgYFBvscZGxvj+vXritfv4vmQkic2W7Zswfjx4zF27Fg0atQIAHDq1CnMnTsXkydPxsuXLzFhwgRMnDgRc+bMkThaIiKisqu0Jg9HRkYqvY6IiIClpSXOnj2LDz74IN/jZDIZrK2t32lskic206ZNw/fffw9fX19Fmbu7O6pWrYqQkBCcOnUKBgYGGD16NBMbIiKigki0LOrJkycAgEqVKhVYLy0tDXZ2dsjJyUG9evUwffp01K5du0RjkTyxuXTpEuzs7PKU29nZ4dKlSwBeDVclJCSUdmhERETlSnHm2Kh6RJGqe8W9KScnByNHjoS3tzfq1KmTbz1nZ2esWLECHh4eePLkCebMmYNmzZrhypUrqFq1apHjfpPkt4J0cXHBjBkzkJmZqSjLysrCjBkz4OLiAgD477//YGVlJVWIRERE5UJxnu4dHh4OExMTpS08PPyt5xw6dCguX76M33//vcB6TZs2Re/eveHl5YWWLVti8+bNsLCwwE8//VRSbx9AGeixWbx4MT799FNUrVoVHh4eAF714mRnZ2P79u0AgNu3b2PIkCFShklERKTRVD2i6G29NcOGDcP27dtx6NAhtXtddHR0ULduXdy6dUvtWAsieWLTrFkzxMbGYu3atbhx4wYAoEuXLvj8889hZGQEAPjiiy+kDJGIiKhcKM4Um8IMO+USQuDrr7/Gli1bcODAATg4OKh9vuzsbFy6dAnt2rVT+9iCSJrYZGVlwcXFBdu3b8dXX30lZShERETlXylNHh46dCjWrVuHbdu2wcjICImJiQAAExMT6Ou/epZY7969UaVKFcVw1pQpU9CkSRPUrFkTjx8/xuzZs3Hnzh0MGDCgRGOTNLHR0dEp8RvzEBERva9K6wZ9S5YsAQC0atVKqXzlypXo06cPACA+Ph5aWv+bypuSkoKBAwciMTERZmZmqF+/Po4dOwY3N7cSjU2SZ0W9bvr06bhx4waWL1+OChVKJs/is6KI6F3is6JIXaX1rKj4Rxlvr5SP6pU04y7/ks+xOX36NKKiorB79264u7vnuWPh5s2bJYqMiIiofOHTvctAYmNqaorPPvtM6jCIiIhIA0ie2KxcuVLqEIiIiDRCaT0rqiyTPLEhIiKiksLMRpLEpl69eoiKioKZmRnq1q1b4NM9z507V4qRERERlV/ssZEosenQoYPiJkAdO3aUIgQiIiKNw7xGosRm8uTJin//+++/6NmzJ1q3Lp2lcERERJqKPTZl4CGYDx8+hJ+fH6pVq4Zx48bhwoULUodERERE5ZTkic22bduQkJCAkJAQnDp1CvXq1UPt2rUxffp0xMXFSR0eERFRuSErxn+aQvLEBgDMzMwwaNAgHDhwAHfu3EGfPn2wevVq1KxZU+rQiIiIyg9ZMTYNUaaWe2dlZeHMmTM4efIk4uLiYGVlJXVIRERE5YYG5SdFViZ6bPbv34+BAwfCysoKffr0gbGxMbZv3467d+9KHRoREVG5IZMVfdMUkvfYVKlSBY8ePULbtm2xbNky+Pv7K5aCExERUeFp0lyZopI8sQkNDUWXLl1gamoqdShERERUzkme2AwcOFDqEIiIiDQDO2ykT2yIiIioZDCvYWJDRESkMTRpEnBRMbEhIiLSEJw8zMSGiIhIY7DHpozcx4aIiIioJDCxISIiIo3BoSgiIiINwaEoJjZEREQag5OHmdgQERFpDPbYMLEhIiLSGMxrmNgQERFpDmY2XBVFREREmoM9NkRERBqCk4eZ2BAREWkMTh7mUBQREZHGkBVjK4rFixfD3t4eenp6aNy4MU6dOlVg/T/++AMuLi7Q09ODu7s7du7cWcQz54+JDRERkaYoxcxm/fr1CAoKwuTJk3Hu3Dl4enrC19cXDx48UFn/2LFj6NGjB/r374/z58+jY8eO6NixIy5fvqz+yQsgE0KIEm2xDHjxUuoIiEiTeYfvlzoEKmfOhrQulfM8zyr6sfo66tVv3LgxGjZsiEWLFgEAcnJyUK1aNXz99deYMGFCnvrdunVDeno6tm/frihr0qQJvLy8sHTp0qIH/gb22BAREZFaMjMzcfbsWfj4+CjKtLS04OPjg+PHj6s85vjx40r1AcDX1zff+kXFycNEREQaojiThzMyMpCRkaFUJpfLIZfL89RNSkpCdnY2rKyslMqtrKxw7do1le0nJiaqrJ+YmFj0oFXQyMRGTyPfVfFlZGQgPDwcwcHBKi9UotfxeslfaQ0rlCe8XsqG4vz+C/0uHGFhYUplkydPRmhoaPGCKmUcinqPZGRkICwsLE9GTqQKrxdSB6+X8i84OBhPnjxR2oKDg1XWNTc3h7a2Nu7fv69Ufv/+fVhbW6s8xtraWq36RcXEhoiIiCCXy2FsbKy05df7pquri/r16yMqKkpRlpOTg6ioKDRt2lTlMU2bNlWqDwB79uzJt35RcdCGiIiI1BYUFITAwEA0aNAAjRo1woIFC5Ceno6+ffsCAHr37o0qVaogPDwcADBixAi0bNkSc+fORfv27fH777/jzJkzWLZsWYnGxcSGiIiI1NatWzc8fPgQkyZNQmJiIry8vBAZGamYIBwfHw8trf8NDDVr1gzr1q3DxIkT8c0338DJyQlbt25FnTp1SjQujbyPDanGyX2kDl4vpA5eL1RWMLEhIiIijcHJw0RERKQxmNgQERGRxmBiQ0QKcXFxkMlkiI6OLpPtUckJDQ2Fl5dXsds5cOAAZDIZHj9+XOhj+vTpg44dOxb73ESqcI6NBoqLi4ODgwPOnz9fIl9c9P7Izs7Gw4cPYW5ujgoVir9oktdi2ZWWloaMjAxUrly5WO1kZmbi0aNHsLKygqyQ9/N/8uQJhBAwNTUt1rmJVOFyb6L3SFZWFnR08n+Er7a2donfBbS4MjMzoaurK3UYGsfQ0BCGhob57i/s566rq6v2NWNiYqJWfSJ1cCiqDNu4cSPc3d2hr6+PypUrw8fHB+np6QCA5cuXw9XVFXp6enBxccGPP/6oOM7BwQEAULduXchkMrRq1QrAq7tCTpkyBVWrVoVcLlfccyBXZmYmhg0bBhsbG+jp6cHOzk5xYyUAmDdvHtzd3WFgYIBq1aphyJAhSEtLK4VP4v20bNky2NraIicnR6m8Q4cO6NevHwBg27ZtqFevHvT09FCjRg2EhYXh5cuXiroymQxLlizBp59+CgMDA0ybNg0pKSno2bMnLCwsoK+vDycnJ6xcuRKA6qGjK1eu4JNPPoGxsTGMjIzQokULxMTEAHj7NaXKwYMH0ahRI8jlctjY2GDChAlKMbdq1QrDhg3DyJEjYW5uDl9f32J9ju+rt10/bw5F5Q4PTZs2Dba2tnB2dgYAHDt2DF5eXtDT00ODBg2wdetWpWvkzaGoiIgImJqaYteuXXB1dYWhoSHatm2LhISEPOfKlZOTg1mzZqFmzZqQy+WoXr06pk2bptg/fvx41KpVCxUrVkSNGjUQEhKCrKyskv3ASHMIKpPu3bsnKlSoIObNmydiY2PFxYsXxeLFi8XTp0/FmjVrhI2Njdi0aZO4ffu22LRpk6hUqZKIiIgQQghx6tQpAUDs3btXJCQkiOTkZCGEEPPmzRPGxsbit99+E9euXRPjxo0TOjo64saNG0IIIWbPni2qVasmDh06JOLi4sThw4fFunXrFDHNnz9f7Nu3T8TGxoqoqCjh7OwsBg8eXPofznvi0aNHQldXV+zdu1dRlpycrCg7dOiQMDY2FhERESImJkbs3r1b2Nvbi9DQUEV9AMLS0lKsWLFCxMTEiDt37oihQ4cKLy8vcfr0aREbGyv27Nkj/vzzTyGEELGxsQKAOH/+vBBCiLt374pKlSqJgIAAcfr0aXH9+nWxYsUKce3aNSHE268pVe1VrFhRDBkyRFy9elVs2bJFmJubi8mTJytibtmypTA0NBRjx44V165dU5yL1PO262fy5MnC09NTsS8wMFAYGhqKL774Qly+fFlcvnxZPHnyRFSqVEn06tVLXLlyRezcuVPUqlVL6We6f/9+AUCkpKQIIYRYuXKl0NHRET4+PuL06dPi7NmzwtXVVXz++edK5+rQoYPi9bhx44SZmZmIiIgQt27dEocPHxY///yzYv/UqVPF0aNHRWxsrPjzzz+FlZWVmDlz5jv53Kj8Y2JTRp09e1YAEHFxcXn2OTo6KiUcQrz6H79p06ZCiLy/THLZ2tqKadOmKZU1bNhQDBkyRAghxNdffy0+/PBDkZOTU6gY//jjD1G5cuXCviUqgg4dOoh+/fopXv/000/C1tZWZGdnizZt2ojp06cr1V+9erWwsbFRvAYgRo4cqVTH399f9O3bV+X53rx2goODhYODg8jMzFRZ/23X1JvtffPNN8LZ2VnpGlu8eLEwNDQU2dnZQohXiU3dunXz+0hIDQVdP6oSGysrK5GRkaEoW7JkiahcubJ4/vy5ouznn39+a2IDQNy6dUtxzOLFi4WVlZXSuXITm9TUVCGXy5USmbeZPXu2qF+/fqHr0/uFQ1FllKenJ9q0aQN3d3d06dIFP//8M1JSUpCeno6YmBj0799fMUZuaGiI7777TjE8oEpqairu3bsHb29vpXJvb29cvXoVwKvu4ejoaDg7O2P48OHYvXu3Ut29e/eiTZs2qFKlCoyMjPDFF18gOTkZz549K/kPgAAAPXv2xKZNmxRPTF67di26d+8OLS0tXLhwAVOmTFG6DgYOHIiEhASln0mDBg2U2hw8eDB+//13eHl5Ydy4cTh27Fi+54+OjkaLFi1UzsspzDX1pqtXr6Jp06ZKk0y9vb2RlpaGu3fvKsrq169fwKdChVXQ9aOKu7u70rya69evw8PDA3p6eoqyRo0avfW8FStWhKOjo+K1jY0NHjx4oLLu1atXkZGRgTZt2uTb3vr16+Ht7Q1ra2sYGhpi4sSJiI+Pf2sc9H5iYlNGaWtrY8+ePfj777/h5uaGhQsXwtnZGZcvXwYA/Pzzz4iOjlZsly9fxokTJ4p1znr16iE2NhZTp07F8+fP0bVrV3Tu3BnAq7kXn3zyCTw8PLBp0yacPXsWixcvBvBqbg69G/7+/hBCYMeOHfj3339x+PBh9OzZE8CrVS1hYWFK18GlS5dw8+ZNpV9EBgYGSm36+fnhzp07GDVqFO7du4c2bdpgzJgxKs+vr6//7t5cAd6MmYqmoOtHlZL63N9MhGUyGUQ+C3Dfdo0dP34cPXv2RLt27bB9+3acP38e3377Lb93KF9MbMowmUwGb29vhIWF4fz589DV1cXRo0dha2uL27dvo2bNmkpb7qTh3L+4srOzFW0ZGxvD1tYWR48eVTrH0aNH4ebmplSvW7du+Pnnn7F+/Xps2rQJjx49wtmzZ5GTk4O5c+eiSZMmqFWrFu7du1cKn8L7TU9PDwEBAVi7di1+++03ODs7o169egBeJaLXr1/Pcx3UrFkz37/Ic1lYWCAwMBBr1qzBggUL8n26roeHBw4fPqxyomZhr6nXubq64vjx40q/5I4ePQojIyNUrVq1wJhJfQVdP4Xh7OyMS5cuKXp8AOD06dMlGqOTkxP09fURFRWlcv+xY8dgZ2eHb7/9Fg0aNICTkxPu3LlTojGQZuFy7zLq5MmTiIqKwscffwxLS0ucPHkSDx8+hKurK8LCwjB8+HCYmJigbdu2yMjIwJkzZ5CSkoKgoCBYWlpCX18fkZGRqFq1KvT09GBiYoKxY8di8uTJcHR0hJeXF1auXIno6GisXbsWwKtVTzY2Nqhbty60tLTwxx9/wNraGqampqhZsyaysrKwcOFC+Pv74+jRo1i6dKnEn9L7oWfPnvjkk09w5coV9OrVS1E+adIkfPLJJ6hevTo6d+6sGJ66fPkyvvvuu3zbmzRpEurXr4/atWsjIyMD27dvh6urq8q6w4YNw8KFC9G9e3cEBwfDxMQEJ06cQKNGjeDs7PzWa+pNQ4YMwYIFC/D1119j2LBhuH79OiZPnoygoKC3JmNUNPldP4Xx+eef49tvv8WgQYMwYcIExMfHY86cOQBQ6HvWvI2enh7Gjx+PcePGQVdXF97e3nj48CGuXLmC/v37w8nJCfHx8fj999/RsGFD7NixA1u2bCmRc5OGknaKD+Xnn3/+Eb6+vsLCwkLI5XJRq1YtsXDhQsX+tWvXCi8vL6GrqyvMzMzEBx98IDZv3qzY//PPP4tq1aoJLS0t0bJlSyGEENnZ2SI0NFRUqVJF6OjoCE9PT/H3338rjlm2bJnw8vISBgYGwtjYWLRp00acO3dOsX/evHnCxsZG6OvrC19fX/Hrr78qTRqkdyM7O1vY2NgIACImJkZpX2RkpGjWrJnQ19cXxsbGolGjRmLZsmWK/QDEli1blI6ZOnWqcHV1Ffr6+qJSpUqiQ4cO4vbt20II1RPPL1y4ID7++GNRsWJFYWRkJFq0aKGI423XlKr2Dhw4IBo2bCh0dXWFtbW1GD9+vMjKylLsb9mypRgxYkQxPzXKld/1o2ry8OsrlXIdPXpUeHh4CF1dXVG/fn2xbt06AUCxWk3V5GETExOlNrZs2SJe/3Xz5rmys7PFd999J+zs7ISOjo6oXr260sT4sWPHisqVKwtDQ0PRrVs3MX/+/DznIMrFOw8TEVGhrV27Fn379sWTJ08km4NFVBAORRERUb5+/fVX1KhRA1WqVMGFCxcwfvx4dO3alUkNlVlMbIiIKF+JiYmYNGkSEhMTYWNjgy5duijdFZiorOFQFBEREWkMLkMgIiIijcHEhoiIiDQGExsiIiLSGExsiIiISGMwsSEiIiKNwcSGiAC8erp7x44dFa9btWqFkSNHlnocBw4cgEwmw+PHj0v93ERU/jGxISrj+vTpA5lMBplMBl1dXdSsWRNTpkzBy5cv3+l5N2/ejKlTpxaqLpMRIioreIM+onKgbdu2WLlyJTIyMrBz504MHToUOjo6CA4OVqqXmZmpeLp7cVWqVKlE2iEiKk3ssSEqB+RyOaytrWFnZ4fBgwfDx8cHf/75p2L4aNq0abC1tYWzszMA4N9//0XXrl1hamqKSpUqoUOHDoiLi1O0l52djaCgIJiamqJy5coYN24c3rxX55tDURkZGRg/fjyqVasGuVyOmjVr4pdffkFcXBxat24NADAzM4NMJkOfPn0AADk5OQgPD4eDgwP09fXh6emJjRs3Kp1n586dqFWrFvT19dG6dWulOImI1MXEhqgc0tfXR2ZmJgAgKioK169fx549e7B9+3ZkZWXB19cXRkZGOHz4MI4ePQpDQ0O0bdtWcczcuXMRERGBFStW4MiRI3j06BG2bNlS4Dl79+6N3377DT/88AOuXr2Kn376CYaGhqhWrRo2bdoEALh+/ToSEhLw/fffAwDCw8Px66+/YunSpbhy5QpGjRqFXr164eDBgwBeJWABAQHw9/dHdHQ0BgwYgAkTJryrj42I3geSPluciN4qMDBQdOjQQQghRE5OjtizZ4+Qy+VizJgxIjAwUFhZWYmMjAxF/dWrVwtnZ2eRk5OjKMvIyBD6+vpi165dQgghbGxsxKxZsxT7s7KyRNWqVRXnEUKIli1bihEjRgghhLh+/boAIPbs2aMyxv379wsAIiUlRVH24sULUbFiRXHs2DGluv379xc9evQQQggRHBws3NzclPaPHz8+T1tERIXFOTZE5cD27dthaGiIrKws5OTk4PPPP0doaCiGDh0Kd3d3pXk1Fy5cwK1bt2BkZKTUxosXLxATE4MnT54gISEBjRs3VuyrUKECGjRokGc4Kld0dDS0tbXRsmXLQsd869YtPHv2DB999JFSeWZmJurWrQsAuHr1qlIcANC0adNCn4OI6E1MbIjKgdatW2PJkiXQ1dWFra0tKlT43/+6BgYGSnXT0tJQv359rF27Nk87FhYWRTq/vr6+2sekpaUBAHbs2IEqVaoo7ZPL5UWKg4jobZjYEJUDBgYGqFmzZqHq1qtXD+vXr4elpSWMjY1V1rGxscHJkyfxwQcfAABevnyJs2fPol69eirru7u7IycnBwcPHoSPj0+e/bk9RtnZ2YoyNzc3yOVyxMfH59vT4+rqij///FOp7MSJE29/k0RE+eDkYSIN07NnT5ibm6NDhw44fPgwYmNjceDAAQwfPhx3794FAIwYMQIzZszA1q1bce3aNQwZMqTAe9DY29sjMDAQ/fr1w9atWxVtbtiwAQBgZ2cHmUyG7du34+HDh0hLS4ORkRHGjBmDUaNGYdWqVYiJicG5c+ewcOFCrFq1CgDw1Vdf4ebNmxg7diyuX7+OdevWISIi4l1/RESkwZjYEGmYihUr4tChQ6hevToCAgLg6uqK/v3748WLF4oenNGjR+OLL75AYGAgmjZtCiMjI3Tq1KnAdpcsWYLOnTtjyJAhcHFxwcCBA5Geng4AqFKlCsLCwjBhwgRYWVlh2LBhAICpU6ciJCQE4eHhcHV1Rdu2bbFjxw44ODgAAKpXr45NmzZh69at8PT0xNKlSzF9+vR3+OkQkaaTifxmCxIRERGVM+yxISIiIo3BxIaIiIg0BhMbIiIi0hhMbIiIiEhjMLEhIiIijcHEhoiIiDQGExsiIiLSGExsiIiISGMwsSEiIiKNwcSGiIiINAYTGyIiItIYTGyIiIhIY/wfaRytTyBbF4UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values\n",
        "for max_depth and min_samples_split."
      ],
      "metadata": {
        "id": "gnlfl9kHE0z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Set up the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 6, None],\n",
        "    'min_samples_split': [2, 5, 10, 20]\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Parameters:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ7raip8FDQz",
        "outputId": "98f98654-e188-4706-8402-d74cfa6143e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 10}\n",
            "Test Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    }
  ]
}