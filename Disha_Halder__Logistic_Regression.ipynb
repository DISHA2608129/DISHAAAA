{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRrzaSz/AqqWfPTaC1gVWP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DISHA2608129/DISHAAAA/blob/main/Disha_Halder__Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear Regression?"
      ],
      "metadata": {
        "id": "WcdHYorCU7O-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression\n",
        "Purpose: Predicts a continuous numerical value.\n",
        "\n",
        "How it works:\n",
        "It models the relationship between the input features (independent variables) and a continuous output (dependent variable) using a linear equation.\n",
        "\n",
        "The equation looks like this:\n",
        "\n",
        "ğ‘¦\n",
        "=\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "ğ›½\n",
        "2\n",
        "ğ‘¥\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        "y=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +Î²\n",
        "2\n",
        "â€‹\n",
        " x\n",
        "2\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        "\n",
        "The model tries to minimize the difference (error) between the predicted and actual values using techniques like least squares.\n",
        "\n",
        "Example:\n",
        "Predicting house prices based on square footage, number of bedrooms, etc.\n",
        "\n",
        "Logistic Regression\n",
        "Purpose: Predicts a categorical outcome, usually binary (like 0 or 1, Yes or No).\n",
        "\n",
        "How it works:\n",
        "Instead of predicting a continuous number, it predicts the probability of the outcome being in a certain class.\n",
        "\n",
        "Uses the logistic (sigmoid) function to squish any real-valued number into a value between 0 and 1:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "(\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        ")\n",
        "P(y=1)=\n",
        "1+e\n",
        "âˆ’(Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        " )\n",
        "\n",
        "1\n",
        "â€‹\n",
        "\n",
        "You can interpret the output as the probability that the instance belongs to class 1."
      ],
      "metadata": {
        "id": "cQv4OZvxVEH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the mathematical equation of Logistic Regression?"
      ],
      "metadata": {
        "id": "YP7WqOvhVJSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Equation\n",
        "The goal is to estimate the probability that a given input belongs to a certain class (usually class 1).\n",
        "\n",
        "Step 1: Linear Combination (like Linear Regression)\n",
        "ğ‘§\n",
        "=\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "ğ›½\n",
        "2\n",
        "ğ‘¥\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        "z=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +Î²\n",
        "2\n",
        "â€‹\n",
        " x\n",
        "2\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        "\n",
        "This is just a weighted sum of inputs, same as linear regression.\n",
        "\n",
        "Step 2: Apply the Sigmoid Function\n",
        "To convert the linear output\n",
        "ğ‘§\n",
        "z into a probability between 0 and 1, we use the sigmoid (logistic) function:\n",
        "\n",
        "ğœ\n",
        "(\n",
        "ğ‘§\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "ğ‘§\n",
        "Ïƒ(z)=\n",
        "1+e\n",
        "âˆ’z\n",
        "\n",
        "1\n",
        "â€‹\n",
        "\n",
        "So the full Logistic Regression equation becomes:\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ğ‘¥\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "(\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        ")\n",
        "P(y=1âˆ£x)=\n",
        "1+e\n",
        "âˆ’(Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        " )\n",
        "\n",
        "1\n",
        "â€‹\n",
        "\n",
        "This gives the probability that the output\n",
        "ğ‘¦\n",
        "y is 1 (positive class), given the input vector\n",
        "ğ‘¥\n",
        "x.\n",
        "\n",
        "Interpretation:\n",
        "If\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ğ‘¥\n",
        ")\n",
        ">\n",
        "0.5\n",
        "P(y=1âˆ£x)>0.5, we typically classify it as class 1\n",
        "\n",
        "If\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ğ‘¥\n",
        ")\n",
        "â‰¤\n",
        "0.5\n",
        "P(y=1âˆ£x)â‰¤0.5, we classify it as class 0\n",
        "\n",
        "Log-Odds Form\n",
        "Logistic regression models the log-odds (logit) of the outcome:\n",
        "\n",
        "log\n",
        "â¡\n",
        "(\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "1\n",
        "âˆ’\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        ")\n",
        "=\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        "log(\n",
        "1âˆ’P(y=1)\n",
        "P(y=1)\n",
        "â€‹\n",
        " )=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        "\n",
        "This linear relationship in the log-odds is what makes logistic regression a generalized linear model (GLM)."
      ],
      "metadata": {
        "id": "ZquB2ngOVSnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why do we use the Sigmoid function in Logistic Regression?"
      ],
      "metadata": {
        "id": "nx61hNolVZ1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It Converts Any Real Value into a Probability\n",
        "The output of a linear function (like in linear regression) can be any number, from\n",
        "âˆ’\n",
        "âˆ\n",
        "âˆ’âˆ to\n",
        "âˆ\n",
        "âˆ.\n",
        "But in classification, especially binary classification, we need to predict a probability â€” something between 0 and 1.\n",
        "\n",
        "The sigmoid function:\n",
        "\n",
        "ğœ\n",
        "(\n",
        "ğ‘§\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "ğ‘§\n",
        "Ïƒ(z)=\n",
        "1+e\n",
        "âˆ’z\n",
        "\n",
        "1\n",
        "â€‹\n",
        "\n",
        "takes any real-valued input\n",
        "ğ‘§\n",
        "z, and maps it to a number in the (0, 1) range.\n",
        "\n",
        "This makes it perfect for modeling probabilities.\n",
        "\n",
        "It Creates a Decision Boundary\n",
        "Once we have a probability, we can set a threshold (commonly 0.5):\n",
        "\n",
        "If\n",
        "ğœ\n",
        "(\n",
        "ğ‘§\n",
        ")\n",
        ">\n",
        "0.5\n",
        "Ïƒ(z)>0.5 â†’ predict class 1\n",
        "\n",
        "If\n",
        "ğœ\n",
        "(\n",
        "ğ‘§\n",
        ")\n",
        "â‰¤\n",
        "0.5\n",
        "Ïƒ(z)â‰¤0.5 â†’ predict class 0\n",
        "\n",
        "This gives us a clear boundary for classification.\n",
        "\n",
        "Itâ€™s Differentiable & Smooth\n",
        "The sigmoid function is smooth and differentiable, which is super important for training the model using gradient descent. That means:\n",
        "\n",
        "We can compute derivatives (gradients)\n",
        "\n",
        "We can update weights to reduce the error\n",
        "\n",
        "This makes learning from data possible and efficient.\n",
        "\n",
        "It Models Log-Odds Naturally\n",
        "Remember this log-odds relationship:\n",
        "\n",
        "log\n",
        "â¡\n",
        "(\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "1\n",
        "âˆ’\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        ")\n",
        "=\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        "log(\n",
        "1âˆ’P(y=1)\n",
        "P(y=1)\n",
        "â€‹\n",
        " )=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        "\n",
        "The sigmoid function is the inverse of the logit (log-odds), so it's mathematically consistent with the model weâ€™re trying to build."
      ],
      "metadata": {
        "id": "oY4zDEn5VeKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the cost function of Logistic Regression?"
      ],
      "metadata": {
        "id": "12aGrvseVpg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost Function of Logistic Regression\n",
        "In logistic regression, we can't use mean squared error (MSE) like in linear regression â€” because:\n",
        "\n",
        "The sigmoid function is non-linear, and\n",
        "\n",
        "MSE would result in a non-convex cost function, making optimization harder.\n",
        "\n",
        "Instead, we use a special cost function based on log-likelihood:\n",
        "\n",
        "Binary Cross-Entropy (a.k.a. Log Loss)\n",
        "ğ½\n",
        "(\n",
        "ğœƒ\n",
        ")\n",
        "=\n",
        "âˆ’\n",
        "1\n",
        "ğ‘š\n",
        "âˆ‘\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "ğ‘š\n",
        "[\n",
        "ğ‘¦\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        "log\n",
        "â¡\n",
        "(\n",
        "â„\n",
        "ğœƒ\n",
        "(\n",
        "ğ‘¥\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "âˆ’\n",
        "ğ‘¦\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        "log\n",
        "â¡\n",
        "(\n",
        "1\n",
        "âˆ’\n",
        "â„\n",
        "ğœƒ\n",
        "(\n",
        "ğ‘¥\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        ")\n",
        "]\n",
        "J(Î¸)=âˆ’\n",
        "m\n",
        "1\n",
        "â€‹\n",
        "  \n",
        "i=1\n",
        "âˆ‘\n",
        "m\n",
        "â€‹\n",
        " [y\n",
        "(i)\n",
        " log(h\n",
        "Î¸\n",
        "â€‹\n",
        " (x\n",
        "(i)\n",
        " ))+(1âˆ’y\n",
        "(i)\n",
        " )log(1âˆ’h\n",
        "Î¸\n",
        "â€‹\n",
        " (x\n",
        "(i)\n",
        " ))]\n",
        "Where:\n",
        "\n",
        "ğ‘š\n",
        "m: number of training examples\n",
        "\n",
        "ğ‘¦\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        "y\n",
        "(i)\n",
        " : actual label (0 or 1)\n",
        "\n",
        "â„\n",
        "ğœƒ\n",
        "(\n",
        "ğ‘¥\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        "h\n",
        "Î¸\n",
        "â€‹\n",
        " (x\n",
        "(i)\n",
        " ): predicted probability = sigmoid function output\n",
        "\n",
        "ğœƒ\n",
        "Î¸: model parameters (weights)"
      ],
      "metadata": {
        "id": "4iYKYl2NVw2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What is Regularization in Logistic Regression? Why is it needed?"
      ],
      "metadata": {
        "id": "4oXhufhjVzTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Regularization?\n",
        "Regularization is a technique used to prevent overfitting by adding a penalty to the loss (cost) function. In simple terms:\n",
        "\n",
        "It discourages the model from fitting the noise in the training data by keeping the model weights small.\n",
        "\n",
        "In logistic regression, regularization helps control the magnitude of the weights\n",
        "ğœƒ\n",
        "Î¸, especially when there are many features.\n",
        "\n",
        "Why is it needed?\n",
        "Without regularization:\n",
        "\n",
        "Your model might become too complex (especially with lots of features).\n",
        "\n",
        "It might fit the training data too well â€” capturing noise instead of true patterns.\n",
        "\n",
        "This leads to overfitting, where your model performs great on training data but poorly on unseen data.\n",
        "\n",
        "Regularization solves this by making the model simpler and more generalizable.\n",
        "\n",
        "Types of Regularization (in Logistic Regression)\n",
        "L2 Regularization (Ridge) â€” Most Common\n",
        "Adds the sum of squares of weights to the cost function:\n",
        "\n",
        "ğ½\n",
        "(\n",
        "ğœƒ\n",
        ")\n",
        "=\n",
        "âˆ’\n",
        "1\n",
        "ğ‘š\n",
        "âˆ‘\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "ğ‘š\n",
        "[\n",
        "ğ‘¦\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        "log\n",
        "â¡\n",
        "(\n",
        "â„\n",
        "ğœƒ\n",
        "(\n",
        "ğ‘¥\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        ")\n",
        "+\n",
        "(\n",
        "1\n",
        "âˆ’\n",
        "ğ‘¦\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        "log\n",
        "â¡\n",
        "(\n",
        "1\n",
        "âˆ’\n",
        "â„\n",
        "ğœƒ\n",
        "(\n",
        "ğ‘¥\n",
        "(\n",
        "ğ‘–\n",
        ")\n",
        ")\n",
        ")\n",
        "]\n",
        "+\n",
        "ğœ†\n",
        "2\n",
        "ğ‘š\n",
        "âˆ‘\n",
        "ğ‘—\n",
        "=\n",
        "1\n",
        "ğ‘›\n",
        "ğœƒ\n",
        "ğ‘—\n",
        "2\n",
        "J(Î¸)=âˆ’\n",
        "m\n",
        "1\n",
        "â€‹\n",
        "  \n",
        "i=1\n",
        "âˆ‘\n",
        "m\n",
        "â€‹\n",
        " [y\n",
        "(i)\n",
        " log(h\n",
        "Î¸\n",
        "â€‹\n",
        " (x\n",
        "(i)\n",
        " ))+(1âˆ’y\n",
        "(i)\n",
        " )log(1âˆ’h\n",
        "Î¸\n",
        "â€‹\n",
        " (x\n",
        "(i)\n",
        " ))]+\n",
        "2m\n",
        "Î»\n",
        "â€‹\n",
        "  \n",
        "j=1\n",
        "âˆ‘\n",
        "n\n",
        "â€‹\n",
        " Î¸\n",
        "j\n",
        "2\n",
        "â€‹\n",
        "\n",
        "ğœ†\n",
        "Î» is the regularization strength (bigger = more penalty)\n",
        "\n",
        "ğœƒ\n",
        "ğ‘—\n",
        "2\n",
        "Î¸\n",
        "j\n",
        "2\n",
        "â€‹\n",
        "  ensures weights are penalized for being too large\n",
        "\n",
        "ğŸ”¹ L1 Regularization (Lasso)\n",
        "Adds the sum of absolute values of weights:\n",
        "\n",
        "ğ½\n",
        "(\n",
        "ğœƒ\n",
        ")\n",
        "+\n",
        "ğœ†\n",
        "ğ‘š\n",
        "âˆ‘\n",
        "ğ‘—\n",
        "=\n",
        "1\n",
        "ğ‘›\n",
        "âˆ£\n",
        "ğœƒ\n",
        "ğ‘—\n",
        "âˆ£\n",
        "J(Î¸)+\n",
        "m\n",
        "Î»\n",
        "â€‹\n",
        "  \n",
        "j=1\n",
        "âˆ‘\n",
        "n\n",
        "â€‹\n",
        " âˆ£Î¸\n",
        "j\n",
        "â€‹\n",
        " âˆ£\n",
        "Encourages sparse models (some weights become exactly 0)\n",
        "\n",
        "Good for feature selection"
      ],
      "metadata": {
        "id": "K8E-RIDWV78l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression."
      ],
      "metadata": {
        "id": "Z15VraP4V_qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso, Ridge, and Elastic Net regression are all techniques used to improve model performance and prevent overfitting by applying regularization, but they differ in how they penalize model complexity. Ridge regression (L2 regularization) adds a penalty equal to the square of the magnitude of the coefficients, which encourages the model to keep all features but with smaller weights â€” it's useful when you have many features that are all somewhat relevant. Lasso regression (L1 regularization), on the other hand, adds a penalty equal to the absolute value of the coefficients, which can shrink some coefficients exactly to zero, effectively performing feature selection and resulting in a sparse model â€” great when only a few features matter. Elastic Net regression combines both L1 and L2 penalties, striking a balance between Ridge and Lasso. It is especially helpful when dealing with highly correlated features or when neither L1 nor L2 alone works best. In summary, Ridge shrinks all features, Lasso selects important ones, and Elastic Net blends both strategies for more flexibility.\n",
        "\n"
      ],
      "metadata": {
        "id": "MY3RqFisWFF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. When should we use Elastic Net instead of Lasso or Ridge?"
      ],
      "metadata": {
        "id": "Szzlq_ByWG7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Elastic Net When:\n",
        "1. You Have Many Correlated Features\n",
        "Lasso tends to pick just one feature from a group of correlated features and ignore the rest.\n",
        "\n",
        "Ridge keeps all correlated features but doesn't do feature selection.\n",
        "\n",
        "Elastic Net handles this better by balancing both â€” it tends to group correlated features and shrink them together, rather than dropping some.\n",
        "\n",
        "2. You Want Both Feature Selection and Stability\n",
        "Lasso can be unstable â€” small changes in data can lead to big changes in selected features.\n",
        "\n",
        "Elastic Net adds the L2 penalty to stabilize things while still zeroing out less important features with the L1 penalty.\n",
        "\n",
        "3. The Number of Features (p) Is Greater Than the Number of Samples (n)\n",
        "In high-dimensional datasets (common in genetics, text data, etc.), Elastic Net often outperforms both Ridge and Lasso.\n",
        "\n",
        "Lasso may select too few features, while Ridge includes all. Elastic Net balances the two.\n",
        "\n",
        "4. Youâ€™re Not Sure Which Regularization Is Better\n",
        "Elastic Net has a mixing parameter\n",
        "ğ›¼\n",
        "Î± that lets you adjust the L1 vs. L2 contribution.\n",
        "\n",
        "ğ›¼\n",
        "=\n",
        "1\n",
        "Î±=1 â†’ behaves like Lasso\n",
        "\n",
        "ğ›¼\n",
        "=\n",
        "0\n",
        "Î±=0 â†’ behaves like Ridge\n",
        "\n",
        "You can tune\n",
        "ğ›¼\n",
        "Î± during cross-validation to find the best balance"
      ],
      "metadata": {
        "id": "nqTbZCIzWMax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the impact of the regularization parameter (Î») in Logistic Regression?"
      ],
      "metadata": {
        "id": "KXPoYcCXWQ-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The regularization parameter\n",
        "ğœ†\n",
        "Î» (lambda) in logistic regression controls the strength of the penalty applied to the modelâ€™s coefficients and plays a crucial role in balancing model complexity and performance. A small\n",
        "ğœ†\n",
        "Î» means less regularization, allowing the model to fit the training data more closely, which may lead to overfitting if the model becomes too complex. Conversely, a large\n",
        "ğœ†\n",
        "Î» increases the regularization effect, shrinking the coefficients more aggressively toward zero, which can simplify the model and help prevent overfitting â€” but if it's too large, it may cause underfitting, where the model becomes too simple to capture important patterns in the data. Essentially,\n",
        "ğœ†\n",
        "Î» acts as a tuning knob that influences how much the model resists complexity, and choosing the right value (often through cross-validation) is key to achieving a good balance between bias and variance."
      ],
      "metadata": {
        "id": "j7o7GVG9WWMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What are the key assumptions of Logistic Regression?"
      ],
      "metadata": {
        "id": "6xvEnsn4WYl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Assumptions of Logistic Regression:\n",
        "1. Binary or Categorical Outcome\n",
        "Logistic regression is designed for binary classification (e.g., 0 or 1, yes or no).\n",
        "\n",
        "It can be extended to multiclass problems (with multinomial logistic regression), but standard logistic regression assumes a binary dependent variable.\n",
        "\n",
        "2. Linearity of Log-Odds\n",
        "Logistic regression does not assume a linear relationship between predictors and the outcome itself.\n",
        "\n",
        "But it does assume a linear relationship between the independent variables and the log-odds of the outcome.\n",
        "\n",
        "This means:\n",
        "\n",
        "log\n",
        "â¡\n",
        "(\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "1\n",
        "âˆ’\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        ")\n",
        "=\n",
        "ğ›½\n",
        "0\n",
        "+\n",
        "ğ›½\n",
        "1\n",
        "ğ‘¥\n",
        "1\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ›½\n",
        "ğ‘›\n",
        "ğ‘¥\n",
        "ğ‘›\n",
        "log(\n",
        "1âˆ’P(y=1)\n",
        "P(y=1)\n",
        "â€‹\n",
        " )=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        "\n",
        "3. No or Little Multicollinearity\n",
        "The model assumes that the independent variables are not too highly correlated with each other.\n",
        "\n",
        "High multicollinearity can make it hard to estimate coefficients accurately.\n",
        "\n",
        "4. Independent Observations\n",
        "Each observation (data point) is assumed to be independent of the others.\n",
        "\n",
        "Violating this (like with time series or grouped data) can lead to biased results unless adjustments are made (e.g., using mixed models).\n",
        "\n",
        "5. Large Sample Size\n",
        "Logistic regression works best with a relatively large sample size, especially when the event (class 1) is rare.\n",
        "\n",
        "A small dataset can lead to unstable estimates."
      ],
      "metadata": {
        "id": "vWCrQOETWcYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are some alternatives to Logistic Regression for classification tasks?"
      ],
      "metadata": {
        "id": "Lg1hhc_CWgVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatives to Logistic Regression for Classification:\n",
        "1. Decision Trees\n",
        "Intuitive, easy to visualize.\n",
        "\n",
        "Handles non-linear relationships well.\n",
        "\n",
        "Can overfit easily, but fast and interpretable.\n",
        "\n",
        "2. Random Forest\n",
        "An ensemble of decision trees (bagging).\n",
        "\n",
        "More robust and accurate than a single decision tree.\n",
        "\n",
        "Handles high-dimensional and non-linear data well.\n",
        "\n",
        "Less interpretable than logistic regression.\n",
        "\n",
        "3. Support Vector Machines (SVM)\n",
        "Great for high-dimensional spaces and complex boundaries.\n",
        "\n",
        "Uses kernel tricks to separate data non-linearly.\n",
        "\n",
        "Can be slower on large datasets; not very interpretable.\n",
        "\n",
        "4. K-Nearest Neighbors (KNN)\n",
        "Instance-based, non-parametric model.\n",
        "\n",
        "Makes predictions based on the \"closeness\" of neighbors.\n",
        "\n",
        "Simple, but can be slow and sensitive to irrelevant features or scaling.\n",
        "\n",
        "5. Naive Bayes\n",
        "Based on Bayes' Theorem with a strong assumption of feature independence.\n",
        "\n",
        "Works well with text classification and spam detection.\n",
        "\n",
        "Fast, but the independence assumption can be unrealistic.\n",
        "\n",
        "6. Gradient Boosting Machines (GBM, XGBoost, LightGBM, CatBoost)\n",
        "Powerful ensemble methods that build trees sequentially.\n",
        "\n",
        "Often deliver state-of-the-art performance on structured/tabular data.\n",
        "\n",
        "More complex and computationally intensive, but highly accurate."
      ],
      "metadata": {
        "id": "lVQNilE1WnJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are Classification Evaluation Metrics?"
      ],
      "metadata": {
        "id": "X8zJ0VgWWnwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification evaluation metrics help assess the performance of a classification model. These metrics are crucial for understanding how well your model is performing, especially when dealing with imbalanced datasets or when trying to optimize for specific outcomes (e.g., minimizing false positives or maximizing recall). Here's a breakdown of the key evaluation metrics for classification tasks:\n",
        "\n",
        "1. Accuracy\n",
        "Definition: The ratio of correctly predicted observations to the total observations.\n",
        "\n",
        "Accuracy\n",
        "=\n",
        "TrueÂ Positives\n",
        "+\n",
        "TrueÂ Negatives\n",
        "TotalÂ Observations\n",
        "Accuracy=\n",
        "TotalÂ Observations\n",
        "TrueÂ Positives+TrueÂ Negatives\n",
        "â€‹\n",
        "\n",
        "When to use: Good for balanced datasets where the class distribution is relatively even.\n",
        "\n",
        "Limitations: Not ideal for imbalanced classes (e.g., rare events), as it might be misleading (e.g., 95% accuracy in a dataset where 95% of the instances are from the majority class).\n",
        "\n",
        "2. Precision\n",
        "Definition: The proportion of positive predictions that are actually correct.\n",
        "\n",
        "Precision\n",
        "=\n",
        "TrueÂ Positives\n",
        "TrueÂ Positives\n",
        "+\n",
        "FalseÂ Positives\n",
        "Precision=\n",
        "TrueÂ Positives+FalseÂ Positives\n",
        "TrueÂ Positives\n",
        "â€‹\n",
        "\n",
        "When to use: Important when the cost of false positives is high (e.g., predicting a disease when the person doesn't have it).\n",
        "\n",
        "3. Recall (Sensitivity, True Positive Rate)\n",
        "Definition: The proportion of actual positives that are correctly identified by the model.\n",
        "\n",
        "Recall\n",
        "=\n",
        "TrueÂ Positives\n",
        "TrueÂ Positives\n",
        "+\n",
        "FalseÂ Negatives\n",
        "Recall=\n",
        "TrueÂ Positives+FalseÂ Negatives\n",
        "TrueÂ Positives\n",
        "â€‹\n",
        "\n",
        "When to use: Critical when the cost of false negatives is high (e.g., not detecting a disease when the person actually has it).\n",
        "\n",
        "4. F1 Score\n",
        "Definition: The harmonic mean of Precision and Recall, combining both into a single metric.\n",
        "\n",
        "F1Â Score\n",
        "=\n",
        "2\n",
        "Ã—\n",
        "Precision\n",
        "Ã—\n",
        "Recall\n",
        "Precision\n",
        "+\n",
        "Recall\n",
        "F1Â Score=2Ã—\n",
        "Precision+Recall\n",
        "PrecisionÃ—Recall\n",
        "â€‹\n",
        "\n",
        "When to use: Useful when you need a balance between Precision and Recall, especially when the class distribution is imbalanced.\n",
        "\n",
        "5. ROC-AUC (Receiver Operating Characteristic - Area Under Curve)\n",
        "Definition: A plot of the True Positive Rate (Recall) versus the False Positive Rate (1 - Specificity), and the AUC is the area under this curve. A higher AUC indicates better model performance.\n",
        "\n",
        "ROC Curve: Plots Recall against the False Positive Rate.\n",
        "\n",
        "AUC: The area under this curve, with values between 0 and 1. A model with an AUC of 0.5 is no better than random guessing, and a model with an AUC of 1 is perfect.\n",
        "\n",
        "When to use: Useful for evaluating models, especially when the classes are imbalanced.\n",
        "\n"
      ],
      "metadata": {
        "id": "fqa68poiWyGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How does class imbalance affect Logistic Regression?"
      ],
      "metadata": {
        "id": "ZHnGyuIjWznD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effects of Class Imbalance on Logistic Regression:\n",
        "1. Skewed Prediction Probabilities\n",
        "In the case of class imbalance, logistic regression may tend to predict the majority class more often because it simply learns to minimize the overall error, which might lead to a high accuracy but poor performance on the minority class. This happens because the model is mostly concerned with minimizing the total error, and since the majority class is dominant, itâ€™s easier for the model to predict it correctly.\n",
        "\n",
        "For example, in a dataset where 95% of the instances are class 0 and only 5% are class 1, the model might learn that always predicting class 0 results in high accuracy, even though it's not capturing any true positives for class 1.\n",
        "\n",
        "2. Poor Recall for Minority Class\n",
        "Logistic regression can have low recall for the minority class (i.e., it's poor at identifying true positives for that class). This means the model may miss many actual positive cases because itâ€™s too focused on predicting the majority class. In medical diagnoses or fraud detection, for example, this can be problematic â€” false negatives (missing a disease or fraudulent transaction) can have serious consequences.\n",
        "\n",
        "3. Bias Toward Majority Class\n",
        "Because logistic regression optimizes based on the log-likelihood (which is influenced by the overall distribution of the classes), the model can become biased toward the majority class. It might assign very high probabilities to the majority class, even if the features suggest otherwise, leading to poor performance on the minority class."
      ],
      "metadata": {
        "id": "g3K_lLkTW6S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  What is Hyperparameter Tuning in Logistic Regression?"
      ],
      "metadata": {
        "id": "ieBVTCvKW7HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning in logistic regression refers to the process of selecting the best set of hyperparameters that optimize the model's performance. Unlike model parameters (such as the coefficients in logistic regression), hyperparameters are not learned from the data but are set before training begins. These hyperparameters control how the model is trained and can significantly impact the model's accuracy, generalizability, and ability to avoid overfitting.\n",
        "\n",
        "In the case of logistic regression, there are a few key hyperparameters to tune:\n",
        "\n",
        "Key Hyperparameters in Logistic Regression:\n",
        "Regularization Strength (\n",
        "ğœ†\n",
        "Î» or C)\n",
        "\n",
        "What it is: In logistic regression, regularization helps control overfitting by penalizing large coefficients. The regularization parameter\n",
        "ğœ†\n",
        "Î» (often denoted as C in scikit-learn) controls the strength of the regularization.\n",
        "\n",
        "A larger\n",
        "ğœ†\n",
        "Î» (or smaller C) increases the regularization strength, making the model simpler by shrinking the coefficients.\n",
        "\n",
        "A smaller\n",
        "ğœ†\n",
        "Î» (or larger C) reduces the regularization strength, allowing the model to fit the data more closely.\n",
        "\n",
        "Impact: The value of\n",
        "ğœ†\n",
        "Î» (or C) controls the bias-variance trade-off. A large regularization term may lead to underfitting (high bias), while a small value can lead to overfitting (high variance).\n",
        "\n",
        "Regularization Type (penalty)\n",
        "\n",
        "What it is: This hyperparameter specifies the type of regularization to apply:\n",
        "\n",
        "l1: Lasso regularization, which can make some coefficients exactly zero (feature selection).\n",
        "\n",
        "l2: Ridge regularization, which keeps all coefficients small but non-zero.\n",
        "\n",
        "elasticnet: A mix of L1 and L2 regularization, useful when you need a balance between feature selection and coefficient shrinkage."
      ],
      "metadata": {
        "id": "RZotvRnkXC-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What are different solvers in Logistic Regression? Which one should be used?"
      ],
      "metadata": {
        "id": "qWlHya1CXDos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In logistic regression, the solver determines the optimization algorithm used to find the best-fit coefficients for the model. Different solvers are available in libraries like scikit-learn, each with its own strengths and weaknesses. Choosing the right solver can significantly impact training speed and model performance, depending on your dataset and the specific problem.\n",
        "\n",
        "\n",
        "1. 'liblinear'\n",
        "Description:\n",
        "\n",
        "The 'liblinear' solver is a coordinate descent algorithm and is particularly well-suited for smaller datasets and models with L1 (Lasso) regularization.\n",
        "\n",
        "It is efficient and handles binary classification well.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Works well for small to medium-sized datasets.\n",
        "\n",
        "Supports both L1 and L2 regularization.\n",
        "\n",
        "Useful for sparse datasets (datasets with a lot of zeros).\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Not as efficient for large datasets compared to other solvers.\n",
        "\n",
        "May not converge as quickly on large, complex datasets.\n",
        "\n",
        "When to use:\n",
        "\n",
        "Best when the dataset is small or medium.\n",
        "\n",
        "If you need to use L1 regularization (feature selection).\n",
        "\n",
        "When the dataset is sparse and contains many zero features.\n",
        "\n",
        "2. 'newton-cg'\n",
        "Description:\n",
        "\n",
        "The 'newton-cg' solver uses Newton's method (a second-order optimization method) and is generally used for large datasets with L2 (Ridge) regularization.\n",
        "\n",
        "It's suitable for multiclass classification problems (one-vs-rest approach).\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Efficient for large datasets.\n",
        "\n",
        "Faster convergence compared to first-order solvers (like 'liblinear') when working with large data.\n",
        "\n",
        "Can handle multiclass classification.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Limited to L2 regularization (can't use L1 regularization).\n",
        "\n",
        "Computationally more expensive than solvers like 'liblinear' for small datasets.\n",
        "\n",
        "When to use:\n",
        "\n",
        "Best for large datasets.\n",
        "\n",
        "When you're working with multiclass classification problems.\n",
        "\n",
        "If you require L2 regularization.\n",
        "\n",
        "3. 'lbfgs'\n",
        "Description:\n",
        "\n",
        "The 'lbfgs' solver is an approximation of Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, which is a quasi-Newton method for optimization.\n",
        "\n",
        "It's commonly used for multiclass classification and works well with both L1 and L2 regularization.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Efficient and fast for larger datasets.\n",
        "\n",
        "Works well with L2 regularization and can handle multiclass classification.\n",
        "\n",
        "More stable and faster than the 'newton-cg' solver for smaller datasets.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Memory intensive for very large datasets.\n",
        "\n",
        "May not be the best choice for high-dimensional sparse data (compared to 'liblinear').\n",
        "\n",
        "When to use:\n",
        "\n",
        "Use when you need a fast and robust solver for multiclass classification and can work with L2 regularization.\n",
        "\n",
        "Best for medium to large datasets.\n",
        "\n",
        "4. 'sag'\n",
        "Description:\n",
        "\n",
        "The 'sag' (Stochastic Average Gradient) solver is an optimization algorithm that uses a stochastic approximation method. It is efficient for large datasets and works with L2 regularization.\n",
        "\n",
        "It's especially useful when the data is dense.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Fast convergence for large datasets.\n",
        "\n",
        "Works well with L2 regularization.\n",
        "\n",
        "Can handle multiclass classification (one-vs-rest approach).\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Requires dense datasets (not ideal for sparse data).\n",
        "\n",
        "May not converge as quickly for smaller datasets.\n",
        "\n",
        "When to use:\n",
        "\n",
        "Ideal for large, dense datasets.\n",
        "\n",
        "When using L2 regularization and needing a fast solution.\n",
        "\n",
        "5. 'saga'\n",
        "Description:\n",
        "\n",
        "The 'saga' solver is an extension of sag that supports both L1 and L2 regularization. It's a variant of stochastic gradient descent (SGD) and is particularly useful for sparse datasets.\n",
        "\n",
        "It can handle multiclass classification (one-vs-rest) and is suitable for high-dimensional data.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Supports L1 and L2 regularization.\n",
        "\n",
        "Efficient on large datasets, particularly when the data is sparse.\n",
        "\n",
        "Can be used for multiclass classification.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Can be slower on dense datasets compared to other solvers like 'lbfgs'.\n",
        "\n",
        "May require more iterations to converge.\n",
        "\n",
        "When to use:\n",
        "\n",
        "Use when dealing with sparse datasets and need L1 regularization or both L1 and L2 regularization.\n",
        "\n",
        "Works well for large datasets and multiclass classification."
      ],
      "metadata": {
        "id": "pUKigC6xXIXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How is Logistic Regression extended for multiclass classification?"
      ],
      "metadata": {
        "id": "a0BIm7cjXVMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In logistic regression, the standard model is designed for binary classification, where the goal is to predict one of two possible classes. However, when dealing with multiclass classification (where there are more than two possible classes), logistic regression can be extended using two common techniques: One-vs-Rest (OvR) and Multinomial Logistic Regression.\n",
        "\n",
        "One-vs-Rest (OvR): This approach, also called One-vs-All, involves training a separate binary logistic regression model for each class. For each class, the model learns to distinguish that class from all the others. At prediction time, the model with the highest predicted probability is chosen as the class. This method is widely used and works well when the classes are not mutually exclusive.\n",
        "\n",
        "Multinomial Logistic Regression: In contrast to the OvR method, multinomial logistic regression (also known as softmax regression) directly generalizes logistic regression to handle multiple classes simultaneously by using a softmax function to model the probability distribution over all classes. This method is more efficient because it optimizes the parameters jointly for all classes, rather than training separate models. The softmax function computes the probability of each class by normalizing the exponential of the raw model outputs (logits) so that they sum to one, ensuring they represent valid probabilities."
      ],
      "metadata": {
        "id": "dxlND6NWXbGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are the advantages and disadvantages of Logistic Regression?"
      ],
      "metadata": {
        "id": "R8E2myO7XfGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of Logistic Regression:\n",
        "Simplicity and Interpretability:\n",
        "\n",
        "Logistic regression is easy to implement and understand, making it a great choice for simple classification tasks. The model provides probabilities for class membership, which can be interpreted directly.\n",
        "\n",
        "The coefficients learned by the model can be easily interpreted as the influence of each feature on the probability of the target class, making it highly transparent and explainable.\n",
        "\n",
        "Efficient for Linearly Separable Data:\n",
        "\n",
        "Logistic regression works particularly well when the classes are linearly separable, i.e., when a straight line (or hyperplane in higher dimensions) can separate the classes in the feature space.\n",
        "\n",
        "Faster Training:\n",
        "\n",
        "Logistic regression typically requires less computational power and shorter training times compared to more complex models like decision trees or neural networks, making it a good choice for datasets with fewer features and fewer data points.\n",
        "\n",
        "Probabilistic Output:\n",
        "\n",
        "Unlike models that just predict a class label, logistic regression outputs probabilities for each class, which can be useful when you need a measure of confidence in the predictions.\n",
        "\n",
        "Regularization Support:\n",
        "\n",
        "Logistic regression supports regularization (like L1 or L2 regularization) to prevent overfitting, making it robust to datasets with irrelevant or redundant features.\n",
        "\n",
        "Works Well with Small Datasets:\n",
        "\n",
        "Logistic regression is effective even with small datasets, particularly when the number of features is not too high.\n",
        "\n",
        "Disadvantages of Logistic Regression:\n",
        "Limited to Linear Decision Boundaries:\n",
        "\n",
        "Logistic regression assumes a linear relationship between the features and the target class. If the true decision boundary between classes is non-linear, logistic regression may not perform well without feature engineering (e.g., using polynomial features) or kernel tricks.\n",
        "\n",
        "Sensitive to Outliers:\n",
        "\n",
        "Logistic regression can be sensitive to outliers in the data, as outliers can significantly affect the modelâ€™s coefficients, leading to poor generalization on unseen data.\n",
        "\n",
        "Struggles with Complex Relationships:\n",
        "\n",
        "While logistic regression can model linear decision boundaries, it may not capture complex, non-linear relationships in the data without additional feature transformations (e.g., using interaction terms, higher-order polynomials, or kernel methods).\n",
        "\n",
        "Feature Engineering Required:\n",
        "\n",
        "Logistic regression works best with clean and well-prepared data. In many cases, you'll need to carefully engineer features to improve the modelâ€™s performance, particularly for non-linear problems.\n",
        "\n",
        "Performance in High-Dimensional Spaces:\n",
        "\n",
        "While logistic regression can handle high-dimensional data, it may not perform well if there are too many features compared to the number of observations (known as the curse of dimensionality), unless proper regularization is applied.\n",
        "\n",
        "Assumption of Independence of Features:\n",
        "\n",
        "Logistic regression assumes that the features are independent of one another (this assumption can be relaxed with regularization), but in practice, many real-world datasets have correlated features, which can impact performance."
      ],
      "metadata": {
        "id": "OPbqiXTRXjDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are some use cases of Logistic Regression?"
      ],
      "metadata": {
        "id": "dXrocEhQXltR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Spam Email Detection (Binary Classification):\n",
        "Problem: Classifying emails as either spam or not spam.\n",
        "\n",
        "Why Logistic Regression: It can be used to predict the probability that an email belongs to the spam category based on features like word frequency, sender address, and other email metadata. The simplicity of logistic regression makes it suitable for this task where a linear decision boundary often works well.\n",
        "\n",
        "2. Customer Churn Prediction:\n",
        "Problem: Predicting whether a customer will churn (leave a service) or stay.\n",
        "\n",
        "Why Logistic Regression: In industries like telecommunications, banking, and subscription services, logistic regression can help predict customer behavior based on historical data (e.g., customer demographics, usage patterns, and service complaints). The model can output the probability that a customer will leave, helping businesses take preventive action.\n",
        "\n",
        "3. Loan Default Prediction:\n",
        "Problem: Determining whether a borrower will default on a loan.\n",
        "\n",
        "Why Logistic Regression: Financial institutions use logistic regression to assess the risk of a loan default based on factors such as income, credit score, debt-to-income ratio, and employment history. Logistic regression provides a simple way to predict binary outcomes (default/no default) and assess risk probabilities.\n",
        "\n",
        "4. Medical Diagnosis (Disease Prediction):\n",
        "Problem: Predicting whether a patient has a certain disease or not (e.g., cancer, diabetes).\n",
        "\n",
        "Why Logistic Regression: Logistic regression is commonly used in healthcare for diagnosing diseases based on various features like age, symptoms, test results, and medical history. For example, predicting whether a patient has diabetes based on factors like blood sugar levels, BMI, and age.\n",
        "\n",
        "5. Credit Scoring:\n",
        "Problem: Assessing the likelihood of a person being creditworthy (whether to approve a credit application).\n",
        "\n",
        "Why Logistic Regression: Financial institutions use logistic regression to analyze historical data on individuals' credit histories and other factors (e.g., income, current debts) to classify applicants as either \"approved\" or \"denied\" for a loan or credit card."
      ],
      "metadata": {
        "id": "Rs2yssKEXr6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the difference between Softmax Regression and Logistic Regression?"
      ],
      "metadata": {
        "id": "4Rg71OjZXsdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax Regression and Logistic Regression are both used for classification tasks, but they differ in how they handle different types of classification problemsâ€”binary classification versus multiclass classification.\n",
        "\n",
        "Hereâ€™s a breakdown of the differences between Softmax Regression and Logistic Regression:\n",
        "\n",
        "1. Nature of the Classification Problem:\n",
        "Logistic Regression:\n",
        "\n",
        "Primarily used for binary classification problems, where there are only two classes (e.g., yes/no, true/false, 0/1).\n",
        "\n",
        "The model outputs a probability that the instance belongs to one of the two classes (usually class 1), and the probability of the other class is implicitly 1 minus the probability of class 1.\n",
        "\n",
        "Softmax Regression:\n",
        "\n",
        "An extension of logistic regression that is used for multiclass classification problems, where there are more than two classes (e.g., classifying an image as one of several possible categories).\n",
        "\n",
        "The model outputs a probability distribution over multiple classes (i.e., the probability of each class, with all probabilities summing to 1).\n",
        "\n",
        "2. Mathematical Representation:\n",
        "Logistic Regression:\n",
        "\n",
        "The model uses a sigmoid function (also known as the logistic function) to map the input into a probability for the positive class (class 1):\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ğ‘‹\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "(\n",
        "ğ‘¤\n",
        "ğ‘‡\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        ")\n",
        "P(y=1âˆ£X)=\n",
        "1+e\n",
        "âˆ’(w\n",
        "T\n",
        " X+b)\n",
        "\n",
        "1\n",
        "â€‹\n",
        "\n",
        "The output is a probability for one class (usually class 1) and the decision threshold is typically 0.5 (if the probability is greater than 0.5, the instance is classified as class 1; otherwise, class 0).\n",
        "\n",
        "Softmax Regression:\n",
        "\n",
        "Softmax regression generalizes logistic regression for multiclass classification by using the softmax function to compute probabilities for each class:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "ğ‘˜\n",
        "âˆ£\n",
        "ğ‘‹\n",
        ")\n",
        "=\n",
        "ğ‘’\n",
        "ğ‘¤\n",
        "ğ‘˜\n",
        "ğ‘‡\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "ğ‘˜\n",
        "âˆ‘\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "ğ¶\n",
        "ğ‘’\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "ğ‘‡\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "ğ‘–\n",
        "P(y=kâˆ£X)=\n",
        "âˆ‘\n",
        "i=1\n",
        "C\n",
        "â€‹\n",
        " e\n",
        "w\n",
        "i\n",
        "T\n",
        "â€‹\n",
        " X+b\n",
        "i\n",
        "â€‹\n",
        "\n",
        "\n",
        "e\n",
        "w\n",
        "k\n",
        "T\n",
        "â€‹\n",
        " X+b\n",
        "k\n",
        "â€‹\n",
        "\n",
        "\n",
        "â€‹\n",
        "\n",
        "Here,\n",
        "ğ¶\n",
        "C is the number of classes, and\n",
        "ğ‘¤\n",
        "ğ‘˜\n",
        "ğ‘‡\n",
        "ğ‘‹\n",
        "+\n",
        "ğ‘\n",
        "ğ‘˜\n",
        "w\n",
        "k\n",
        "T\n",
        "â€‹\n",
        " X+b\n",
        "k\n",
        "â€‹\n",
        "  is the linear combination for each class\n",
        "ğ‘˜\n",
        "k. The softmax function ensures that the sum of the probabilities across all classes equals 1.\n",
        "\n",
        "3. Output:\n",
        "Logistic Regression:\n",
        "\n",
        "Outputs a single probability for the positive class (class 1) in binary classification, which can be thresholded to make the decision between two classes.\n",
        "\n",
        "Softmax Regression:\n",
        "\n",
        "Outputs multiple probabilities, one for each class, in multiclass classification. The class with the highest probability is typically chosen as the predicted class.\n",
        "\n",
        "4. Type of Problems:\n",
        "Logistic Regression:\n",
        "\n",
        "Used for binary classification, where there are two possible classes.\n",
        "\n",
        "Softmax Regression:\n",
        "\n",
        "Used for multiclass classification, where there are more than two classes. It can handle scenarios where there are multiple categories (e.g., classifying an image as one of 10 possible classes).\n",
        "\n"
      ],
      "metadata": {
        "id": "ARAz0NC4XwjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?"
      ],
      "metadata": {
        "id": "fZ0sPQ2bXz2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with multiclass classification, two popular approaches to extending logistic regression are One-vs-Rest (OvR) and Softmax Regression. The choice between these two methods depends on several factors, including model complexity, the nature of the data, and computational efficiency.\n",
        "\n",
        "Here's a detailed comparison of when to use One-vs-Rest (OvR) and Softmax Regression:\n",
        "\n",
        "1. Conceptual Difference:\n",
        "One-vs-Rest (OvR):\n",
        "\n",
        "In this approach, you train a separate binary classifier for each class, where each classifier learns to distinguish one class from all other classes.\n",
        "\n",
        "For\n",
        "ğ¶\n",
        "C classes, you train\n",
        "ğ¶\n",
        "C separate logistic regression classifiers. Each classifier outputs a probability that the instance belongs to its corresponding class.\n",
        "\n",
        "During prediction, the model with the highest probability is selected.\n",
        "\n",
        "Softmax Regression:\n",
        "\n",
        "Softmax Regression is a single model that directly outputs probabilities for all classes at once. It uses the softmax function to normalize the outputs of the model into a valid probability distribution over all classes.\n",
        "\n",
        "It produces one set of weights to handle all classes and optimizes the parameters in a unified manner.\n",
        "\n",
        "2. When to Choose One-vs-Rest (OvR):\n",
        "Simplicity and Efficiency:\n",
        "\n",
        "OvR can be a good choice if you want to use a simpler model or when you are working with simple classifiers like logistic regression.\n",
        "\n",
        "Training multiple independent classifiers (one for each class) can be more efficient when the classes are easily separable or when you want to handle unbalanced datasets more flexibly.\n",
        "\n",
        "Imbalanced Classes:\n",
        "\n",
        "OvR is often useful when you have class imbalance. Since each classifier is trained independently, it can focus more on the specific class, potentially improving the performance for rare classes.\n",
        "\n",
        "For instance, if one class is much less frequent than others, OvR can give that class more attention in its classifier, while other classes can be ignored for that classifier.\n",
        "\n",
        "Different Loss Functions for Each Class:\n",
        "\n",
        "OvR allows more flexibility in choosing different loss functions or regularization strategies for each classifier, which can be helpful when each class requires specific treatment.\n",
        "\n",
        "Handling Multiclass with Binary Models:\n",
        "\n",
        "OvR is conceptually easier to understand and implement, as it turns a multiclass problem into multiple binary classification problems, which are easier to interpret individually.\n",
        "\n",
        "3. When to Choose Softmax Regression:\n",
        "Unified Model:\n",
        "\n",
        "If you prefer a single model that can learn the relationships between all classes simultaneously, Softmax Regression is the better choice.\n",
        "\n",
        "It can be more efficient, as it avoids the overhead of training multiple classifiers, and typically requires less computation during inference since there's only one model to evaluate.\n",
        "\n",
        "Mutual Exclusivity of Classes:\n",
        "\n",
        "Softmax regression assumes that the classes are mutually exclusive. If the classes do not overlap and the decision boundary is clear between them, Softmax Regression is often the preferred method as it directly models the probability distribution across all classes in one go.\n",
        "\n",
        "If there are complex relationships between classes or interactions between features, Softmax Regression might be more effective than OvR.\n",
        "\n",
        "Probabilistic Interpretation:\n",
        "\n",
        "Since Softmax Regression provides a probability distribution over all possible classes, it can give you more informative output (not just the predicted class but the probabilities for each class). This can be useful in applications where you need to make decisions based on the predicted probabilities (e.g., ranking or uncertainty quantification).\n",
        "\n",
        "It is especially beneficial when you need to know the confidence of the prediction, as it normalizes the output to sum to 1."
      ],
      "metadata": {
        "id": "63IMVsifX6ZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How do we interpret coefficients in Logistic Regression?"
      ],
      "metadata": {
        "id": "KiZBriPgX6yp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreting the coefficients in Logistic Regression is essential for understanding how the input features influence the predicted probability of the outcome. While interpreting logistic regression coefficients is slightly more complex than linear regression due to the use of the logistic function, it is still manageable.\n",
        "1. Logistic Regression Model Recap:\n",
        "The logistic regression model can be expressed as:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ğ‘‹\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ğ‘’\n",
        "âˆ’\n",
        "(\n",
        "ğ‘¤\n",
        "0\n",
        "+\n",
        "ğ‘¤\n",
        "1\n",
        "ğ‘‹\n",
        "1\n",
        "+\n",
        "ğ‘¤\n",
        "2\n",
        "ğ‘‹\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğ‘¤\n",
        "ğ‘›\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        ")\n",
        "P(y=1âˆ£X)=\n",
        "1+e\n",
        "âˆ’(w\n",
        "0\n",
        "â€‹\n",
        " +w\n",
        "1\n",
        "â€‹\n",
        " X\n",
        "1\n",
        "â€‹\n",
        " +w\n",
        "2\n",
        "â€‹\n",
        " X\n",
        "2\n",
        "â€‹\n",
        " +â‹¯+w\n",
        "n\n",
        "â€‹\n",
        " X\n",
        "n\n",
        "â€‹\n",
        " )\n",
        "\n",
        "1\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ğ‘‹\n",
        ")\n",
        "P(y=1âˆ£X) is the predicted probability that the dependent variable\n",
        "ğ‘¦\n",
        "y equals 1 (positive class).\n",
        "\n",
        "ğ‘‹\n",
        "1\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        ",\n",
        "â€¦\n",
        ",\n",
        "ğ‘‹\n",
        "ğ‘›\n",
        "X\n",
        "1\n",
        "â€‹\n",
        " ,X\n",
        "2\n",
        "â€‹\n",
        " ,â€¦,X\n",
        "n\n",
        "â€‹\n",
        "  are the input features.\n",
        "\n",
        "ğ‘¤\n",
        "0\n",
        "w\n",
        "0\n",
        "â€‹\n",
        "  is the intercept (bias term), and\n",
        "ğ‘¤\n",
        "1\n",
        ",\n",
        "ğ‘¤\n",
        "2\n",
        ",\n",
        "â€¦\n",
        ",\n",
        "ğ‘¤\n",
        "ğ‘›\n",
        "w\n",
        "1\n",
        "â€‹\n",
        " ,w\n",
        "2\n",
        "â€‹\n",
        " ,â€¦,w\n",
        "n\n",
        "â€‹\n",
        "  are the coefficients corresponding to each feature.\n",
        "\n",
        "ğ‘’\n",
        "e is the base of the natural logarithm.\n",
        "\n",
        "The model predicts probabilities that an observation belongs to the positive class (class 1) based on a logistic function.\n",
        "\n",
        "2. Interpretation of Coefficients in Logistic Regression:\n",
        "2.1 Odds Ratios:\n",
        "The key to interpreting the coefficients is understanding odds and odds ratios. In logistic regression, the coefficient\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "  of each feature\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  corresponds to the change in the log-odds of the dependent variable.\n",
        "\n",
        "The odds of an event occurring is the ratio of the probability of the event happening to the probability of it not happening:\n",
        "\n",
        "Odds\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "1\n",
        "âˆ’\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "Odds=\n",
        "1âˆ’P(y=1)\n",
        "P(y=1)\n",
        "â€‹\n",
        "\n",
        "The log-odds (or logit) is the natural log of the odds:\n",
        "\n",
        "Log-Odds\n",
        "=\n",
        "log\n",
        "â¡\n",
        "(\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        "1\n",
        "âˆ’\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        ")\n",
        ")\n",
        "Log-Odds=log(\n",
        "1âˆ’P(y=1)\n",
        "P(y=1)\n",
        "â€‹\n",
        " )\n",
        "The logistic regression equation essentially models the log-odds of the outcome as a linear combination of the input features.\n",
        "\n",
        "2.2 Interpretation of a Single Coefficient\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "w\n",
        "i\n",
        "â€‹\n",
        " :\n",
        "The coefficient\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "  tells you how a one-unit change in the corresponding feature\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  affects the log-odds of the outcome. More specifically:\n",
        "\n",
        "If\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "  is positive, an increase in\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  increases the log-odds of the positive class (i.e., makes it more likely that\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "y=1).\n",
        "\n",
        "If\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "  is negative, an increase in\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  decreases the log-odds of the positive class (i.e., makes it less likely that\n",
        "ğ‘¦\n",
        "=\n",
        "1\n",
        "y=1).\n",
        "\n",
        "If\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "=\n",
        "0\n",
        "w\n",
        "i\n",
        "â€‹\n",
        " =0,\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  has no effect on the probability of the outcome.\n",
        "\n",
        "2.3 Exponentiating the Coefficients to Get Odds Ratios:\n",
        "To make the interpretation easier, we often exponentiate the coefficients. This gives us the odds ratio (OR), which tells us how the odds of the outcome change with a one-unit increase in\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        " .\n",
        "\n",
        "The odds ratio for feature\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  is given by:\n",
        "\n",
        "OddsÂ Ratio\n",
        "=\n",
        "ğ‘’\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "OddsÂ Ratio=e\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "\n",
        "\n",
        "This is easier to interpret than the raw coefficient\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "  because it gives you the change in odds rather than log-odds.\n",
        "\n",
        "2.4 Interpretation of the Odds Ratio:\n",
        "If\n",
        "ğ‘’\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "=\n",
        "1\n",
        "e\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "\n",
        " =1, it means the feature\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  has no effect on the odds of the outcome.\n",
        "\n",
        "If\n",
        "ğ‘’\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        ">\n",
        "1\n",
        "e\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "\n",
        " >1, it means that an increase in\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  increases the odds of the outcome happening (class 1). In other words, a one-unit increase in\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  is associated with an increase in the likelihood of class 1.\n",
        "\n",
        "If\n",
        "ğ‘’\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "<\n",
        "1\n",
        "e\n",
        "w\n",
        "i\n",
        "â€‹\n",
        "\n",
        " <1, it means that an increase in\n",
        "ğ‘‹\n",
        "ğ‘–\n",
        "X\n",
        "i\n",
        "â€‹\n",
        "  decreases the odds of the outcome happening (class 1)."
      ],
      "metadata": {
        "id": "HfBea660YDCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "5uVqyUqEYL9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC8KGNdFYRST",
        "outputId": "9dd459f2-4a4e-440f-875f-858d9db9d62e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "and print the model accuracy."
      ],
      "metadata": {
        "id": "9kNxR9-6YeJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='saga', max_iter=200)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy with L1 Regularization (Lasso): {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcl1AHS7YjRt",
        "outputId": "03686f4d-fcfe-4b28-80de-1e6f721e1978"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization (Lasso): 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficientsC"
      ],
      "metadata": {
        "id": "CBUFUpCJYoSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy with L2 Regularization (Ridge): {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiGG_YmWYslj",
        "outputId": "050d19ab-7f40-4148-e556-eb946454a38e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization (Ridge): 100.00%\n",
            "Model Coefficients:\n",
            "[[-0.40538561  0.86892188 -2.277875   -0.95680118]\n",
            " [ 0.4664269  -0.37487908 -0.18745251 -0.72127094]\n",
            " [-0.06104129 -0.4940428   2.46532752  1.67807213]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "qjapkr5BYwc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with Elastic Net regularization\n",
        "# Set penalty='elasticnet' and use 'saga' solver which supports elasticnet\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=200, l1_ratio=0.5)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEkFUE3Y4Rf",
        "outputId": "8c709b6c-9a33-4784-bc9f-167d55cdecb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 100.00%\n",
            "Model Coefficients:\n",
            "[[ 0.38501     1.70640431 -2.35354651 -0.65547148]\n",
            " [ 0.04510454  0.          0.         -0.54229557]\n",
            " [-1.22328967 -1.29197413  2.47019237  1.98917559]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr'C."
      ],
      "metadata": {
        "id": "EIW8GBblY5Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model for multiclass classification with One-vs-Rest (OvR)\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Model Accuracy with One-vs-Rest (OvR): {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j4MuAf5Y9bn",
        "outputId": "6ac770fe-30a4-4a42-ca79-4950c9be8fba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-Rest (OvR): 97.78%\n",
            "Model Coefficients:\n",
            "[[ 0.36479402  1.35499766 -2.09628559 -0.92154751]\n",
            " [ 0.4808915  -1.58463288  0.3937527  -1.09224057]\n",
            " [-1.5286415  -1.43244729  2.3048277   2.08584535]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "9qAHW0m6ZAUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],  # Type of regularization\n",
        "    'solver': ['liblinear', 'saga']  # Solvers that support L1 and ElasticNet\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the model to the training data using GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters found by GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Get the best model's accuracy on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the best parameters and the accuracy\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RTXUvI-ZEpn",
        "outputId": "051b7ff7-27a4-4b3b-9fb8-e0223bbff53e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Model Accuracy with Best Parameters: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "50 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.35238095 0.34285714 0.64761905 0.86666667        nan        nan\n",
            " 0.67619048 0.94285714 0.8        0.94285714        nan        nan\n",
            " 0.94285714 0.97142857 0.94285714 0.97142857        nan        nan\n",
            " 0.94285714 0.96190476 0.95238095 0.96190476        nan        nan\n",
            " 0.94285714 0.96190476 0.94285714 0.96190476        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracy."
      ],
      "metadata": {
        "id": "TgXicCJ3ZMqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Initialize Stratified K-Fold Cross Validation\n",
        "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# List to store the accuracy for each fold\n",
        "accuracies = []\n",
        "\n",
        "# Stratified K-Fold Cross-Validation\n",
        "for train_index, test_index in k_fold.split(X, y):\n",
        "    # Split data into training and testing sets for the current fold\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the Logistic Regression model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the model on this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Append the accuracy to the list\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = np.mean(accuracies)\n",
        "\n",
        "# Print the average accuracy\n",
        "print(f\"Average Accuracy using Stratified K-Fold Cross-Validation: {average_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngnW-kCAZRXD",
        "outputId": "61fc3de9-9edb-4a52-92d1-db2ce1621f7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy using Stratified K-Fold Cross-Validation: 96.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "ApOi9qyvZi_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (Iris dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target  # Target labels (species)\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define the hyperparameter grid for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'C': np.logspace(-4, 4, 20),  # Regularization strength from 10^-4 to 10^4\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],  # Regularization types\n",
        "    'solver': ['liblinear', 'saga', 'lbfgs']  # Solvers that support l1 and elasticnet\n",
        "}\n",
        "\n",
        "# Initialize the RandomizedSearchCV with 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=50,  # Number of iterations to sample\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    verbose=1,  # Print progress during search\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# Perform the RandomizedSearchCV to find the best parameters\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters found by RandomizedSearchCV\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Get the best model's accuracy on the test set\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the best parameters and the accuracy\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Model Accuracy with Best Hyperparameters: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ybRhGZyZkJk",
        "outputId": "6aa9f743-bed1-4a46-bf6b-050696d5628f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best Hyperparameters: {'solver': 'saga', 'penalty': 'l1', 'C': np.float64(545.5594781168514)}\n",
            "Model Accuracy with Best Hyperparameters: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "120 fits failed out of a total of 250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.34285714        nan 0.94285714        nan 0.96190476        nan\n",
            "        nan 0.93333333 0.94285714 0.96190476 0.95238095        nan\n",
            "        nan        nan 0.35238095        nan        nan        nan\n",
            "        nan        nan        nan 0.94285714        nan 0.35238095\n",
            " 0.2952381  0.96190476        nan 0.2952381  0.96190476        nan\n",
            " 0.96190476 0.83809524 0.95238095 0.94285714 0.78095238        nan\n",
            " 0.94285714        nan 0.94285714 0.78095238 0.35238095 0.80952381\n",
            "        nan 0.96190476        nan        nan 0.93333333        nan\n",
            "        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "Uw8NBa3pZoZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset (you can replace it with your dataset)\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (3 classes in Iris)\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "logreg_model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Create OneVsOne classifier\n",
        "ovo_model = OneVsOneClassifier(logreg_model)\n",
        "\n",
        "# Train the OvO model on the training set\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model's accuracy\n",
        "print(f\"Accuracy of One-vs-One Multiclass Logistic Regression: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mwXkQq-Zuv3",
        "outputId": "871302b7-d576-4bfa-9761-dc9f4a54f92d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of One-vs-One Multiclass Logistic Regression: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification."
      ],
      "metadata": {
        "id": "2aABtYEJZwLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a synthetic binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print model accuracy\n",
        "print(f\"Accuracy of the Logistic Regression model: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "9bzHhXrcZ3Bc",
        "outputId": "675e0779-e0c2-4257-9c00-ca12eb71e2d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Logistic Regression model: 85.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score."
      ],
      "metadata": {
        "id": "iKQWT5neZ4wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Create a synthetic binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEAKqT9TZ9MW",
        "outputId": "40329b1f-cf42-4918-dbe3-4bfd3025dd56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.00%\n",
            "Precision: 0.88\n",
            "Recall: 0.83\n",
            "F1-Score: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance."
      ],
      "metadata": {
        "id": "tPVXn8dHaAnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Create an imbalanced synthetic binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_classes=2,\n",
        "                           weights=[0.9, 0.1], random_state=42)  # 90% of data belongs to class 0\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with class weights\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=200)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Generate and visualize the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "KSzhdxRIaIrz",
        "outputId": "f2082b83-a215-4981-8351-1818c17c21d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.33%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.91       270\n",
            "           1       0.37      0.77      0.49        30\n",
            "\n",
            "    accuracy                           0.84       300\n",
            "   macro avg       0.67      0.81      0.70       300\n",
            "weighted avg       0.91      0.84      0.87       300\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAGJCAYAAABrSFFcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWMpJREFUeJzt3XdYFNf7NvB7QVh6U5diAZQEJXaNSIwKNuwaTYwtghpbrKDG8o0NIxjU2KISjVGjoMZG7Ak2CBGNUbFFURAlRhArVZc27x++7C8rqOwCO8Lcn1xzXeyZMzPPbNZ99pw5c0YmCIIAIiIikgQ9sQMgIiIi3WHiJyIikhAmfiIiIglh4iciIpIQJn4iIiIJYeInIiKSECZ+IiIiCWHiJyIikhAmfiIiIglh4icqoZs3b6Jz586wtLSETCZDeHh4me7/9u3bkMlk2LRpU5nutyLz9PSEp6en2GEQVSpM/FShJCQkYPTo0ahTpw6MjIxgYWGB1q1bY8WKFXj27Fm5HtvHxweXL1/GwoULsWXLFrRo0aJcj6dLvr6+kMlksLCwKPZ9vHnzJmQyGWQyGZYsWaLx/u/du4d58+YhNja2DKIlotKoInYARCV18OBBfPLJJ5DL5Rg6dCgaNGiAnJwcREdHY9q0abh69SrWrVtXLsd+9uwZYmJi8L///Q/jx48vl2M4Ojri2bNnMDAwKJf9v0mVKlWQnZ2N/fv3o3///mrrQkNDYWRkhOfPn2u173v37mH+/PlwcnJCkyZNSrzdb7/9ptXxiOjVmPipQkhMTMSAAQPg6OiI48ePw97eXrVu3LhxiI+Px8GDB8vt+A8ePAAAWFlZldsxZDIZjIyMym3/byKXy9G6dWts27atSOIPCwtD9+7dsXv3bp3Ekp2dDRMTExgaGurkeERSwq5+qhCCg4ORmZmJDRs2qCX9Qi4uLpg0aZLqdV5eHhYsWIC6detCLpfDyckJs2bNglKpVNvOyckJPXr0QHR0NFq2bAkjIyPUqVMHP/30k6rOvHnz4OjoCACYNm0aZDIZnJycALzoIi/8+7/mzZsHmUymVhYREYEPP/wQVlZWMDMzg6urK2bNmqVa/6pr/MePH0ebNm1gamoKKysr9O7dG9euXSv2ePHx8fD19YWVlRUsLS0xbNgwZGdnv/qNfcmgQYNw+PBhPH36VFV29uxZ3Lx5E4MGDSpS//Hjx5g6dSoaNmwIMzMzWFhYoGvXrrh48aKqzsmTJ/H+++8DAIYNG6a6ZFB4np6enmjQoAHOnTuHtm3bwsTERPW+vHyN38fHB0ZGRkXO39vbG9bW1rh3716Jz5VIqpj4qULYv38/6tSpgw8++KBE9T///HPMmTMHzZo1w7Jly9CuXTsEBQVhwIABRerGx8fj448/RqdOnbB06VJYW1vD19cXV69eBQD07dsXy5YtAwAMHDgQW7ZswfLlyzWK/+rVq+jRoweUSiUCAgKwdOlS9OrVC3/88cdrtzt69Ci8vb2RmpqKefPmwd/fH6dOnULr1q1x+/btIvX79++PjIwMBAUFoX///ti0aRPmz59f4jj79u0LmUyGPXv2qMrCwsJQr149NGvWrEj9W7duITw8HD169MC3336LadOm4fLly2jXrp0qCdevXx8BAQEAgFGjRmHLli3YsmUL2rZtq9rPo0eP0LVrVzRp0gTLly+Hl5dXsfGtWLEC1atXh4+PD/Lz8wEA33//PX777TesWrUKDg4OJT5XIskSiN5yaWlpAgChd+/eJaofGxsrABA+//xztfKpU6cKAITjx4+ryhwdHQUAQlRUlKosNTVVkMvlwpQpU1RliYmJAgBh8eLFavv08fERHB0di8Qwd+5c4b//vJYtWyYAEB48ePDKuAuPsXHjRlVZkyZNBIVCITx69EhVdvHiRUFPT08YOnRokeMNHz5cbZ8fffSRULVq1Vce87/nYWpqKgiCIHz88cdChw4dBEEQhPz8fMHOzk6YP39+se/B8+fPhfz8/CLnIZfLhYCAAFXZ2bNni5xboXbt2gkAhJCQkGLXtWvXTq3s119/FQAIX3/9tXDr1i3BzMxM6NOnzxvPkYheYIuf3nrp6ekAAHNz8xLVP3ToEADA399frXzKlCkAUGQsgJubG9q0aaN6Xb16dbi6uuLWrVtax/yywrEBv/zyCwoKCkq0TXJyMmJjY+Hr6wsbGxtVeaNGjdCpUyfVef7XmDFj1F63adMGjx49Ur2HJTFo0CCcPHkSKSkpOH78OFJSUort5gdejAvQ03vxNZKfn49Hjx6pLmOcP3++xMeUy+UYNmxYiep27twZo0ePRkBAAPr27QsjIyN8//33JT4WkdQx8dNbz8LCAgCQkZFRovp37tyBnp4eXFxc1Mrt7OxgZWWFO3fuqJXXrl27yD6sra3x5MkTLSMu6tNPP0Xr1q3x+eefw9bWFgMGDMDPP//82h8BhXG6uroWWVe/fn08fPgQWVlZauUvn4u1tTUAaHQu3bp1g7m5OXbs2IHQ0FC8//77Rd7LQgUFBVi2bBneeecdyOVyVKtWDdWrV8elS5eQlpZW4mPWqFFDo4F8S5YsgY2NDWJjY7Fy5UooFIoSb0skdUz89NazsLCAg4MDrly5otF2Lw+uexV9ff1iywVB0PoYhdefCxkbGyMqKgpHjx7FZ599hkuXLuHTTz9Fp06ditQtjdKcSyG5XI6+ffti8+bN2Lt37ytb+wAQGBgIf39/tG3bFlu3bsWvv/6KiIgIvPfeeyXu2QBevD+auHDhAlJTUwEAly9f1mhbIqlj4qcKoUePHkhISEBMTMwb6zo6OqKgoAA3b95UK79//z6ePn2qGqFfFqytrdVGwBd6uVcBAPT09NChQwd8++23+Pvvv7Fw4UIcP34cJ06cKHbfhXHGxcUVWXf9+nVUq1YNpqampTuBVxg0aBAuXLiAjIyMYgdEFtq1axe8vLywYcMGDBgwAJ07d0bHjh2LvCcl/RFWEllZWRg2bBjc3NwwatQoBAcH4+zZs2W2f6LKjomfKoQvv/wSpqam+Pzzz3H//v0i6xMSErBixQoAL7qqARQZef/tt98CALp3715mcdWtWxdpaWm4dOmSqiw5ORl79+5Vq/f48eMi2xZOZPPyLYaF7O3t0aRJE2zevFktkV65cgW//fab6jzLg5eXFxYsWIDvvvsOdnZ2r6ynr69fpDdh586d+Pfff9XKCn+gFPcjSVPTp09HUlISNm/ejG+//RZOTk7w8fF55ftIROo4gQ9VCHXr1kVYWBg+/fRT1K9fX23mvlOnTmHnzp3w9fUFADRu3Bg+Pj5Yt24dnj59inbt2uHPP//E5s2b0adPn1feKqaNAQMGYPr06fjoo48wceJEZGdnY+3atXj33XfVBrcFBAQgKioK3bt3h6OjI1JTU7FmzRrUrFkTH3744Sv3v3jxYnTt2hUeHh4YMWIEnj17hlWrVsHS0hLz5s0rs/N4mZ6eHr766qs31uvRowcCAgIwbNgwfPDBB7h8+TJCQ0NRp04dtXp169aFlZUVQkJCYG5uDlNTU7i7u8PZ2VmjuI4fP441a9Zg7ty5qtsLN27cCE9PT8yePRvBwcEa7Y9IkkS+q4BIIzdu3BBGjhwpODk5CYaGhoK5ubnQunVrYdWqVcLz589V9XJzc4X58+cLzs7OgoGBgVCrVi1h5syZanUE4cXtfN27dy9ynJdvI3vV7XyCIAi//fab0KBBA8HQ0FBwdXUVtm7dWuR2vmPHjgm9e/cWHBwcBENDQ8HBwUEYOHCgcOPGjSLHePmWt6NHjwqtW7cWjI2NBQsLC6Fnz57C33//rVan8Hgv3y64ceNGAYCQmJj4yvdUENRv53uVV93ON2XKFMHe3l4wNjYWWrduLcTExBR7G94vv/wiuLm5CVWqVFE7z3bt2gnvvfdescf8737S09MFR0dHoVmzZkJubq5aPT8/P0FPT0+IiYl57TkQkSDIBEGDUT9ERERUofEaPxERkYQw8RMREUkIEz8REZGEMPETERFJCBM/ERGRhDDxExERSQgTPxERkYRUypn7jJuOFzsEonJ36chisUMgKnfv2Gr2ACdNlSZfPLvwXRlGojuVMvETERGViEx6Hd9M/EREJF1l+OTIikJ6P3WIiIgKyfS0XzQQFBSE999/H+bm5lAoFOjTp4/aI7cfP36MCRMmwNXVFcbGxqhduzYmTpyItLQ09XBlsiLL9u3bNYqFiZ+IiKicRUZGYty4cTh9+jQiIiKQm5uLzp07IysrCwBw79493Lt3D0uWLMGVK1ewadMmHDlyBCNGjCiyr40bNyI5OVm19OnTR6NY2NVPRETSpaOu/iNHjqi93rRpExQKBc6dO4e2bduiQYMG2L17t2p93bp1sXDhQgwZMgR5eXmoUuX/0rWVlRXs7Oy0joUtfiIikq5SdPUrlUqkp6erLUqlskSHLezCt7GxeW0dCwsLtaQPAOPGjUO1atXQsmVL/Pjjj9D0IbtM/EREJF0ymdZLUFAQLC0t1ZagoKA3HrKgoACTJ09G69at0aBBg2LrPHz4EAsWLMCoUaPUygMCAvDzzz8jIiIC/fr1wxdffIFVq1ZpdsqCpj8VKgDex09SwPv4SQrK/T7+VtO13vZpZECRFr5cLodcLn/tdmPHjsXhw4cRHR2NmjVrFlmfnp6OTp06wcbGBvv27YOBgcEr9zVnzhxs3LgR//zzT4njZoufiIikqxQtfrlcDgsLC7XlTUl//PjxOHDgAE6cOFFs0s/IyECXLl1gbm6OvXv3vjbpA4C7uzvu3r1b4ksMABM/ERFRuRMEAePHj8fevXtx/PhxODs7F6mTnp6Ozp07w9DQEPv27YORkdEb9xsbGwtra+s3/uD4L47qJyIi6dLRzH3jxo1DWFgYfvnlF5ibmyMlJQUAYGlpCWNjY1XSz87OxtatW1WDBQGgevXq0NfXx/79+3H//n20atUKRkZGiIiIQGBgIKZOnapRLEz8REQkXTq6nW/t2rUAAE9PT7XyjRs3wtfXF+fPn8eZM2cAAC4uLmp1EhMT4eTkBAMDA6xevRp+fn4QBAEuLi749ttvMXLkSI1iYeInIiLp0lGL/03j6D09Pd9Yp0uXLujSpUupY2HiJyIi6ZLgXP1M/EREJF0SfDqf9M6YiIhIwtjiJyIi6ZJgi5+Jn4iIpEuP1/iJiIikgy1+IiIiCeGofiIiIgmRYItfemdMREQkYWzxExGRdEmwq/+taPH//vvvGDJkCDw8PPDvv/8CALZs2YLo6GiRIyMiokpNpqf9UkGJHvnu3bvh7e0NY2NjXLhwQfVM4bS0NAQGBoocHRERVWoymfZLBSV64v/6668REhKC9evXw8DAQFXeunVrnD9/XsTIiIio0pNgi1/0a/xxcXFo27ZtkXJLS0s8ffpU9wEREZF0VOCWu7ZE/8liZ2eH+Pj4IuXR0dGoU6eOCBERERFVXqIn/pEjR2LSpEk4c+YMZDIZ7t27h9DQUEydOhVjx44VOzwiIqrM2NWvezNmzEBBQQE6dOiA7OxstG3bFnK5HFOnTsWECRPEDo+IiCozCXb1i574ZTIZ/ve//2HatGmIj49HZmYm3NzcYGZmJnZoRERU2VXglru2RE/8W7duRd++fWFiYgI3NzexwyEiIimRYOIX/Yz9/PygUCgwaNAgHDp0CPn5+WKHREREUsH7+HUvOTkZ27dvh0wmQ//+/WFvb49x48bh1KlTYodGRERU6Yie+KtUqYIePXogNDQUqampWLZsGW7fvg0vLy/UrVtX7PCIiKgy46h+cZmYmMDb2xtPnjzBnTt3cO3aNbFDIiKiyqwCd9lr6634yZKdnY3Q0FB069YNNWrUwPLly/HRRx/h6tWrYodGRESVmY5a/EFBQXj//fdhbm4OhUKBPn36IC4uTq3O8+fPMW7cOFStWhVmZmbo168f7t+/r1YnKSkJ3bt3h4mJCRQKBaZNm4a8vDyNYhE98Q8YMAAKhQJ+fn6oU6cOTp48ifj4eCxYsAD16tUTOzwiIqrMdDS4LzIyEuPGjcPp06cRERGB3NxcdO7cGVlZWao6fn5+2L9/P3bu3InIyEjcu3cPffv2Va3Pz89H9+7dkZOTg1OnTmHz5s3YtGkT5syZo9kpC4IgaLRFGRs8eDAGDx4Mb29v6Ovrl8k+jZuOL5P9EL3NLh1ZLHYIROXuHVvjct2/Sb8ftd42e/dwrbd98OABFAoFIiMj0bZtW6SlpaF69eoICwvDxx9/DAC4fv066tevj5iYGLRq1QqHDx9Gjx49cO/ePdja2gIAQkJCMH36dDx48ACGhoYlOrboLf7CLv6ySvpERES6oFQqkZ6errYUPlr+TdLS0gAANjY2AIBz584hNzcXHTt2VNWpV68eateujZiYGABATEwMGjZsqEr6AODt7Y309HSNLo2LMrhv5cqVGDVqFIyMjLBy5crX1p04caKOoiIiIqmRlWJwX1BQEObPn69WNnfuXMybN++12xUUFGDy5Mlo3bo1GjRoAABISUmBoaEhrKys1Ora2toiJSVFVee/Sb9wfeG6khIl8S9btgyDBw+GkZERli1b9sp6MpmMiZ+IiMpPKQb1z5w5E/7+/mplcrn8jduNGzcOV65cQXR0tPYHLwVREn9iYmKxfxMREelSaVr8crm8RIn+v8aPH48DBw4gKioKNWvWVJXb2dkhJycHT58+VWv1379/H3Z2dqo6f/75p9r+Ckf9F9YpCdGv8QcEBCA7O7tI+bNnzxAQECBCREREJBUymUzrRROCIGD8+PHYu3cvjh8/DmdnZ7X1zZs3h4GBAY4dO6Yqi4uLQ1JSEjw8PAAAHh4euHz5MlJTU1V1IiIiYGFhodGzbkQf1a+vr4/k5GQoFAq18kePHkGhUGg1dz9H9ZMUcFQ/SUF5j+q3GPCT1tumbx9a4rpffPEFwsLC8Msvv8DV1VVVbmlpCWPjF+c4duxYHDp0CJs2bYKFhYXq0fSFU9jn5+ejSZMmcHBwQHBwMFJSUvDZZ5/h888/R2BgYIljEX3mPkEQiv3ldPHiRdVoRyIioops7dq1AABPT0+18o0bN8LX1xfAi/Fvenp66NevH5RKJby9vbFmzRpVXX19fRw4cABjx46Fh4cHTE1N4ePjo3HvuGiJ39raWtVd8u6776ol//z8fGRmZmLMmDFihUdERBJQmmv8mihJ57qRkRFWr16N1atXv7KOo6MjDh06VKpYREv8y5cvhyAIGD58OObPnw9LS0vVOkNDQzg5OamuaxAREZUL6U3VL17i9/HxAQA4Ozvjgw8+gIGBgVihEBGRROmqxf82Ef0af7t27VR/P3/+HDk5OWrrLSwsdB0SERFJhBQTv+i382VnZ2P8+PFQKBQwNTWFtbW12kJERFRedHU739tE9MQ/bdo0HD9+HGvXroVcLscPP/yA+fPnw8HBAT/9pP1tFkRERFSU6F39+/fvx08//QRPT08MGzYMbdq0gYuLCxwdHREaGorBgweLHSIREVVSFbnlri3RW/yPHz9GnTp1ALy4nv/48WMAwIcffoioqCgxQyMiospOVoqlghI98depU0c1X3+9evXw888/A3jRE/DyU4qIiIjKEq/xi2DYsGG4ePEiAGDGjBlYvXo1jIyM4Ofnh2nTpokcHRERVWZSTPyiX+P38/NT/d2xY0dcv34d586dg4uLCxo1aiRiZEREVNlV5ASuLdET/8scHR3h6OgodhhERESVkuiJf+XKlcWWy2QyGBkZwcXFBW3btoW+vr6OIyMiokpPeg1+8RP/smXL8ODBA2RnZ6sm7Hny5AlMTExgZmaG1NRU1KlTBydOnECtWrVEjpaIiCoTKXb1iz64LzAwEO+//z5u3ryJR48e4dGjR7hx4wbc3d2xYsUKJCUlwc7OTm0sABERUVng4D4RfPXVV9i9ezfq1q2rKnNxccGSJUvQr18/3Lp1C8HBwejXr5+IURIRUWVUkRO4tkRP/MnJycjLyytSnpeXh5SUFACAg4MDMjIydB0aERFVclJM/KJ39Xt5eWH06NG4cOGCquzChQsYO3Ys2rdvDwC4fPkynJ2dxQqRiIio0hA98W/YsAE2NjZo3rw55HI55HI5WrRoARsbG2zYsAEAYGZmhqVLl4ocKRERVToSnLJX9K5+Ozs7RERE4Pr167hx4wYAwNXVFa6urqo6Xl5eYoVHRESVmBS7+kVP/IXq1KkDmUyGunXrokqVtyYsIiKqxKSY+EXv6s/OzsaIESNgYmKC9957D0lJSQCACRMmYNGiRSJHR0RElZkUb+cTPfHPnDkTFy9exMmTJ2FkZKQq79ixI3bs2CFiZERERJWP6H3q4eHh2LFjB1q1aqX2C+q9995DQkKCiJEREVGlV3Eb7loTPfE/ePAACoWiSHlWVlaF7kqp6KYO74w+7RvjXSdbPFPm4szFW/jfil9w806qqs6q/w1Ae3dX2Fe3ROYzJU5fTMRXK37Bjdv3VXVq2VljxaxP0a7Fu8h8pkTo/jOYvWof8vMLxDgtIo3s3PojNq9biV4fD8KoiV8CAHKUSmxYvRRRx39Fbm4Omr3/Acb6z4K1TVWRoyVtSDHPiN7V36JFCxw8eFD1uvB/wg8//AAPDw+xwpK8Ns1cELIjCu2GLkGPsd+hShV9HFg7HiZGhqo6F679g1HztqJJ36/R64vVkMlkOLBmHPT0Xvw/1NOTYc/KsTA0qAIv36UYOWcLhvRyx5yx3cU6LaISu3HtCo7s2wWnuu+qla//bgn+PBWFGfMXY9HKDXj06AECv/IXKUoqLV1d44+KikLPnj3h4OAAmUyG8PDwEsWxePFiVR0nJ6ci67UZCyd6iz8wMBBdu3bF33//jby8PKxYsQJ///03Tp06hcjISLHDk6ze49eovR41dyv+Ob4ITd1q4Y/zLy7B/LjnD9X6pOTHmL96P87+PAuODlWRePchOnrUR/06dug+ZhVSH2fg0o1/EbDmIL6e2BtfhxxCbl6+Ts+JqKSeZWdjyYJZmPDlHGz/ab2qPCszAxEH92LqnCA0bt4SADB5xnyM/ewjXL96CfXeayRWyKQlXbX4s7Ky0LhxYwwfPhx9+/Ytsj45OVnt9eHDhzFixIgi09UHBARg5MiRqtfm5uYaxyJ6i//DDz9EbGws8vLy0LBhQ/z2229QKBSIiYlB8+bNxQ6P/j8LsxcDL5+kZRe73sTIEEN7tULi3Ye4m/IEAODeyBlX4u8h9fH/TbccceoaLM2N4VbXvvyDJtLS2mWBeN+jDZq0aKVWHh93DXl5eWjS3F1VVsvRGdVt7XH96kVdh0llQFct/q5du+Lrr7/GRx99VOx6Ozs7teWXX36Bl5cX6tSpo1bP3NxcrZ6pqanG5yx6ix8A6tati/Xr17+5IolCJpNh8dSPcepCAv5OUP9VOuqTNlg4uQ/MTOSIS0xB97HfqVrytlUtkPpI/RkLqY/TX6yrZgHE6SZ+Ik1EHjuChBvXsWxdaJF1Tx4/RBUDA5iZW6iVW1nb4MmjR7oKkd4SSqUSSqVSraxwBtrSuH//Pg4ePIjNmzcXWbdo0SIsWLAAtWvXxqBBg+Dn56fx3Deit/hLS6lUIj09XW0RCtiFXJaWz+yP91zsMXTGxiLrth8+i1YDF6HjiGW4mfQAW78ZDrnhW/F7kkhjD+6nYP3KYEydEwjDUn55UwVRiil7g4KCYGlpqbYEBQWVOqTNmzfD3Ny8yCWBiRMnYvv27Thx4gRGjx6NwMBAfPnllxrvX7RvaD09vTd2lchksmKf3PdfQUFBmD9/vlqZvu37MLBvWeoYCVg2/RN0a9MAHUcsx7+pT4usT898jvTM50hIeoA/L91GclQwerdvjJ+PnMP9R+lo0cBRrb7C5kVL6f7DdF2ET6SR+Bt/4+mTx5j0+UBVWUF+Pq5ePI8De3cgYMka5OXmIjMjXa3V//TJY1hX5aj+iqg01/hnzpwJf3/1gZ2lbe0DwI8//ojBgwerzW0DQO1YjRo1gqGhIUaPHo2goCCNjita4t+7d+8r18XExGDlypUoKHjzLV/FvfGKNtNLHR+9SPq92jdG55ErcOfem7sxZTIZZJDB0ODFx+rMpURMH+GN6tZmePAkEwDQoVU9pGU8w7VbKeUaO5E2Gjd3x3ebdqmVrVg0BzVrO6PfoGGorrBFlSpVcPHcn2jt2REAcDfpNh7cT0a99xqLETKVUmkSf1l067/s999/R1xcXIkmsHN3d0deXh5u376t9nybNxEt8ffu3btIWVxcHGbMmIH9+/dj8ODBCAgIeON+invjZXr6ZRanVC2f2R+fdm2BT/zWITPrOWyrvhg5mpb5HM+VuXCqURUfezfHsZhrePgkEzVsrTBlWGc8U+bi1+irAICjMddw7VYKNnztg/+tCIdtVQvMHdcD3/8chZzc1/fkEInBxMQUTnVc1MrkRsYwt7BUlXfq/hF+WL0U5haWMDE1RcjyRaj3XiOO6K+g3rbb+Dds2IDmzZujceM3/5CMjY2Fnp5esXPhvM5bcTH23r17mDt3LjZv3gxvb2/ExsaiQYMGYoclaaP7twUARPwwWa185Jwt2Lr/DJQ5eWjdtC7GD/KEtYUJUh9lIPp8PLx8l6pa9wUFAvpNWosVswbg5KYpyHquROj+PxGw9uDLhyOqMEaOnwo9mQyBs6eoJvD5wn+W2GGRlnR1O19mZibi4+NVrxMTExEbGwsbGxvUrl0bAJCeno6dO3cW+xj6mJgYnDlzBl5eXjA3N0dMTAz8/PwwZMgQWFtbaxSLTBAEoXSno720tDQEBgZi1apVaNKkCb755hu0adOm1Ps1bjq+DKIjertdOrL4zZWIKrh3bI3Ld//Tjmi97c3FXUpc9+TJk8U+Yt7HxwebNm0CAKxbtw6TJ09GcnIyLC0t1eqdP38eX3zxBa5fvw6lUglnZ2d89tln8Pf31/hyg2iJPzg4GN988w3s7OwQGBhYbNe/tpj4SQqY+EkKyjvxv/ul9on/RnDJE//bRLSu/hkzZsDY2BguLi7YvHlzsfcrAsCePXt0HBkREUmFFOfqFy3xDx06VJJvOBERvT2kmIZES/yF1zSIiIjEUvhQMSl5K0b1ExERiUGKLf4KP2UvERERlRxb/EREJFlSHGvGxE9ERJIlwbzPxE9ERNLFFr+O7Nu3r8R1e/XqVY6REBGRlDHx60ifPn1KVE8mkyE/P798gyEiIsmSYN4XJ/GX5HG7REREVPZ4jZ+IiCSLXf0iycrKQmRkJJKSkpCTk6O2buLEiSJFRURElZ0E8774if/ChQvo1q0bsrOzkZWVBRsbGzx8+BAmJiZQKBRM/EREVG6k2OIXfeY+Pz8/9OzZE0+ePIGxsTFOnz6NO3fuoHnz5liyZInY4RERUSUmk2m/VFSiJ/7Y2FhMmTIFenp60NfXh1KpRK1atRAcHIxZs2aJHR4REVViMplM66WiEj3xGxgYQE/vRRgKhQJJSUkAAEtLS/zzzz9ihkZERFTpiH6Nv2nTpjh79izeeecdtGvXDnPmzMHDhw+xZcsWNGjQQOzwiIioEqvADXetid7iDwwMhL29PQBg4cKFsLa2xtixY/HgwQOsW7dO5OiIiKgyk2JXv+gt/hYtWqj+VigUOHLkiIjREBGRlFTg/K010RM/ERGRWCpyy11boid+Z2fn177xt27d0mE0REQkJRLM++In/smTJ6u9zs3NxYULF3DkyBFMmzZNnKCIiIgqKdET/6RJk4otX716Nf766y8dR0NERFKiq67+qKgoLF68GOfOnUNycjL27t2r9qRaX19fbN68WW0bb29vtXFvjx8/xoQJE7B//37o6emhX79+WLFiBczMzDSKRfRR/a/StWtX7N69W+wwiIioEtPVzH1ZWVlo3LgxVq9e/co6Xbp0QXJysmrZtm2b2vrBgwfj6tWriIiIwIEDBxAVFYVRo0ZpfM6it/hfZdeuXbCxsRE7DCIiqsR01eLv2rUrunbt+to6crkcdnZ2xa67du0ajhw5grNnz6ruhlu1ahW6deuGJUuWwMHBocSxiJ74mzZtqvbGC4KAlJQUPHjwAGvWrBExMiIiquxKk/iVSiWUSqVamVwuh1wu12p/J0+ehEKhgLW1Ndq3b4+vv/4aVatWBQDExMTAyspK7Rb4jh07Qk9PD2fOnMFHH31U4uOInvh79+6t9sbr6emhevXq8PT0RL169USMjIiIKrvSNPiDgoIwf/58tbK5c+di3rx5Gu+rS5cu6Nu3L5ydnZGQkIBZs2aha9euiImJgb6+PlJSUqBQKNS2qVKlCmxsbJCSkqLRsURP/Nq8QURERGKbOXMm/P391cq0be0PGDBA9XfDhg3RqFEj1K1bFydPnkSHDh1KFefLRB/cp6+vj9TU1CLljx49gr6+vggRERGRVJRmyl65XA4LCwu1RdvE/7I6deqgWrVqiI+PBwDY2dkVyZV5eXl4/PjxK8cFvIroiV8QhGLLlUolDA0NdRwNERFJia5G9Wvq7t27ePTokepZNh4eHnj69CnOnTunqnP8+HEUFBTA3d1do32L1tW/cuVKAC9+bf3www9q9yHm5+cjKiqK1/iJiKhc6WpUf2Zmpqr1DgCJiYmIjY2FjY0NbGxsMH/+fPTr1w92dnZISEjAl19+CRcXF3h7ewMA6tevjy5dumDkyJEICQlBbm4uxo8fjwEDBmg0oh8QMfEvW7YMwIsWf0hIiFq3vqGhIZycnBASEiJWeEREJAG6mrL3r7/+gpeXl+p14dgAHx8frF27FpcuXcLmzZvx9OlTODg4oHPnzliwYIHapYPQ0FCMHz8eHTp0UE3gU9iI1oRoiT8xMREA4OXlhT179sDa2lqsUIiISKL0dJT5PT09X3lpGwB+/fXXN+7DxsYGYWFhpY5F9FH9J06cEDsEIiIiyRB9cF+/fv3wzTffFCkPDg7GJ598IkJEREQkFW/r4L7yJHrij4qKQrdu3YqUd+3aFVFRUSJEREREUlGa2/kqKtG7+jMzM4u9bc/AwADp6ekiRERERFKhV3Hzt9ZEb/E3bNgQO3bsKFK+fft2uLm5iRARERFJBVv8Ipg9ezb69u2LhIQEtG/fHgBw7NgxbNu2DTt37hQ5OiIiqswqcP7WmuiJv2fPnggPD0dgYCB27doFY2NjNGrUCEePHkW7du3EDo+IiKhSET3xA0D37t3RvXv3IuVXrlxBgwYNRIiIiIikQAbpNflFv8b/soyMDKxbtw4tW7ZE48aNxQ6HiIgqMT2Z9ktF9dYk/qioKAwdOhT29vZYsmQJ2rdvj9OnT4sdFhERVWIc3KdjKSkp2LRpEzZs2ID09HT0798fSqUS4eHhHNFPRETlrgLnb62J1uLv2bMnXF1dcenSJSxfvhz37t3DqlWrxAqHiIgkSE8m03qpqERr8R8+fBgTJ07E2LFj8c4774gVBhERkaSI1uKPjo5GRkYGmjdvDnd3d3z33Xd4+PChWOEQEZEEca5+HWrVqhXWr1+P5ORkjB49Gtu3b4eDgwMKCgoQERGBjIwMsUIjIiKJkOLgPtFH9ZuammL48OGIjo7G5cuXMWXKFCxatAgKhQK9evUSOzwiIqrE2OIXmaurK4KDg3H37l1s27ZN7HCIiKiS4+C+t4S+vj769OmDPn36iB0KERFVYhU3fWuvRIl/3759Jd4hu+eJiIjeXiVK/CVtectkMuTn55cmHiIiIp2pyIP0tFWixF9QUFDecRAREelcRZ5zX1tv5TV+IiIiXWCLv4SysrIQGRmJpKQk5OTkqK2bOHFimQRGRERU3iSY9zVP/BcuXEC3bt2QnZ2NrKws2NjY4OHDhzAxMYFCoWDiJyKiCkOKLX6N7+P38/NDz5498eTJExgbG+P06dO4c+cOmjdvjiVLlpRHjERERBVaVFQUevbsCQcHB8hkMoSHh6vW5ebmYvr06WjYsCFMTU3h4OCAoUOH4t69e2r7cHJyKjJ74KJFizSORePEHxsbiylTpkBPTw/6+vpQKpWoVasWgoODMWvWLI0DICIiEoueTPtFE1lZWWjcuDFWr15dZF12djbOnz+P2bNn4/z589izZw/i4uKKvT0+ICAAycnJqmXChAkan7PGXf0GBgbQ03vxe0GhUCApKQn169eHpaUl/vnnH40DICIiEouuuvq7du2Krl27FrvO0tISERERamXfffcdWrZsiaSkJNSuXVtVbm5uDjs7u1LFonGLv2nTpjh79iwAoF27dpgzZw5CQ0MxefJkNGjQoFTBEBER6ZKsFItSqUR6erraolQqyySutLQ0yGQyWFlZqZUvWrQIVatWRdOmTbF48WLk5eVpvG+NE39gYCDs7e0BAAsXLoS1tTXGjh2LBw8eYN26dRoHQEREJJbSzNUfFBQES0tLtSUoKKjUMT1//hzTp0/HwIEDYWFhoSqfOHEitm/fjhMnTmD06NEIDAzEl19+qfH+ZYIgCKWO8i1j3HS82CEQlbtLRxaLHQJRuXvH1rhc9//5jitab7u6zztFWvhyuRxyufy128lkMuzdu7fYWXFzc3PRr18/3L17FydPnlRL/C/78ccfMXr0aGRmZr7xmP/FCXyIiEiySnOJvyRJXhO5ubno378/7ty5g+PHj7826QOAu7s78vLycPv2bbi6upb4OBonfmdn59cOhrh165amuyQiIhLF23Iff2HSv3nzJk6cOIGqVau+cZvY2Fjo6elBoVBodCyNE//kyZPVXufm5uLChQs4cuQIpk2bpunuiIiIRKOrvJ+ZmYn4+HjV68TERMTGxsLGxgb29vb4+OOPcf78eRw4cAD5+flISUkBANjY2MDQ0BAxMTE4c+YMvLy8YG5ujpiYGPj5+WHIkCGwtrbWKBaNE/+kSZOKLV+9ejX++usvTXdHREQkGj0dZf6//voLXl5eqtf+/v4AAB8fH8ybNw/79u0DADRp0kRtuxMnTsDT0xNyuRzbt2/HvHnzoFQq4ezsDD8/P9V+NFFmg/tu3bqFJk2aID09vSx2Vyoc3EdSwMF9JAXlPbjviz1/a73tmr5uZRiJ7mh8O9+r7Nq1CzY2NmW1OyIiIioHGnf1N23aVG0whCAISElJwYMHD7BmzZoyDY6IiKg8vS2D+3RJ48Tfu3dvtTdKT08P1atXh6enJ+rVq1emwWnrydnvxA6BqNylP8sVOwSiCq/Mur0rEI0T/7x588ohDCIiIt2TYotf4x87+vr6SE1NLVL+6NEj6Ovrl0lQREREuqCrp/O9TTRu8b/qJgClUglDQ8NSB0RERKQrFTmBa6vEiX/lypUAXnSL/PDDDzAzM1Oty8/PR1RU1FtzjZ+IiIiKV+LEv2zZMgAvWvwhISFq3fqGhoZwcnJCSEhI2UdIRERUTqR4jb/EiT8xMREA4OXlhT179mg8RSAREdHbhl39JXDixInyiIOIiEjnJNjg13xUf79+/fDNN98UKQ8ODsYnn3xSJkERERHpgp5MpvVSUWmc+KOiotCtW7ci5V27dkVUVFSZBEVERKQLeqVYKiqNY8/MzCz2tj0DA4O34gE9RERE9GoaJ/6GDRtix44dRcq3b98ON7eK+aQiIiKSJplM+6Wi0nhw3+zZs9G3b18kJCSgffv2AIBjx44hLCwMu3btKvMAiYiIyktFvlavLY0Tf8+ePREeHo7AwEDs2rULxsbGaNy4MY4fP87H8hIRUYUiwbyveeIHgO7du6N79+4AgPT0dGzbtg1Tp07FuXPnkJ+fX6YBEhERlRcp3sev9cDEqKgo+Pj4wMHBAUuXLkX79u1x+vTpsoyNiIioXEnxdj6NWvwpKSnYtGkTNmzYgPT0dPTv3x9KpRLh4eEc2EdERFQBlLjF37NnT7i6uuLSpUtYvnw57t27h1WrVpVnbEREROWKo/pf4/Dhw5g4cSLGjh2Ld955pzxjIiIi0gle43+N6OhoZGRkoHnz5nB3d8d3332Hhw8flmdsRERE5UpWiv8qqhIn/latWmH9+vVITk7G6NGjsX37djg4OKCgoAARERHIyMgozziJiIjKnJ5M+6Wi0nhUv6mpKYYPH47o6GhcvnwZU6ZMwaJFi6BQKNCrV6/yiJGIiKhc6CrxR0VFoWfPnnBwcIBMJkN4eLjaekEQMGfOHNjb28PY2BgdO3bEzZs31eo8fvwYgwcPhoWFBaysrDBixAhkZmZqfs4ab/Efrq6uCA4Oxt27d7Ft27bS7IqIiKjSysrKQuPGjbF69epi1wcHB2PlypUICQnBmTNnYGpqCm9vbzx//lxVZ/Dgwbh69SoiIiJw4MABREVFYdSoURrHIhMEQdD6TN5Sz/PEjoCo/KU/yxU7BKJypzA3KNf9Lz55S+ttp3nW0Wo7mUyGvXv3ok+fPgBetPYdHBwwZcoUTJ06FQCQlpYGW1tbbNq0CQMGDMC1a9fg5uaGs2fPokWLFgCAI0eOoFu3brh79y4cHBxKfPyK/GRBIiKiUilNV79SqUR6erraolQqNY4hMTERKSkp6Nixo6rM0tIS7u7uiImJAQDExMTAyspKlfQBoGPHjtDT08OZM2c0O2eNIyQiIqokSnMff1BQECwtLdWWoKAgjWNISUkBANja2qqV29raqtalpKRAoVCora9SpQpsbGxUdUpKq7n6iYiIKoPSTL07c+ZM+Pv7q5XJ5fLShlTumPiJiEiySnNbnlwuL5NEb2dnBwC4f/8+7O3tVeX3799HkyZNVHVSU1PVtsvLy8Pjx49V25fUW9HV//vvv2PIkCHw8PDAv//+CwDYsmULoqOjRY6MiIiofDk7O8POzg7Hjh1TlaWnp+PMmTPw8PAAAHh4eODp06c4d+6cqs7x48dRUFAAd3d3jY4neuLfvXs3vL29YWxsjAsXLqgGRqSlpSEwMFDk6IiIqDLT1Vz9mZmZiI2NRWxsLIAXA/piY2ORlJQEmUyGyZMn4+uvv8a+fftw+fJlDB06FA4ODqqR//Xr10eXLl0wcuRI/Pnnn/jjjz8wfvx4DBgwQKMR/cBbkPi//vprhISEYP369TAw+L/bNlq3bo3z58+LGBkREVV2epBpvWjir7/+QtOmTdG0aVMAgL+/P5o2bYo5c+YAAL788ktMmDABo0aNwvvvv4/MzEwcOXIERkZGqn2EhoaiXr166NChA7p164YPP/wQ69at0/icRb+P38TEBH///TecnJxgbm6Oixcvok6dOrh16xbc3NzUJi8oKd7HT1LA+/hJCsr7Pv41p25rve0XHziVWRy6JHqL387ODvHx8UXKo6OjUaeOdpMjEBERlQTn6hfByJEjMWnSJJw5cwYymQz37t1DaGgopk6dirFjx4odHhERVWJ6MpnWS0Ul+u18M2bMQEFBATp06IDs7Gy0bdsWcrkcU6dOxYQJE8QOj4iIqFIR/Rp/oZycHMTHxyMzMxNubm4wMzPTel+8xk9SwGv8JAXlfY1//Zk7Wm870t2xDCPRHdFb/Fu3bkXfvn1hYmICNzc3scMhIiIJqchd9toS/Rq/n58fFAoFBg0ahEOHDiE/P1/skIiISCJ0dR//20T0xJ+cnIzt27dDJpOhf//+sLe3x7hx43Dq1CmxQyMiokpOrxRLRSV67FWqVEGPHj0QGhqK1NRULFu2DLdv34aXlxfq1q0rdnhERFSJyWQyrZeKSvRr/P9lYmICb29vPHnyBHfu3MG1a9fEDomIiKhSEb3FDwDZ2dkIDQ1Ft27dUKNGDSxfvhwfffQRrl69KnZoRERUiclKsVRUorf4BwwYgAMHDsDExAT9+/fH7NmzVU8jIiIiKk9SHNUveuLX19fHzz//DG9vb+jr64sdDhERSYj00v5bkPhDQ0PFDoGIiCRKgg1+cRL/ypUrMWrUKBgZGWHlypWvrTtx4kQdRUVERFJTkUfna0uUKXudnZ3x119/oWrVqnB2dn5lPZlMhlu3bmm8f07ZS1LAKXtJCsp7yt5tF/7VetuBTWuUYSS6I0qLPzExsdi/iYiIdOmtuLVNx0Q/54CAAGRnZxcpf/bsGQICAkSIiIiIpEKKE/iI/nQ+fX19JCcnQ6FQqJU/evQICoVCq7n72dVPUsCufpKC8u7q3xl7T+ttP2niUIaR6I7oo/oFQSj2l9PFixdhY2MjQkRERCQVFbnlri3REr+1tbWqu+Tdd99Ve/Pz8/ORmZmJMWPGiBUeERFJgOjXu0UgWuJfvnw5BEHA8OHDMX/+fFhaWqrWGRoawsnJiTP4ERERlTHREr+Pjw+AF7f2ffDBBzAwKN/rOERERC9jV7+OpKenw8LCAgDQtGlTPHv2DM+ePSu2bmE9IiKisia9tC9S4re2tlaN5Leysir2F1fhoD9tRvUTERGVhAQb/OIk/uPHj6tG7J84cUKMEIiIiKCnoza/k5MT7ty5U6T8iy++wOrVq+Hp6YnIyEi1daNHj0ZISEiZxyJK4m/Xrl2xfxMREemSrlr8Z8+eVevBvnLlCjp16oRPPvlEVTZy5Ei1ietMTEzKJRbR72Q4cuQIoqOjVa9Xr16NJk2aYNCgQXjy5ImIkREREZWN6tWrw87OTrUcOHAAdevWVWv8mpiYqNUprzFuoif+adOmIT09HQBw+fJl+Pv7o1u3bkhMTIS/v7/I0RERUWUmK8V/SqUS6enpaotSqXzjMXNycrB161YMHz5cbYxbaGgoqlWrhgYNGmDmzJnFTmdfFkRP/ImJiXBzcwMA7N69Gz179kRgYCBWr16Nw4cPixwdERFVZjKZ9ktQUBAsLS3VlqCgoDceMzw8HE+fPoWvr6+qbNCgQdi6dStOnDiBmTNnYsuWLRgyZEj5nLPYc/Xb2NggOjoabm5u+PDDDzF06FCMGjUKt2/fhpubm1a/eDhXP0kB5+onKSjvufqPXH2g9bZeLhZFWvhyuRxyufy123l7e8PQ0BD79+9/ZZ3jx4+jQ4cOiI+PR926dbWOsTiiz9X/4Ycfwt/fH61bt8aff/6JHTt2AABu3LiBmjVrihwdERFVZqUZ3FeSJP+yO3fu4OjRo9izZ89r67m7uwNAuSR+0bv6v/vuO1SpUgW7du3C2rVrUaNGDQDA4cOH0aVLF5GjIyKiyqw0Xf3a2LhxIxQKBbp37/7aerGxsQAAe3t77Q70GqJ39ZcHdvWTFLCrn6SgvLv6f7umfVd/5/rVNapfUFAAZ2dnDBw4EIsWLVKVJyQkICwsDN26dUPVqlVx6dIl+Pn5oWbNmkXu7S8Lonf1Ay+exhceHo5r164BAN577z306tUL+vr6IkdGRESVmUyHk/YePXoUSUlJGD58uFq5oaEhjh49iuXLlyMrKwu1atVCv3798NVXX5VLHKK3+OPj49GtWzf8+++/cHV1BQDExcWhVq1aOHjwoFbXNtjiJylgi5+koLxb/MeuP9R62w71qpVhJLoj+jX+iRMnom7duvjnn39w/vx5nD9/HklJSXB2dsbEiRPFDo+IiCqx0tzHX1GJ3tUfGRmJ06dPq+buB4CqVati0aJFaN26tYiRERFRZSfFh/SI3uKXy+XIyMgoUp6ZmQlDQ0MRIiIiIqq8RE/8PXr0wKhRo3DmzBkIggBBEHD69GmMGTMGvXr1Ejs8IiKqxNjVL4KVK1fCx8cHHh4eMDB4MYgjLy8PvXr1wooVK0SOjl6na6f2uHfv3yLlnw4YhFmz54oQEVHpbdm4HlEnjuLO7UTI5UZo0KgJxk7wQ20nZ1WdxQvn468/Y/Dw4QMYG5ugYaMmGDPRD45OdUSMnLShV3Hzt9ZEH9VfKD4+XnU7X/369eHi4qL1vjiqXzceP36Mgv88ZjI+/iZGfz4MP2z8Ce+3dBcxMmngqP7yMWXCaHTo3BX13RogPz8P369egcSEeGzZ+QuMjV88JnXfnp2o7eQMWzt7pKenYeP3a3DzxnX8vO9X3oZcxsp7VP/vN7R/Cmybd63LMBLdES3xFxQUYPHixdi3bx9ycnLQoUMHzJ07F8bGxqXeNxO/OIKDFiIq8iT2H/5N7YlTVD6Y+HXjyZPH6NWpLVat24QmzVoUWyf+ZhyGDeyH7eGHUKNmbR1HWLmVd+KPvql94v/wnYqZ+EW7xr9w4ULMmjULZmZmqFGjBlasWIFx48aJFQ6VUm5ODg4e2Ic+ffsx6VOlkpWZCQCwsLAsdv2zZ9k4tC8c9jVqQmFb9tOrUvmSlWKpqES7xv/TTz9hzZo1GD16NIAXMxp1794dP/zwA/T0RB9zSBo6fvwoMjIy0KvPR2KHQlRmCgoKsHLpIjRs3BR1XN5RW7d353asXbkUz549Q21HZyxbvU41TonobSZaV79cLkd8fDxq1aqlKjMyMkJ8fLxGT+VTKpVFHoso6Gv+xCQqnTEjR8DAwACr1oSIHYpksKu//C0JCsCZU9FY/cNPUNjaqa3LzMzAk8eP8ejhA2zfsgkPHqRizYYt/O4pY+Xd1R8T/1TrbT1crMosDl0SrWmdl5cHIyMjtTIDAwPk5mr2ZRYUFARLS0u1ZfE3QWUZKr3BvXv/4szpU+j78cdih0JUZpZ9sxAx0ZFYEfJjkaQPAGZm5qhV2xFNmrXAguBlSLqdiN9PHBMhUioNdvXrkCAI8PX1Vft1/Pz5c4wZMwampqaqsjc9s3jmzJnw9/dX37c+f3Hr0i9798DGpiratPUUOxSiUhMEAcuDAxF18hhWfr8RDjXe3ANZOAdJTm6ODiKkMlWRM7iWREv8Pj4+RcqGDBmi8X7k8qLd+hzVrzsFBQX4Ze8e9OzdB1WqiD4tBFGpffvN1zh65BACl66EiYkpHj188RAXMzMzyI2McO/uPzgWcQQtW30AK2sbpN5PQeimDZAbyeHRuo3I0ZOmKvJEPNoS7Zt648aNYh2aytDpmFNITr6HPn37iR0KUZkI37UDADBx9DC18plzv0a3nn1gKJfj0oXz2LltCzLS02FTtSoaN22BtRu2wtqmqhghUylI8Sakt2YCn7LEFj9JAQf3kRSU9+C+P2+lab1tyzrF3+L5tmPfLBERSZYEG/xM/EREJGESzPxM/EREJFkc3EdERCQhUhzcJ0ri37dvX4nr9urVqxwjISIiKZNg3hcn8ffp06dE9WQyGfL/89hXIiIiKh1REn9BQYEYhyUiIlInwSY/r/ETEZFkcXCfSLKyshAZGYmkpCTk5KjPdT1x4kSRoiIiospOV4P75s2bh/nz56uVubq64vr16wBePKtmypQp2L59O5RKJby9vbFmzRrY2tqWeSyiJ/4LFy6gW7duyM7ORlZWFmxsbPDw4UOYmJhAoVAw8RMRUbnRZXv/vffew9GjR1Wv//t8Ez8/Pxw8eBA7d+6EpaUlxo8fj759++KPP/4o8zhET/x+fn7o2bMnQkJCYGlpidOnT8PAwABDhgzBpEmTxA6PiIgqMx1m/ipVqsDOrugjntPS0rBhwwaEhYWhffv2AF48z6Z+/fo4ffo0WrVqVaZx6JXp3rQQGxuLKVOmQE9PD/r6+lAqlahVqxaCg4Mxa9YsscMjIiIqllKpRHp6utqiVCpfWf/mzZtwcHBAnTp1MHjwYCQlJQEAzp07h9zcXHTs2FFVt169eqhduzZiYmLKPG7RE7+BgQH09F6EoVAoVG+EpaUl/vnnHzFDIyKiSk5Wiv+CgoJgaWmptgQFBRV7HHd3d2zatAlHjhzB2rVrkZiYiDZt2iAjIwMpKSkwNDSElZWV2ja2trZISUkp83MWvau/adOmOHv2LN555x20a9cOc+bMwcOHD7FlyxY0aNBA7PCIiKgSK83gvpkzZ8Lf31+tTC6XF1u3a9euqr8bNWoEd3d3ODo64ueff4axsbH2QWhB9BZ/YGAg7O3tAQALFy6EtbU1xo4diwcPHmDdunUiR0dERJWZrBSLXC6HhYWF2vKqxP8yKysrvPvuu4iPj4ednR1ycnLw9OlTtTr3798vdkxAaYne4m/RooXqb4VCgSNHjogYDRERSYpIt/FnZmYiISEBn332GZo3bw4DAwMcO3YM/fr1AwDExcUhKSkJHh4eZX5s0RM/ERGRWHQ1gc/UqVPRs2dPODo64t69e5g7dy709fUxcOBAWFpaYsSIEfD394eNjQ0sLCwwYcIEeHh4lPmIfuAtSPzOzs6QveYiy61bt3QYDRERUdm7e/cuBg4ciEePHqF69er48MMPcfr0aVSvXh0AsGzZMujp6aFfv35qE/iUB5kgCEK57LmEVqxYofY6NzcXFy5cwJEjRzBt2jTMmDFD430+zyur6IjeXunPcsUOgajcKcwNynX/f9/L0npbNwfTMoxEd0Rv8b9qkp7Vq1fjr7/+0nE0REQkJdKbqf8tGNX/Kl27dsXu3bvFDoOIiCqz0gzrr6BEb/G/yq5du2BjYyN2GEREVInx6XwiaNq0qdrgPkEQkJKSggcPHpTbwAYiIiJAd0/ne5uInvh79+6tlvj19PRQvXp1eHp6ol69eiJGRkREVPmIPqq/PHBUP0kBR/WTFJT3qP4bKdlab/uunUkZRqI7og/u09fXR2pqapHyR48eQV9fX4SIiIhIMji4T/de1eGgVCphaGio42iIiEhKOLhPh1auXAkAkMlk+OGHH2BmZqZal5+fj6ioKF7jJyKicsXBfTq0bNkyAC9a/CEhIWrd+oaGhnByckJISIhY4RERkQRIMO+Ll/gTExMBAF5eXtizZw+sra3FCoWIiEgyRL/Gf+LECbFDICIiqZJgk1/0Uf39+vXDN998U6Q8ODgYn3zyiQgRERGRVMhK8V9FJXrij4qKQrdu3YqUd+3aFVFRUSJEREREUiGTab9UVKJ39WdmZhZ7256BgQHS09NFiIiIiKSiAudvrYne4m/YsCF27NhRpHz79u1wc3MTISIiIpIMTuCje7Nnz0bfvn2RkJCA9u3bAwCOHTuGbdu2YefOnSJHR0REVLmInvh79uyJ8PBwBAYGYteuXTA2NkajRo1w9OhRtGvXTuzwiIioEqvIg/S09VY/pOfKlSto0KCBxtvxIT0kBXxID0lBeT+kJ+mxUutta9vIyzAS3RH9Gv/LMjIysG7dOrRs2RKNGzcWOxwiIqrEJHiJ/+1J/FFRURg6dCjs7e2xZMkStG/fHqdPnxY7LCIiqsR4O5+OpaSkYNOmTdiwYQPS09PRv39/KJVKhIeHc0Q/ERHpQAXO4FoSrcXfs2dPuLq64tKlS1i+fDnu3buHVatWiRUOERGRJIjW4j98+DAmTpyIsWPH4p133hErDCIikrCK3GWvLdFa/NHR0cjIyEDz5s3h7u6O7777Dg8fPhQrHCIikiBdDe4LCgrC+++/D3NzcygUCvTp0wdxcXFqdTw9PSGTydSWMWPGlOb0iiVa4m/VqhXWr1+P5ORkjB49Gtu3b4eDgwMKCgoQERGBjIwMsUIjIiKJ0NXgvsjISIwbNw6nT59GREQEcnNz0blzZ2RlZanVGzlyJJKTk1VLcHBwGZ7tC2/VffxxcXHYsGEDtmzZgqdPn6JTp07Yt2+fxvvhffwkBbyPn6SgvO/jT0nT/t+RnaX2sT148AAKhQKRkZFo27YtgBct/iZNmmD58uVa77ck3prb+QDA1dUVwcHBuHv3LrZt2yZ2OEREVNmVoq9fqVQiPT1dbVEqSzYhUFpaGgDAxsZGrTw0NBTVqlVDgwYNMHPmTGRnZ5fBSap7q1r8ZYUtfpICtvhJCsq9xZ+u/b+jkG8XYv78+Wplc+fOxbx58167XUFBAXr16oWnT58iOjpaVb5u3To4OjrCwcEBly5dwvTp09GyZUvs2bNH6xiLw8RPVEEx8ZMUlHfiv1+KxG8lLyjSwpfL5ZDLXz+V79ixY3H48GFER0ejZs2ar6x3/PhxdOjQAfHx8ahbt67Wcb5M9If0EBERiaU0t/OVJMm/bPz48Thw4ACioqJem/QBwN3dHQCY+ImIiMqKrp7OJwgCJkyYgL179+LkyZNwdnZ+4zaxsbEAAHt7+zKNhYmfiIikS0cT+IwbNw5hYWH45ZdfYG5ujpSUFACApaUljI2NkZCQgLCwMHTr1g1Vq1bFpUuX4Ofnh7Zt26JRo0ZlGguv8RNVULzGT1JQ3tf4H2ZqnzCqmZW87Sx7xTWFjRs3wtfXF//88w+GDBmCK1euICsrC7Vq1cJHH32Er776ChYWFlrHWGwsTPxEFRMTP0lBZUn8b5OKGTUREVEZkOJc/Uz8REQkWboa3Pc2YeInIiLJkmKL/62aspeIiIjKF1v8REQkWWzxExERUaXGFj8REUkWB/cRERFJiBS7+pn4iYhIsiSY95n4iYhIwiSY+Tm4j4iISELY4iciIsni4D4iIiIJ4eA+IiIiCZFg3mfiJyIiCZNg5mfiJyIiyZLiNX6O6iciIpIQtviJiEiypDi4TyYIgiB2EFSxKZVKBAUFYebMmZDL5WKHQ1Qu+DmnyoKJn0otPT0dlpaWSEtLg4WFhdjhEJULfs6psuA1fiIiIglh4iciIpIQJn4iIiIJYeKnUpPL5Zg7dy4HPFGlxs85VRYc3EdERCQhbPETERFJCBM/ERGRhDDxExERSQgTfwXj6+uLPn36qF57enpi8uTJOo/j5MmTkMlkePr0qc6PXZZu374NmUyG2NhYsUOhN+Bn/4V58+ahSZMmr63DzzW9DhN/GfD19YVMJoNMJoOhoSFcXFwQEBCAvLy8cj/2nj17sGDBghLV1fUXlpOTE2QyGU6fPq1WPnnyZHh6euokhv96OXEAQK1atZCcnIwGDRroPJ7KgJ/94hV+9mUyGUxNTdGsWTPs3LmzTPY9depUHDt2TPWan2vSFBN/GenSpQuSk5Nx8+ZNTJkyBfPmzcPixYuLrZuTk1Nmx7WxsYG5uXmZ7a+sGRkZYfr06WKH8Ur6+vqws7NDlSp8XpW2+NkvXkBAAJKTk3HhwgW8//77+PTTT3Hq1KlS79fMzAxVq1Z9bR1+rul1mPjLiFwuh52dHRwdHTF27Fh07NgR+/btA/B/v8gXLlwIBwcHuLq6AgD++ecf9O/fH1ZWVrCxsUHv3r1x+/Zt1T7z8/Ph7+8PKysrVK1aFV9++SVevvvy5e5OpVKJ6dOno1atWpDL5XBxccGGDRtw+/ZteHl5AQCsra0hk8ng6+sLACgoKEBQUBCcnZ1hbGyMxo0bY9euXWrHOXToEN59910YGxvDy8tLLc7XGTVqFE6fPo1Dhw69tt4PP/yA+vXrw8jICPXq1cOaNWvU1p86dQpNmjSBkZERWrRogfDwcLWuzPz8fIwYMUJ1Dq6urlixYoVq+3nz5mHz5s345ZdfVC2xkydPqnWJFhQUoGbNmli7dq3asS9cuAA9PT3cuXMHAPD06VN8/vnnqF69OiwsLNC+fXtcvHixRO9HZcTPfvHMzc1hZ2eHd999F6tXr4axsTH2798PALh8+TLat28PY2NjVK1aFaNGjUJmZqZq25MnT6Jly5YwNTWFlZUVWrdurfr8/bern59r0gYTfzkxNjZWa90cO3YMcXFxiIiIwIEDB5Cbmwtvb2+Ym5vj999/xx9//AEzMzN06dJFtd3SpUuxadMm/Pjjj4iOjsbjx4+xd+/e1x536NCh2LZtG1auXIlr167h+++/h5mZGWrVqoXdu3cDAOLi4pCcnKxKjEFBQfjpp58QEhKCq1evws/PD0OGDEFkZCSAF1/Sffv2Rc+ePREbG4vPP/8cM2bMKNH74OzsjDFjxmDmzJkoKCgotk5oaCjmzJmDhQsX4tq1awgMDMTs2bOxefNmAC8ejtKzZ080bNgQ58+fx4IFC4r0IhR+ue3cuRN///035syZg1mzZuHnn38G8KJ7tH///qrWaXJyMj744AO1fejp6WHgwIEICwsrEl/r1q3h6OgIAPjkk0+QmpqKw4cP49y5c2jWrBk6dOiAx48fl+g9qez42S+qSpUqMDAwQE5ODrKysuDt7Q1ra2ucPXsWO3fuxNGjRzF+/HgAQF5eHvr06YN27drh0qVLiImJwahRoyAr5vmx/FyTVgQqNR8fH6F3796CIAhCQUGBEBERIcjlcmHq1Kmq9ba2toJSqVRts2XLFsHV1VUoKChQlSmVSsHY2Fj49ddfBUEQBHt7eyE4OFi1Pjc3V6hZs6bqWIIgCO3atRMmTZokCIIgxMXFCQCEiIiIYuM8ceKEAEB48uSJquz58+eCiYmJcOrUKbW6I0aMEAYOHCgIgiDMnDlTcHNzU1s/ffr0Ivt6maOjo7Bs2TIhNTVVMDc3F3766SdBEARh0qRJQrt27VT16tatK4SFhaltu2DBAsHDw0MQBEFYu3atULVqVeHZs2eq9evXrxcACBcuXHjl8ceNGyf069dP9fq//58KJSYmqu3nwoULgkwmE+7cuSMIgiDk5+cLNWrUENauXSsIgiD8/vvvgoWFhfD8+XO1/dStW1f4/vvvXxlLZcXPfvEKP/uF5xYYGCgAEA4cOCCsW7dOsLa2FjIzM1X1Dx48KOjp6QkpKSnCo0ePBADCyZMni9333LlzhcaNG6te83NNmuIFoDJy4MABmJmZITc3FwUFBRg0aBDmzZunWt+wYUMYGhqqXl+8eBHx8fFFrlE+f/4cCQkJSEtLQ3JyMtzd3VXrqlSpghYtWhTp8iwUGxsLfX19tGvXrsRxx8fHIzs7G506dVIrz8nJQdOmTQEA165dU4sDADw8PEp8jOrVq2Pq1KmYM2cOPv30U7V1WVlZSEhIwIgRIzBy5EhVeV5eHiwtLQG8aKU1atQIRkZGqvUtW7YscpzVq1fjxx9/RFJSEp49e4acnJw3jn5+WZMmTVC/fn2EhYVhxowZiIyMRGpqKj755BMAL/6/ZWZmFrnG+uzZMyQkJGh0rMqCn/3iTZ8+HV999RWeP38OMzMzLFq0CN27d4e/vz8aN24MU1NTVd3WrVujoKAAcXFxaNu2LXx9feHt7Y1OnTqhY8eO6N+/P+zt7Ut8bi/j55r+i4m/jHh5eWHt2rUwNDSEg4NDkUE1//1HDgCZmZlo3rw5QkNDi+yrevXqWsVgbGys8TaF1xUPHjyIGjVqqK0ryznJ/f39sWbNmiLX7guPv379+iJfsPr6+iXe//bt2zF16lQsXboUHh4eMDc3x+LFi3HmzBmNYx08eLDqCzIsLAxdunRRfSFmZmbC3t4eJ0+eLLKdlZWVxseqDPjZL960adPg6+sLMzMz2NraFttV/yobN27ExIkTceTIEezYsQNfffUVIiIi0KpVK63j4eeaCjHxlxFTU1O4uLiUuH6zZs2wY8cOKBQKWFhYFFvH3t4eZ86cQdu2bQG8aAUXXnsrTsOGDVFQUIDIyEh07NixyPrCVld+fr6qzM3NDXK5HElJSa9sLdWvX181WKvQy7fovYmZmRlmz56NefPmoVevXqpyW1tbODg44NatWxg8eHCx27q6umLr1q1QKpWqL+SzZ8+q1fnjjz/wwQcf4IsvvlCVvdxSMTQ0VDv3Vxk0aBC++uornDt3Drt27UJISIhqXbNmzZCSkoIqVarAycnpjfuSAn72i1etWrVi35f69etj06ZNyMrKUv0o+uOPP6Cnp6ca/AgATZs2RdOmTTFz5kx4eHggLCys2MTPzzVpioP7RDJ48GBUq1YNvXv3xu+//47ExEScPHkSEydOxN27dwEAkyZNwqJFixAeHo7r16/jiy++eO19yE5OTvDx8cHw4cMRHh6u2mfhADdHR0fIZDIcOHAADx48QGZmJszNzTF16lT4+flh8+bNSEhIwPnz57Fq1SrV4LoxY8bg5s2bmDZtGuLi4hAWFoZNmzZpfM6jRo2CpaVlkUFG8+fPR1BQEFauXIkbN27g8uXL2LhxI7799lsAL76wCgoKMGrUKFy7dg2//vorlixZAgCqVtQ777yDv/76C7/++itu3LiB2bNnF/lx4OTkhEuXLiEuLg4PHz5Ebm7uK9/HDz74ACNGjEB+fr7aD5WOHTvCw8MDffr0wW+//Ybbt2/j1KlT+N///oe//vpL4/dEiqT42X/5/I2MjODj44MrV67gxIkTmDBhAj777DPY2toiMTERM2fORExMDO7cuYPffvsNN2/eRP369V957vxck0bEHmRQGRQ3uKYk65OTk4WhQ4cK1apVE+RyuVCnTh1h5MiRQlpamiAILwY0TZo0SbCwsBCsrKwEf39/YejQoa8c4CQIgvDs2TPBz89PsLe3FwwNDQUXFxfhxx9/VK0PCAgQ7OzsBJlMJvj4+AiC8GJQ1vLlywVXV1fBwMBAqF69uuDt7S1ERkaqttu/f7/g4uIiyOVyoU2bNsKPP/6o0QCnQmFhYQIAtcF9giAIoaGhQpMmTQRDQ0PB2tpaaNu2rbBnzx7V+j/++ENo1KiRYGhoKDRv3ly1n+vXrwuC8GKglq+vr2BpaSlYWVkJY8eOFWbMmKE2CCo1NVXo1KmTYGZmJgAQTpw4UWQQVKE1a9YIAIShQ4cWOa/09HRhwoQJgoODg2BgYCDUqlVLGDx4sJCUlPTK96Ky4me/eMV99v/r0qVLgpeXl2BkZCTY2NgII0eOFDIyMgRBEISUlBShT58+qvNwdHQU5syZI+Tn5wuCUHRwHz/XpCk+lpcqpNDQUAwbNgxpaWlaXd8lIpIqXuOnCuGnn35CnTp1UKNGDVy8eBHTp09H//79mfSJiDTExE8VQkpKCubMmYOUlBTY29vjk08+wcKFC8UOi4iowmFXPxERkYRwVD8REZGEMPETERFJCBM/ERGRhDDxExERSQgTPxERkYQw8RNVAL6+vujTp4/qtaenJyZPnqzzOE6ePAmZTPba6XOJ6O3GxE9UCr6+vpDJZJDJZDA0NISLiwsCAgKQl5dXrsfds2cPFixYUKK6TNZE9F+cwIeolLp06YKNGzdCqVTi0KFDGDduHAwMDDBz5ky1ejk5OWrPpS8NGxubMtkPEUkPW/xEpSSXy2FnZwdHR0eMHTsWHTt2xL59+1Td8wsXLoSDg4Pqkav//PMP+vfvDysrK9jY2KB37964ffu2an/5+fnw9/eHlZUVqlatii+//BIvz7P1cle/UqnE9OnTUatWLcjlcri4uGDDhg24ffs2vLy8AADW1taQyWTw9fUFABQUFCAoKAjOzs4wNjZG48aNsWvXLrXjHDp0CO+++y6MjY3h5eWlFicRVUxM/ERlzNjYGDk5OQCAY8eOIS4uDhEREThw4AByc3Ph7e0Nc3Nz/P777/jjjz9gZmaGLl26qLZZunQpNm3ahB9//BHR0dF4/Pgx9u7d+9pjDh06FNu2bcPKlStx7do1fP/99zAzM0OtWrWwe/duAEBcXBySk5OxYsUKAEBQUBB++uknhISE4OrVq/Dz88OQIUMQGRkJ4MUPlL59+6Jnz56IjY3F559/jhkzZpTX20ZEuiLqswGJKrj/Pna2oKBAiIiIEORyuTB16lTBx8dHsLW1FZRKpar+li1bBFdXV6GgoEBVplQqBWNjY+HXX38VBEEQ7O3theDgYNX63NxcoWbNmq98JG1cXJwAQIiIiCg2xhMnThR5jOzz588FExMT4dSpU2p1R4wYIQwcOFAQBEGYOXOm4ObmprZ++vTpb3wkLRG93XiNn6iUDhw4ADMzM+Tm5qKgoACDBg3CvHnzMG7cODRs2FDtuv7FixcRHx8Pc3NztX08f/4cCQkJSEtLQ3JyMtzd3VXrqlSpghYtWhTp7i8UGxsLfX19tGvXrsQxx8fHIzs7G506dVIrz8nJQdOmTQEA165dU4sDADw8PEp8DCJ6OzHxE5WSl5cX1q5dC0NDQzg4OKBKlf/7Z2VqaqpWNzMzE82bN0doaGiR/VSvXl2r42vzaOLMzEwAwMGDB1GjRg21dXK5XKs4iKhiYOInKiVTU1O4uLiUqG6zZs2wY8cOKBQKWFhYFFvH3t4eZ86cQdu2bQEAeXl5OHfuHJo1a1Zs/YYNG6KgoACRkZHo2LFjkfWFPQ75+fmqMjc3N8jlciQlJb2yp6B+/frYt2+fWtnp06fffJJE9Fbj4D4iHRo8eDCqVauG3r174/fff0diYiJOnjyJiRMn4u7duwCASZMmYdGiRQgPD8f169fxxRdfvPYefCcnJ/j4+GD48OEIDw9X7fPnn38GADg6OkImk+HAgQN48OABMjMzYW5ujqlTp8LPzw+bN29GQkICzp8/j1WrVmHz5s0AgDFjxuDmzZuYNm0a4uLiEBYWhk2bNpX3W0RE5YyJn0iHTExMEBUVhdq1a6Nv376oX78+RowYgefPn6t6AKZMmYLPPvsMPj4+8PDwgLm5OT766KPX7nft2rX4+OOP8cUXX6BevXoYOXIksrKyAAA1atTA/PnzMWPGDNja2mL8+PEAgAULFmD27NkICgpC/fr10aVLFxw8eBDOzs4AgNq1a2P37t0IDw9H48aNERISgsDAwHJ8d4hIF2TCq0YMERERUaXDFj8REZGEMPETERFJCBM/ERGRhDDxExERSQgTPxERkYQw8RMREUkIEz8REZGEMPETERFJCBM/ERGRhDDxExERSQgTPxERkYT8P6StE/puemScAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance."
      ],
      "metadata": {
        "id": "B7htAJ5_aLsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the Titanic dataset (You can replace this with your own dataset path)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Preprocess the data\n",
        "# Handle missing values\n",
        "# Impute missing values for 'Age' using median, and 'Embarked' using the most frequent value\n",
        "imputer_age = SimpleImputer(strategy='median')\n",
        "imputer_embarked = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Apply the imputer for the 'Age' and 'Embarked' columns\n",
        "data['Age'] = imputer_age.fit_transform(data[['Age']])\n",
        "data['Embarked'] = imputer_embarked.fit_transform(data[['Embarked']])\n",
        "\n",
        "# Drop columns that won't be used for modeling\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical columns ('Sex' and 'Embarked') to numeric using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.drop(columns=['Survived'])\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the data into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the classification report (Precision, Recall, F1-Score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "WaK4bdcEaQZb",
        "outputId": "f906f755-4097-4494-98a3-d2ff32b7fbb5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-96aaecea0c47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Apply the imputer for the 'Age' and 'Embarked' columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer_age\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer_embarked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Embarked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Drop columns that won't be used for modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5266\u001b[0m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5267\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5268\u001b[0m         if (\n\u001b[1;32m   5269\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 if (\n\u001b[1;32m    608\u001b[0m                     \u001b[0mobject_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;31m# Caller is responsible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "je3NupffaXjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset (you can use any dataset)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# We will use only two classes (0 and 1) for binary classification\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train and evaluate without scaling (raw features)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling * 100:.2f}%\")\n",
        "\n",
        "# Apply Standardization (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train and evaluate with scaling (standardized features)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_with_scaling = model.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vseoP940aeNS",
        "outputId": "ddb806db-4a07-4090-cb9f-5dde884499d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 100.00%\n",
            "Accuracy with scaling: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "cmH_54J3afT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (Survived = 1)\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"ROC-AUC score: {roc_auc:.4f}\")\n",
        "\n",
        "# Calculate ROC curve (FPR, TPR, thresholds)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Optionally, calculate accuracy for reference\n",
        "accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "l6mI2ikLajWX",
        "outputId": "80d1e239-cf3e-4733-8f8e-106c889fd145"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-70eb8de9340f>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-16-70eb8de9340f>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC score: 0.8798\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 81.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy."
      ],
      "metadata": {
        "id": "rrJjzmGCan1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model with custom regularization strength C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with C=0.5: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4BB8jDmasGY",
        "outputId": "4deea82d-a071-4e44-d475-74e09fc8d1f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 81.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-6460db9579ba>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-17-6460db9579ba>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients."
      ],
      "metadata": {
        "id": "mC5KGnW7ayUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Identify the coefficients and feature names\n",
        "coefficients = model.coef_[0]  # Coefficients for the features\n",
        "features = X.columns\n",
        "\n",
        "# Create a DataFrame to display feature names and their corresponding coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Coefficient': coefficients\n",
        "})\n",
        "\n",
        "# Sort the features by the absolute value of the coefficients\n",
        "feature_importance['AbsCoefficient'] = feature_importance['Coefficient'].apply(np.abs)\n",
        "feature_importance = feature_importance.sort_values(by='AbsCoefficient', ascending=False)\n",
        "\n",
        "# Print the sorted features and their coefficients\n",
        "print(\"Feature Importance (sorted by absolute coefficient value):\")\n",
        "print(feature_importance[['Feature', 'Coefficient']])\n",
        "\n",
        "# Visualize the feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['AbsCoefficient'], color='skyblue')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Feature Importance in Logistic Regression')\n",
        "plt.gca().invert_yaxis()  # To display the highest values at the top\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "4i7x8Sb7a11L",
        "outputId": "a28635a9-2167-4021-83dd-bac18d46ca0e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-f64456b64279>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-18-f64456b64279>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance (sorted by absolute coefficient value):\n",
            "    Feature  Coefficient\n",
            "1       Sex     1.223858\n",
            "0    Pclass    -0.745868\n",
            "2       Age    -0.423261\n",
            "3     SibSp    -0.323025\n",
            "6  Embarked    -0.228806\n",
            "5      Fare     0.133478\n",
            "4     Parch    -0.082757\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train Logistic Regression and evaluate its performance using Cohenâ€™s Kappa\n",
        "Score."
      ],
      "metadata": {
        "id": "Pi0HmNi3a6hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model using Cohen's Kappa score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n",
        "\n",
        "# Optionally, calculate accuracy for reference\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX6qqXOsa_SK",
        "outputId": "49df59bb-fb30-44df-ca88-069c2a61570b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.6104\n",
            "Accuracy: 81.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-8d8fd23b37a9>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-19-8d8fd23b37a9>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classification."
      ],
      "metadata": {
        "id": "sWQLeX3dbGTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_scores = model.predict_proba(X_test_scaled)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "# Compute precision and recall\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='blue', label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Logistic Regression')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "J2R50z-EbPw0",
        "outputId": "a3bad0ac-4cec-4d7a-e67d-c1254df8446a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-77ec87a41de2>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-20-77ec87a41de2>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
        "their accuracy."
      ],
      "metadata": {
        "id": "VJImh1uibRJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracies = {}\n",
        "\n",
        "# Train and evaluate Logistic Regression with different solvers\n",
        "for solver in solvers:\n",
        "    # Initialize the Logistic Regression model with the current solver\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Store the accuracy for comparison\n",
        "    accuracies[solver] = accuracy\n",
        "\n",
        "# Print the accuracies for each solver\n",
        "print(\"Accuracy comparison between different solvers:\")\n",
        "for solver, accuracy in accuracies.items():\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFA-hDJTbXnb",
        "outputId": "c514e63e-fc81-4e07-95a6-3e07a7f5b223"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy comparison between different solvers:\n",
            "Solver: liblinear, Accuracy: 81.34%\n",
            "Solver: saga, Accuracy: 81.34%\n",
            "Solver: lbfgs, Accuracy: 81.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-44c42839142a>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-21-44c42839142a>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "h5a-GAu3bY7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model using Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3m7JdtTbcnE",
        "outputId": "7f58be37-2d5c-4ed0-9dbe-0433be521d68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.6123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-846423cce5a9>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-22-846423cce5a9>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "w9095aUzbg6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# --- Training on raw data (no scaling) ---\n",
        "# Train the model on raw data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set (raw data)\n",
        "y_pred_raw = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on raw data\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "print(f\"Accuracy on raw data: {accuracy_raw * 100:.2f}%\")\n",
        "\n",
        "# --- Training on standardized data (scaling features) ---\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the model on standardized data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set (standardized data)\n",
        "y_pred_scaled = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy on standardized data\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy on standardized data: {accuracy_scaled * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu3S-tVVboc1",
        "outputId": "dd66e280-1c48-4b49-fd2d-9757ac52dbd4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 81.34%\n",
            "Accuracy on standardized data: 81.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3ef99a0e3102>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-23-3ef99a0e3102>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "cross-validation."
      ],
      "metadata": {
        "id": "byPWCk3Ibpll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Set up the parameter grid for cross-validation (trying different values of C)\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Initialize GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Perform GridSearchCV on the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameter and best score\n",
        "print(f\"Best C value: {grid_search.best_params_['C']}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_ * 100:.2f}%\")\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3A-yXEAbwLB",
        "outputId": "d9a7b8bc-1368-4a6d-900e-634d19342ad8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-451f0927f5d2>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-24-451f0927f5d2>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value: 0.1\n",
            "Best cross-validation accuracy: 80.41%\n",
            "Accuracy on the test set: 80.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "tmUALIQIb3v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load a dataset (using the Titanic dataset as an example)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Preprocess the dataset: handle missing values and drop irrelevant columns\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns not needed for logistic regression\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Convert categorical variables into numeric (Sex and Embarked columns)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the features (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the trained model using joblib\n",
        "joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')  # Save the scaler too\n",
        "\n",
        "# Load the model and scaler from disk\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "loaded_scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "X_test_scaled_loaded = loaded_scaler.transform(X_test)  # Standardize using the loaded scaler\n",
        "y_pred_loaded = loaded_model.predict(X_test_scaled_loaded)\n",
        "\n",
        "# Calculate and print accuracy for the loaded model\n",
        "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
        "print(f\"Accuracy using the loaded model: {accuracy_loaded * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXhEvuBub254",
        "outputId": "cc0eec9a-26c2-49e9-acb5-987697dae31b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 81.34%\n",
            "Accuracy using the loaded model: 81.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-9d018cea11db>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
            "<ipython-input-25-9d018cea11db>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    }
  ]
}